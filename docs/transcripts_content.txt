Live Lecture Transcript
Stanford CS229 Machine Learning I Introduction I 2022 I Lecture 1

so I am tongima this quarter we are going to have two instructors you know me and Chris I I'm tonyma I work on machine learning machine learning theory um including the theory for different topics machine learning reinforcement learning representation learning supervised learning so and so forth um I guess I would like Chris to say uh say something about him whatever he wants to say yeah I'm Chris also the machine learning group I'm really interested in how systems we build are changing with machine learning uh it's been a really interesting time for the last 10 years started a lot on optimization how we scale up these big models that was when machine learning had very few applications in our in our lives around you over the last couple of years have built things that hopefully some of you in this room have used my students contributed to things like search and Gmail and assistance and other places there and more recently really interested in how to make these models robust and we'll have a great new lecture that tangyu is going to give about what are called Foundation models or these large self-supervised models that are kind of all the rage Percy and a course about them last term and this course is really exciting because it's giving you kind of that absolutely foundational layer of machine learning that all that stuff is built on so this is a great time to study it because it's no longer abstract like you get to use machine learning products in every day and hopefully you'll get some insight into how they actually work and and why there's still so much research to do so really excited and looking forward to lecturing with you folks great uh I guess you'll see me and Chris alternate um for every few weeks you know next next lecture will decrease and then after two or three weeks you can see me um so to this lecture I guess I'm going to um okay I guess the first thing the second thing is that let me introduce the teaching team so uh we're gonna have um 12 like fantastic Tas and the one high ta and of course coordinator so what is the high ta and it's gonna be the course coordinator they will be probably uh doing most of the works behind the scenes you know you probably don't necessarily have to interact with them very often so they are organizing the whole ta team and we have like 12 currently 12 Tas I guess probably we're gonna have more if we have more enrollments um and I guess um I didn't ask the kids to show up in the first lecture just because I guess they also have to wear masks and and maybe the pictures you know serve the same need but I guess you'll see them you know pretty often in office hours and and different uh scenarios um cool so um okay so I guess the um this lecture I think I'm going to spend first probably 20 minutes on some of the logistics some of the the basic kind of like uh the structure of the course and so forth and then I'm going to introduce um the incredible at the high level the topics that covered that is covered by this course so I guess um we tried very hard to make everything available online like in a single dock I guess on a single website so we have this course website which has links to a few different Google Docs um one of them is about all the logistical stuff and the other is about the syllabus and the the final one is about um also there's the links to the lecture notes and there's links to um some kind of like guidelines on the final project so in theory I think all the informations I presented today you know will be subside of what you can found on the on the website and it's actually a very small subset um so I do encourage you to kind of like read through the the documents you know to some extent you know especially when you have some questions you know maybe first go to see whether the documents answer those questions and and then feel free to ask questions to us so um I guess the first thing I'm going to talk about is the prerequisite um so this course you know as you'll see will be you know at least the sum of the students in the past say this course is challenging of course some students say it's on the easier side no um there are different kind of backgrounds you know um so I think that's why we do this is my first slice right because um I think it's important for you to have some kind of like a backgrounds to be able to achieve your your goals in this course so I think the most important prerequisite is probably some knowledge about probability on the level Flex cs109 or size 116 now for example you probably should be at least you should have heard of this these terms like distribution random variables you know expectation conditional probability violence density so and so forth right you don't necessarily have to know exactly all of them like off the top of your head but this probably should be something you have seen in one of the previous courses another thing is linear algebra major specification eigenvectors I guess linear algebra was offered in mathml4 113 205 actually there's a longer list of kind of relevant courses in the logistic doc which you know taught linear algebra and the most important thing I think we need is measure specification and eigenvectors and we also require some basic knowledge of programming especially in Python and numpy so um I think if you only know python but not numpy I think that's probably pretty much fine because numpy is really just some basic you know numerical operations but if you don't know Python and numpy but you know for example C plus plus I think that's still probably pretty fun um because you know I think migrating from C to python is is pretty relatively easy in my opinion but you know um I think they have similar kind of you just have to change the syntax but if you know nothing about programming I think that's probably going to be difficult because a lot of homework you know they have some math part and they have some programming part and one of them the most challenging thing I've seen in my past about homeworks is that when you write a piece of code and something goes wrong which happens all the time and even when I write code you know there's something that seems to be wrong and you don't know whether it's about the syntax or it's about math right so these two things kind of sometimes entangled together so so you saw that I did I derived the wrong you know equations but actually probably you didn't use numpy in the right way so we're going to kind of cover python numpy in some of the TA lectures um just to kind of give you some refreshment or kind of like if you didn't know them you can learn something from the te lectures um um so but but I think you need to have some basic programming knowledge um yeah so um the tea lectures you know we also have materials for the tea lecture so you can um like we're gonna have three lectures on each of these topics um programming in the algebra and and probability to kind of review some of the backgrounds for you um I guess you know this is a mathematical intense course you know at least according to you know of course depending on your backgrounds but kind of like a good portion of students found that uh this course is mathematically intense um so it's kind of a heads up so so it's probably good for you to have at least you know at least 12 out of these three two like among the three things probably you need to know at least two of them um relatively well so that you don't get kind of credit entangles kind of like issues when you do the homeworks so um yeah but that's kind of why this is exciting and rewarding as Chris has said the goal of this course is to give you the foundations of machine learning this is the foundational layer um so so this is a simultaneously introduction course to machine learning we don't require you to have taken a machine in the course to take this right um so so it's an introductory course but on the other hand we hope that after you take this course you feel somewhat comfortable that you know like enough basics of machine learning so that you can apply machine learning to some of the applications of course if you really want to kind of be an expert in some of the applications like nlpm Vision you probably have to take those courses but this course probably will set up the foundations for the most learning component of some of the the general kind of like AI or other applications of AI right so so that's why we're kind of like this course is actually covers a diverse set of topics and and does involve some mathematics we don't have um mathematical proofs you know probably we have a little bit proofs but very little proofs but we do have a lot of like mathematical derivations right you probably have to follow um like a do some kind of mass derivations in the homeworks and we are going to do the revisions in the in the lectures as well right um by the way if you have any questions just feel free to stop me um um I'm happy to answer any questions yes the lectures are recorded and you can find the recording on canvas I guess right so the second important thing that I want to say is the owner code it's probably a little kind of awkward to say this you know um so early and I think the reason is that in the past unfortunately we do have some kind of there are some issues with let's be frank there's some kind of issues with the owner code violations you know I I don't want to see them you know it's very you know side for me to to see the to report to have to report students you know with designer code violation but that's what's you know that happened in the past so so that's why I want to kind of like put this up front um you know if you don't intentionally write Honor Code um I don't think there's anything you should worry about like um but anyway let me briefly say you know this is actually a subset of like uh things that we have on the uh the course website but I think these are the important thing so um for example you know on one side you know we do encourage you to have study groups so you can um collaborate with other people on homeworks or on on like uh homework questions like um so but um um but the thing is that you can own you cannot okay so you can discuss works on homework problems in groups but you have to write down Solutions independently and you also have to write down the names of people with whom you discuss the homework and I guess this is I'm copying this from the logistic doc which is a little bit longer you probably should read that piece of text you know in the dock as well so it's all the code violation to copy refer to or look at written or coding solutions from a previous year including not limited to official solutions from a previous year Solutions posted online Solutions you or someone else may have written up in previous year solution for related problems you know anyway it should be fine um but as long as you don't intentionally kind of like do anything bad I think you know don't be stressed out about it but on the other hand they were kind of like reporting of final violations in the past so we do kind of like check the code um like like using some some kind of softwares and also we we do we'll we'll have Tas to kind of like deal with this kind of honor code violations too much stress about this but I don't want to kind of like put it up front here um okay so um one another component I would like to kind of like um besides homework and homework is kind of like obvious where we have to have homeworks another component of the course is the course project so we encourage you to form groups of one to three people and um so you do a project with three people for example and it's the same Criterion for either one people or two or three people so and there are more informations on the course web on a website um and typically you you apply machine learning to some kind of like um applications you know or some kind of topics you are interested in right so um this is actually one thing that I really like about this course eventually you know after every year every quarter we got like probably 100 submissions from the the projects and we see all kind of topics you know um um or like all kind of applications of machine learning like these are just a list of topics we have you know see in the past and you are welcome to you know even work on other topics right so of course you can also work on just the pure algorithms for machine learning that's also fun but many people have actually also work on applications of machine learning uh to other kind of topics like music you know Finance which are kind of interesting um okay great so and we have homeworks you know we have four homeworks you know you'll see um you know uh and we also we are also going to have a meter there is no final um uh exam so the um so midterm cost project and homework those are the main things for the course um and another component of the course is the TA lectures um so these are optional uh you don't have to attend them if you don't find them to be useful and also there are actually two sets of ta lectures so one type of tea lecture is the so-called Friday the lecture of Friday section so um so we're gonna have problematicus six to seven weeks of these lectures the first three weeks will be about reviewing some of the basics um and especially the part of the basic kind of concepts related to machine learning and then the other weeks about more advanced topics um which are not required for the course but maybe interesting for some subset of you and we also have the discussion sections the goal of this is to have some interactive sessions our course is pretty big right so you know you can feel free to ask questions but I I guess you know after bullet you know like it's a bit less interactive per person compared to other courses um so we're gonna have this uh small sessions led by Tas which the goal is to kind of like imitate more traditional classroom settings and also work on kind of like a um more kind of like Bridging the Gap between the lectures and the homeworks right so um so basically the Tas will largely work through problems that are very similar to the homeworks or even sometimes simpler than homeworks so that if you um if you need it if you need them you know they will help you to kind of like uh make it easier to solve homework questions right so and I mean terms so um and this kind of sessions will be more interactive like the Tas probably will let you to do some questions live and and maybe present your Solutions and discuss with other students so and so forth um and the exact time and format will be you can find them on the on the the dock um the Google Doc about the logistics oops Okay so yeah so there are some you know many other informations on the course website on the Google Doc the dock is actually 15 pages now um it's pretty comprehensive um so for example recordings they can be found on canvas um there's a course calendar on canvas there's a syllabus page which will link to the lecture notes um and um and we're gonna have like the the ad the platform for question answering um we do encourage you to use that to communicate with us um if that makes sense like a like almost in all situations I think you probably should use ads to communicate with us you can have private posts or another's post um different type of posts depending on what you need um and if you don't have access to that then you probably have to email some of us I guess you can email the uh the ITA too um to add you to the to that to give you access to add um and there's grid scope which is used to submit homeworks and there are some late take policies which you can find in the the dock as well so I guess one thing that I need to mention here just uh as a heads up is that we don't allow late days for the final project and this the reason is just that especially for spring quarter the grading deadline is very tight so it's pretty much just a few days after the the final the exam week so especially because some of the students have to graduate and they have and it's the timeline is very very strict so um and we don't want to kind of like make the course project deadline the final project like very early right because then that would kind of conflict with the homework deadlines so and so forth so so the final project I've done I think is on the I think it's on Monday of the the finals week uh double check that but but it's it's we try to put it as late as possible but on the other hand because the the final greeting deadline we don't allow later is for the final project uh and there are some other IFA cues you know in the Google Doc as well any other questions before I move on to the topics the more kind of like the scientific topics foreign we have two uh Tas uh offering two discussion sessions I think we will try to make sure that the materials in the two sessions are pretty much the same and the times are kind of like somewhat kind of I think we haven't decided time yet um so you can feel free to choose any uh sessions you want to go um probably is the best for you to consistently go to one session maybe the Tas knows you better you know um but you don't necessarily have to and then this is also optional you don't have to really say go to all of them depending on your needs yeah other questions okay uh okay sounds great so I guess then I will move on to the more scientific part of the course so as I said um the main goal of this course is to set up you for the foundations of machine learning um and we're going to cover a pretty diverse set of topics immersion learning with the you know some kind of mathematical way so let me start by um some definitions of machine learning what is machine learning right as you can imagine you know when you are speaking about you know such a kind of like hot topic that is kind of like um that people are constantly researching on right so there's probably not unique definition right so that can fit uh everything right but I'm trying to find out some kind of like historical definitions of machine learning which I think describes the field um pretty well so in 1959 I think this is probably the first time machine learning the word the phrase machine learning was introduced on by author Samuel um he says that machine learning is the field of study that gives the computer the ability to learn without being explicitly programmed so I guess without being explicit program it's probably um something pretty important for example suppose I guess this is in the paper titled some studies in machine learning using the games of checkers recent progress I don't exactly know what the game of hackers is so don't ask me about what the rules of the the game but the point is that if you explicitly write a piece of code that play the Checker right that doesn't really mean that you are using machine learning right so if you just say I have this fixed strategy I know which is actually very good for checkered the first step would be this and the Second Step would be that move right I just explicit code that uh in my in my computer and with some branching algorithms right so um that probably doesn't count towards machine learning right so uh if you use machine learning you have to like the computer to learn without being explicitly programmed so you shouldn't have explicit programming so but how do you learn right how do you give the computer the ability to learn I think in the second definition of machine learning by Tom Mitchell it's kind of like describes more context or more kind of like a um like a context about you know how do you really let the program to learn uh without being explicit programmed I think it says that a computer program is set to learn from experiences e with respect to some class of tasks T and performance measure P if its performance at tasks in t as measured by P improves The Experience e the the rhythm is kind of nice um so um so I guess there are several important Concepts in this passage so one thing is that The Experience e right so so I guess let's still use this example of the game of Checker so the experience in this case could mean for example the data so data basically means that this policy could be games played by the program with itself it could mean games played by humans in the past it could mean you know other kind of like a data you collected from other you know source of information maybe you collect some data from I don't know like uh in this case maybe um um you know you can collect data from other sorts of information maybe here mostly just on collecting data by playing itself or playing by humans so so experiences mostly means data and there's a concept called performance performance measure which is kind of important in machine learning of course there's no unique performance measure for different tasks you have different measures of performance but but the metric performance is the this metric the performance measure is pretty important in here you can call it um the performance measure could be the winning rate it could be the the winning rate Plus for example the the number of steps you played right you probably want to win as fast as possible in some other cases the performance measure that could be How likely You can predict something very accurately right so you can Define many performance measures and um I guess actually you know immersion learning you know if you look at the research you know some papers about you know understanding what's the right performance measure what's the right way to formulate our problem and some of the papers are about that given the performance measure how do you make the performance you know as best as possible so um and there is so and also there is this um last sentence where it says that if it's performance at the task in t as measured by P improves with experience what does improves with experience E I think it means that if you have more experiences if you have more data then your algorithm should have better performance so so that in some sense is a kind of like a a kind of like a evidence for you to learn something from the experiences right if you have more and more experiences you your performance is not improved maybe that doesn't really mean that you learn something right that could probably just means that you are you just progress you just program some kind of like explicit program some strategy and that strategy probably wouldn't improve as you have more experiences right so so in some sense this last few words indicates that you are learning uh from the experiences all right so I guess you know the final thing is that the tasks right so here the tasks is really winning um is this kind of context of playing the game right so um and we're gonna see actually a many different type of tasks uh actually just in this lecture right so there are tasks about predicting um the the labels of predicting something given the the input or the task could be finding out certain structures in the data or the tasks could be something like this where you want you want to kind of make decisions about you know how do you play the game in any case feel free to stop me just with your hand then I'm happy to answer any questions um this lecture is supposed to be very high level so um feel free to ask any questions so uh I guess um speaking of tasks right so this is um a pretty simplistic view based on tasks you know how do you have a taxonomy of machine learning right so I don't think everyone agrees with this 100 um um but it's a it's a reasonable Baseline you know as a as a kind of like a high level kind of like taxonomy so I think surprise learning and surprise learning and reinforcement I'm going to introduce uh this um uh separately but it's not like these tasks are completely uh separated right so probably the real figure would be like this right so there's some overlaps right so in reinforced learning problem you have to use supervised learning as a component and and as I said like many machine Learners where people are trying to figure out what's the right way to formulate the question to solve the applications right so maybe for some applications you have to use two of this together so um they are not necessarily only tasks but sometimes there also kind of can be viewed as you know tools or methods to solve your question right so maybe some questions requires you know using for requires a formulation that involves both of these three ingredients in some way um but as a first other bet you can think of them as three separate or roughly separate kind of type of tasks so I'm going to introduce supervised learning first so um surprise learning I guess um we are actually in the lecture we are going to use this um uh house price prediction uh as a kind of a running example so the kind of idea is that I'm going to have a relatively abstract way to introduce this but you can use this you can think of the the house price prediction as the kind of application so what you are given is a data set that contains n samples and what are these n samples it's n samples are in pairs um of you know numbers or empires of like vectors where X could be a vector or a number let's say x is a number and Y is also number so you have n pairs of X Y numbers and you can actually draw these numbers you know um here you know have a Sketcher plot right so every you know cross is really just One X by pair and the X could mean um so ask means the hot I guess this as shown here in the in the caption or um so the square feet is X and the Y is the price right so basically for every example it's a pair of square feet and price you are trying to use the square feet X to predict the price y That's the task and and this data set is called you know using Tom Mitchell's language this data set is the experience in a problem more more than language we call this data set of data so so basically our goal is to learn from the data set how to predict the price given uh the square feet of the house and so so basically if x is 800 then what is y and 8 this x you know might not be seen in the data set right if you ask is already you know show up already shows up in the data setting it's easy you can just read it off but X could be something that you haven't seen in the data set so and you know one of the way that you probably have seen this you know in some of the other lectures or other courses where you can do a linear regression you fit a linear line and then when you predict you just read off the corresponding number on this linear line what is the corresponding Y where X is 800. so and of course you can do um other things for example you can try to fade a quadratic line right so which actually in this case in this example uh this artificial example I I created you know a quadratic line problem with fill the data better um and in lecture two and three I think our goal would be um to discuss you know how do you fit a linear model and all you how to create a quadratic model for the data to predict the house price of course you know the house price prediction is only your application you can imagine you know many other applications where you are giving a data set of X by Pairs and your goal is to predict y given X for example you know um we can even we can just simply make the house price prediction problem a little more complicated right so we said that in the previous lecture in the previous slide we use the the size to predict the price but actually you know probably more about the house right so and you know for example the lot size and maybe you know other things right then for example suppose you also know the lot size then your goal could be to predict the price using size and loss size and we call this kind of like input different dimensions of the input X features right so size is one feature and loss size is another feature so now you have two features of the the particular house and you want to predict the price based on the two features and now your data if you draw them um and then there will be three dimensional X1 X2 and Y and then you can kind of plot them in these three dimensional graph um and as I said you know the um the the kind of the the things you know in the class time right the size and loss size is called features or input and in this case this features is two-dimensional and typically people call the price label or output and you are trying to find a function which Maps the input to the output um so actually another heads up is that in machine learning almost every concept has more than one terms for them so you're gonna see that you know some people call this feature some called people call this inputs and in some other cases probably you have other names for for digital things we'll try to be kind of um uh comprehensive like I'm gonna tell you what are the different names but we're going to use one of them I think in the lectures mostly we probably we're going to use input because input and output is a little bit less ambiguous actually features sometimes could mean other things as well um and again now everything is the same in terms of the mathematical notations the only difference is that now your ex is a two-dimensional thing let me explain the notation here a little bit which will be used consistently in the lecture so the superscript here denotes the which example uh you're talking about whether it's the index for the example and the subscript here denotes the demand the coordinates of the of the data so x superscript i is a two-dimensional vector and the X superscript I sub 1 is the first coordinate of the two-dimensional vector yeah and also sometimes like a website that the price the Y is called labels and outputs and sometimes they also because they're also called supervicious or generally if you say supervisions that means the set of labels right that's why this is called supervised learning because you do observe uh some um labels um in the in the in the in the data set and also the data set you know sometimes people call it tuning data set um or data set um or training examples you know there are multiple names um for the for it any questions and you can also have like high dimensional features like before we only have two Dimensions but actually in many cases you know if you have a house listed on online right for sale then you probably know a lot more about the house and then you can have a high dimensional Vector uh say d dimensional vector and each Dimension means something right maybe the number of floors the condition the ZIP code so and so forth and you use this High dimensional Vector to predict the Y um the label that you are trying to predict and in lecture six and seven we are going to talk about you know infinite dimensional features actually so in some cases you can uh have like you know uh you can combine these features into not a lot of more other features where you can say I don't use X Y as my features but I actually use X1 times X2 as my features right leaving size times a lot of size I don't think that makes a lot of sense for this application but in some other cases maybe you can kind of like take the product of your two um raw features right two dimension of the input you have and use that as a as a new feature right so and we're going to talk about how do you deal with infant dimensional features as well um and in some of the other lectures we're going to talk about you know how to select features Based on data um so maybe not all of these features are useful if you use all of these features then maybe you can overfit which is the concept we're going to talk uh talk about you may kind of like be confused if there are too many informations um available so you may select something that is most important right so maybe um I don't know like all of this seems to be important but maybe there's other features that are not important for price prediction right and there's another concept that I'm going to introduce in the in the first lecture we'll talk about this um later as well so um typically there are two typos two types of supervised problems so based on this distinction is based on what kind of labels uh you have right so um one type is called regression problem so these are problems where your label y is um is a real number so you are predicting for example something like a price right so this is a continuous variable and there's another type of questions which is called classification and these are cases where the labels is a discrete variable what does that mean that means that your labels are probably like you have two labels yes and no right so you just have like this label that is just a discrete set with two choices yes and no um for example like in this case you can change the question like you know if you're given the size and lost size you can ask you know whether this house what's the type of this horse or this residence right is it a house or townhouse right so it's not a continuous prediction problem it's really just the predicting one of the two choices and you can make this problem more complicated for example you can have much more choices here um not only just two choices and then in this case you know the way that we can kind of like um kind of plot the data set um one way to product is the following so now you have a two-dimensional uh graph where uh the x is the size and the Y is the the Lost size and then for every dot you have a you know if it's a triangle it means it's house and if it's a circle it means a townhouse and that's how you kind of like visualize the at least one way of how to visualize a classification data set where the labels are discrete you just use the triangle and circle um to to indicate the label of this example and and and then you know the kind of questions you want to solve sorry my animation the question you want to solve is that now if you give me a house which is a two-dimensional Vector with the size and loss size given as it as the input and you're asking what's the type of this uh house um so whether it's a house or town house and one of the way to do it is that you say you okay now I see okay so you can fade a linear classifier that distinguish these two type of dots and then your answer here would be naturally house because it sounds like it's on the right side of the this correct this side of the the line so it's probably should be consistent with all the other uh examples on the same side of the line so I guess lecture three and four will be about classification problems and the next few slides I'm going to talk about some broader applications of machine learning which we don't necessarily will cover I think image classification I think probably we're going to have one homework questions on image classification so the kind of the type of question is that you are given all of these images and every image has a label which describes the content of this uh the main object in this image of course you know in other cases you know you may have multiple objects in the same image but here let's say let's focus on a simple setting where every image has a single important object and then your label is basically describing what this object is and you're giving this data set this is actually a real data set you know created by Stanford people like by Professor Philistine so which is called imagenet this is a very important data set that you probably should remember the name of it because this is pretty much the data set that in some sense make deep learning take off in the last five to ten years um like before after the creation of this data set and some of the new um deep learning algorithms with new artworks I think in the last five to ten years we saw um like machine learning took off and are able to kind of we were able to make a lot of progress because of the data set and speak of the data set here I'm only trying to say what's the format or what's kind of the task right so basically your ex is some raw pixels of the images where you just represent this image as a sequence of numbers actually here's a matrix of numbers and then um your Y is the the main object of the of the image so and you can have other kind of tasks in vision for example object localization or detection right so give an image you can ask you know how do I localize you know um find out each of the important objects right with the bounding box we're not going to cover anything like this because these are more specific to the vision applications and right so so here I guess the the thing is that your why becomes like a a bounding box right so so how do you present this box um you know you don't have to know this but you know if you are interested the way to present the box is to present a box by uh the the coordinate here and the coordinate here and these two coordinates four numbers by two points four numbers will describe the box so basically a y will become four numbers uh instead of just one number and actually you can have actually more complex labels or y's in other applications for example in natural language processing which is the area to deal with you know language problems so for example machine translation you can have this problem where you you want to translate um for example English to Chinese uh and your ex is I don't know what happens with my pointer okay so your X is the the English sentence and your Y is the um is the uh the Chinese sentence right all sentences in other languages and now you can see that the Y even though Y is a discrete set the the family of y's is the family of all possible sentences um in uh in Chinese right but so so why looks like this quiz but Y is much more complicated than the house versus townhouse application right so you have so many choices of why like almost like exponential or even number of choices so then you have to deal with them in some different ways I think we're going to cover a little bit about machine translation or this kind of questions uh in one of the lectures that we uh added on this year um I guess Chris mentioned that like we're going to talk a little bit about like a large language models uh for language applications but on the other hand you know this course only covers the basics of the foundational techniques of surprise learning so we're going to talk about language applications but if you really care about the particular applications how to solve them the best way then you probably would have to take some other uh more kind of like a specific courses um for those particular applications okay so before I move on to unspressed learning any questions about surprise learning so would you say it's a regression problem or classification problem I think I would say it's a classification problem because why the formula of Y is still technically discrete right because you still have like a a finite number of possible y's because um I assume you can say the number of sentences um Chinese let's say the name of Chinese sentences is finance right even though the number is very large but this is a good question because you know you cannot choose this as a simple as a you have to treat it in some slightly different way differently from the the most vanilla classification problems because if you view this as the vanilla classification problems then you're going to get into other issues right so um just because the set of wires is too big when you use infant dimensional features so um I think I might not have a very clear answer right now because this does depends on a little bit on some of the other things we're going to teach but I think generally basically sometimes you don't know what so basically okay first of all how do you create infinite number of features right like so you you have to create them from X right so for example I guess I I think I alluded to this a little bit at some point so for example suppose you have this number of features right maybe D is a hundred so now you have 100 features how do you create more features you're going to use combinations of the existing features right so um and you can come up with a lot of different combinations um so you can have like for example x d to the power of K right and K could be any integer right so that's how you create infinite number of features and why you want to use them sometimes it's because you don't know which one is the best so you just say I'm going to create all the possible features I can think of and I'm going to like the machine learning model to decide which feature is the most useful or how do you combine these features so that's why we use info-dimensional features in most of the cases in reality you don't have to literally with infinite dimensional features after you run the algorithm you found out that some features are more important than others but before you run an algorithm we don't know which one is useful so you like the algorithm the machine learning algorithm to figure out which one is the most useful and actually one of the interesting is that even the dimension of the features is infinite it doesn't really mean that your runtime has to be infinite so there are some tricks to reduce the actual runtime so even though you are implicitly learning with infinimental features actually your algorithm or runtime and memory all of these are actually finite and and actually sometimes they could be pretty fast in some in some cases so these are great questions yeah thanks for all the questions any other questions okay so the the second part of the um the course will be about Enterprise Learning I think Chris will probably um give about five lectures on and space learning so and space learning the if you still use the host um house prediction kind of data set as an example the basic idea is that you know you are only given a data set without labels you only see the access but not wise right so you don't know how this house is you know in a data set are sold um in in the past so so what happens is you know it's you still using this townhouse versus house example right so if you are supervised and you have this triangles and and and circles here to indicate what what are the labels but you guys should stand here so but uh um if it's answered you just don't have this this part of the information right you just see kind of like a this this bunch of dogs here in the in the scatter plot but as as you will see right even you just see this right as a human if once you see this you somehow tell that okay this bunch of points here is very different from this bunch of points here so maybe there are two type of residents here uh going on even as a human right even though you don't see the the triangle and circle you still kind of are able to tell there's something going on there right so that's the kind of the the nature of science learning we want to be able to discover interesting structure in the data without uh knowledge about the the labels right so you want to figure out the structure hidden in the data so to find some interest instructional data so for example in this case you know what you can do is that you can try to Cluster um cluster these points into groups right you want to divide these points into groups and what you want to say that each group probably have some kind of like a similar structure right so this probably doesn't sound like a very good clustering because um at least as a human being you probably wouldn't cast it like this but maybe you you like a good algorithm problem would produce this right so if you produce this then essentially you figure out and there are two type of residents and this data set even though you don't know the the name of these two happy presidents right because the algorithm wouldn't know townhouse or house is two words but the algorithms knows there are two type of things going on here in the in the data set um and in lecture 12 and 13 we are going to talk about a few different kind of algorithms for discovering the structures okay means classroom and mixture of gaussians um and there are other kind of applications uh for example um I think this is a paper by um Daphne Collins group who is a Adjunct professor here at Stanford so so here the kind of applications about Gene clustering so I think the idea is that you have a lot of individuals and for this particular part of the genes you know you can group uh the genes of individuals into different groups so and and you can see that um um I guess even basically you can kind of see I'm not sure what's going on with my foreign you can see that there are some kind of clusters here and it turns out that each of these clusters you know corresponds to how the individuals would react to a certain kind of medicine right so and once you kind of like can group people you know into groups then you can probably apply the right type of kind of like um treatment on to each type of people um now here is another example which is probably a little more kind of easier to understand you know like uh so so the the the the type of kind of question is called latency meta-analysis which I don't expect you to understand what each of these means you know it's just a kind of like a name iOS a so the idea is that you kind of like look at a bunch of documents and every document has a lot of words right so and you look at which word show up in which document for how many types so each entry here supposed to pick one entry it means how how often the word power shows up in this corresponding column the document 16 is it document document six there right so every answer is how often the word shows up in the in the in the document and if you see this you know it then sounds like there's any pattern here right so what's the structure it's unclear but if you use the right machine learning algorithm what happens is that you can reorder or regroup this kind of words and documents in the following way you see the video is working right so basically you permute the documents and words and and then you see this kind of like interesting and sometimes block diagonal structure not very prominently but still kind of interesting enough and now you can see each of these blocks has some particular interesting meaning for example here this group of documents and words has this it's clearly about something about space kind of like shuttles right so shuttle space launch booster these are all about kind of like a like um um like a like a space traveling kind of things right so and so basically you know that this kind of four words have similar meanings and these four documents or three documents are about this this topic so by doing this you in some sense you know at least in this application you can figure out the kind of the topics of uh in in your data set right so you can figure out probably here there's one topic two one two three four five topics and each topic is more likely to associate to a certain type of words and every document is most likely about one topic and sometimes it's about two topics and then what you what happens is that once you figure out these kind of topics and then you can use some humans to kind of like interpret each of these topics what each of these topics are and then give a new document you can figure out you know what topic this new document is about and this actually is very popular um tool in many of the social science because in Social guys actually even myself you know was involved in some of the projects in my PhD so the social scientists they have some texts right they maybe have like a lot of like a maybe blog posts about politics right and they want to understand you know what each for example what trends happens you know in the blog post that so suppose you want to understand that and then you have to know you know what are the kind of topics about each of the blog posts where you don't want to kind of like label them each one by one because they maybe they have like a million blog posts right so they use this to kind of group the blog post in certain ways and then they can do statistics to understand what happens with all of these blog posts and this kind of applies to other kind of things Beyond politics you can have like actually you can even apply this to I think many things like you know history um what else you know um like psychologists so and so forth right so um and this was actually an algorithm discovered probably 20 years ago or even maybe earlier than that maybe 30 years ago and it was pretty uh popular still like a um in in social science of course there are even more advanced you know algorithms they stay single Beyond this um um which we're also going to discuss right so this is actually one of the the more recent kind of advancement I think this was like a around 2013 2014 about seven eight years ago so what happens here is that um you have a very very large unlabeled data set which is the which is called Wikipedia um so um so you just download all the documents from Wikipedia there's no other human labeling right they are just just raw documents and what you do is that you learn from these documents using some algorithms and what you can eventually produce is the so-called word embeddings so you can represent all the Every Word by a corresponding vector and why you want to do that the reason is that these vectors has um basically a kind of like the the numerical representations of the of the discrete word and and there are some nice properties about these factors that captures the semantic meanings of the words so so what happens is that similar words will have similar vectors and and also the that's that's what I mean by like a the word is encoding the vector so similar word would have similar vectors and also the relationship between words will be encoded in the directions of the vectors this sounds a little bit abstract maybe it's easier with this figure so um actually this kind of happens in reality right so if you look at the vectors each point is the vector for that word right so Italy has a vector and the vector let's say is this point and France has the vector and Germany has a vector so you'll find out that the vectors for all the countries they are somewhat kind of similar in similar directions right so they are so for example suppose you have another country USA then you probably would find out the the point somewhere here like nearby right so all the country uh has vectors that are similar in similar that are that are in similar directions and all the capitals are also in similar directions so this is what I mean by the um the the vectors kind of encode some kind of semantic um uh like a similarity between the words and also interestingly the directions also encode some kind of uh relationship so here what happens is that if you look at the difference of the um uh between Italy and Rome right so you kind of this this direction right this is the difference between Italy and Rome and you also do the same thing for Paris and France and Berlin Germany you'll see that the three directions they are very uh similar to each other they are kind of like in these parallel positions so um so in so um at least one application of this is that if you want to know um suppose you are given let's say us right so which is a vector here right and you want to know what is the capital of U.S where is the capital of U.S you probably should you go along this direction to search for points and that's likely to be the capital maybe you'll find DC or Washington I guess you'll find DC there um because I think Washington is ambiguous which is a little trickier um I guess that's why I don't have the actually this is an interesting thing right so uh if you have the the Washington director uh would be tricky right it's not clear where the the vector for Washington will be not clear where it will be because Washington has multiple meanings right so it's a state it's a it's a person is you know um so so actually this is a sometimes you know you have this ambiguity and and then you can have this kind of like more kind of complex clusterance of the words so for example I think um so here I guess what happens is that you know you can also use these vectors to Cluster the words into groups um so for example uh you have this kind of groups kind of these words you know like scientific words some of which which some of which I don't even know and then you can use the the casting algorithms for the vectors to figure out what they uh what kind of topics or what kind of like scientific areas they belongs to right and and you can also have hierarchical clusterings uh to deal with kind of certain kind of overlaps because for example mathematical physics probably would be closer to the physics vectors and math factors on both right some somewhere in the middle of the math and physics vectors so um um so so so there are this kind of like an interesting many kind of different interesting structures in in all of these word vectors which you can uh leverage to solve your tasks I'm a little conflict here just because you know to exactly do all of this it requires a little bit more uh uh things you know um that we haven't you know discussing but we will discuss some of this in later lectures so and and most recently um in the last two or three years there's a new um kind of like uh say Trend or kind of like there's a new breakthrough in machine learning which is um these large language models I think many of us are very excited about it you know Chris has mentioned about that um and and I stand for new health actually um a lot of people you know working on these large language models um and roughly speaking these are machine learning models for language and they are learned on very large scale data sets you know for example Wikipedia I say um discussed before or sometimes even bigger than Wikipedia so you can download you know um a trillion you know words or maybe like a like a like a 10 trillion words you know on on online because there are so many kind of like online documents and you collect all of this um documents and you learn a gigantic model on top of it you know these are gonna be very very costly even tuning the single model would probably cost you like a 10 million dollars you know um so just for one time so they are they are very costly but they are very powerful because they can be used for many different purposes and in particularly here I'm talking about this breakthrough called gpt3 you're gonna heard this name probably pretty often uh not very often like in the lecture um uh like pretty often in general like a um in the next few years I think uh or you probably already heard of it in the in the lecture we're going to talk about this like in one lecture so GPD three is this gigantic model and they can do a lot of things so I'm downloading this is a example of from there on blog post so you can use this gpt3 to generate uh stories I think here what happens is that you you give human some person writes this paragraph about you know something right so like some I guess mountains or valleys and then um the model the Machinery model can just generate some story and some kind of like very coherent and meaningful text afterwards and you cannot probably if you don't tell you these are generated by machines you probably wouldn't know that they are generated by machines you probably guess this is written by um on some some authors so that's one application you can one use one way to use this model to generate stories and you can also use this model to answer questions right so here um you you give you give this model this long paragraph and then you can ask um it's kind of like a SAT I'm not sure like this is kind of like GRE questions I'm not sure whether all of you know GRE but like um so like these are kind of like just basic questions answering about the past passage right you can ask you know what's what is the most popular uh um politics in uh in Finland and and this will this is this is the information you can find in a document and and they would answer the right thing um so that's another application and you can also use this to do other things for example you can say you can just just write in the text say please unscramble the letters into a word and write that word and then you give this to the model and the model will just change the uh the orders of the letters to to make it a meaningful word and you can ask you know for example this is not like a simple numerical questions what is 95 times 45 and it gives you the right answer and all of this are not like so so what's the amazing about this is not because it can solve all of these tasks just each of these tasks the amazing thing is that you learn on this unlimited site this gigantic and enabled set you didn't specify what tasks you want to solve right the only thing you see is this gigantic data and then the single model can be used to solve multiple tasks just by interacting it with different things right if you want to solve this task you just write it in the human interpretable language 95 times 44 45 and if you want to solve another task you just do something else a slightly different kind of like phrasing um then they can be used to solve multiple tasks and that's that's why we call them Foundation models um at least you know your paper in a white paper written by Stanford people um so um so in some sense there are kind of Foundations uh for uh they can be used for a wide range of applications uh without um further and sometimes without a lot of like further uh changes right so the model itself can be can do a lot of work um for many tasks okay so I guess I'm supposed to stop like for 30 wait 445 right yeah sorry like uh um okay so I still have some time any questions sorry um like a um right so I guess um maybe one if I understand the question correctly so one concern is that whether this 95 times 45 already show up in the Corpus but maybe you just memorize it that's one possibility but I think that's that's not the case so of course some of the numerical um problems like some of these multiplication problems show up in the Corpus christ you will find one document online about you know what is 12 times 35 but you wouldn't find I think you wouldn't find the uh documents about all pairs of like multiplications um so like multiplications of pairs of like two digits numbers I don't think you'll find all of them um so so there's some kind of extrapolations where you see some of course you have to see something right so that you can learn from them right so you probably have seen a lot of kind of like a numerical um uh operations like all kind of like mathematics the formulas in the document but then you can in the in the tuning Corpus and then you kind of extrapolate to other uh other instances right like so you learn from um some basic stuff and then you learn like then you can use the model to Output multiplication so for example longer uh digits does it make sense does that answer the question right so how do you make sure that the like uh by pollution I guess you mean that how do you make sure that in the tuning Corpus they are not all pairs of double digits right so I think they do run some tests to check that so of course you cannot make sure I guess is that what you mean by pollution or you mean by pollution you mean like something wrong about the false information right right okay right so that's a great question right so I think abstract is speaking the question is about you know how do you make sure your training corpers don't doesn't have wrong information for you all right so I think we you know I think they definitely they are wrong information in the Corpus right I think what happens is that they are probably more correct information than raw information and and you somehow kind of reconcile between them and you kind of pick the right thing um so that's largely what's going on but of course you know if you are very specific about you know so this this area called Data poisoning so you can actually specifically change your tuning data in some special way actually you just change a small number of training data so that your model learns something completely wrong so that's that's actually possible so but that requires a kind of adversarial change of the tuning Corpus so so on one side this is a very bad thing because you know if someone do something out of a serial online and you use those kind of documents to train your model that's that's a huge risk on the other hand you have because you have to right so at least right now like uh like the it's not it's like a this kind of like a adversary Point thing is not happening very often just because it's not very easy to achieve them thank you okay any other questions okay cool yeah these are all great questions like I like to have more questions uh that's great so um okay so the last part is about reinforcement learning um this will consist of probably two or three lectures at the end of the um at the end of the course so the main idea of reinforcement is that here the tasks roughly speaking about learning to make sequential decisions so I think there are two things right one thing is that you are making decisions so before in both Superstar and express learning in some sense you are making predictions right at least in supervisoring it's pretty clear you are predicting wise but here you are talking about decisions and what's the difference between predicting decisions and like the decisions and and predictions the decisions has uh long-term consequences right so for example if you play chess right so you you make some move and that move will affect your future uh like it affect the future right so so you have to to think about long-term ramifications and also this is a sequential decision so so you're going to take a a sequence of steps right so when you take the first step you have to consider you know what this step will change my game and what happens in the future so so that's why you can see that you know this kind of like reinforcement algorithms are mostly trying to solve these kind of questions where you have to make a sequence of decisions so for example when you self-go right you probably heard of alphago and another example is like for example you want to learn a robot so if you want to control the robot you have to take a sequence of decisions right how do you change the joints you know how do you kind of like a control uh like actually there are always multiple kind of like uh things you can control for a robot and how do you control all of them in a sequential way so here I'm I'm showing this in a simulation environment so this is a so-called humanoid which is kind of a robot that imitates a human so and the goal is to you can control a lot of joints um in this in this robot and your goal is that you want to make this robot be able to walk to the right as fast as possible and and this is what happens uh how the kind of what happens with the reinforcement algorithm learning here so it's kind of like trials and errors to some extent so what you do is you say you first try some actions right you first try to kind of like do something like this and and then you figure out that this didn't work well right it's false and then you go back to say I'm going to change my strategy in some way right so I know that some strategy is not going to work I'm going to try some other strategies and maybe I know some strategies is actually partially working because at least the robot the humanoid is is doing something right it does walk to to the right for one step it just didn't keep the balance you know some part is good some part is bad and then you try to go back to change your strategy and then you probably can walk a little further something like this right and then I guess I'm going to fast forward to iteration 80 I think 80 works I forgot whether I have an oh actually 80 still doesn't work perfectly you can see it's working in a weird way um yeah so and I think at iteration 210 I think it's it can keep working but still it sounds that it sounds very natural but this is a problem like you shouldn't expect that the humanoid work as natural as humans um partly because they are different there are many different things right so like maybe for the robot this is optimal strategy you know that's possible but of course I don't think it's the optimal strategy but it's possible that optimal strategy for the robot is not the same as the option strategy for for us so and generally as I alluded to so the kind of like the the very high level idea of reinforcement algorithm is that you have this kind of like Loop um between training and data collection so so the algorithm so before in Supersonic and Einstein we always have a data set where someone give you a data set and that's all you have right you cannot say okay give more examples of the house uh house prices right so you have to work with what we are given but here uh in the reinforcement formulation you often can collect data interactively I see some questions it's a question sorry okay um okay so so here you often can collect data interactively so meaning that you try like for example in the humanoid example you try some strategy and you see that humanoid false then that's the data you see additionally right so then you can incorporate new data back to your training algorithm and then change your strategy right so you have this kind of loop where you in one one side you try the strategy and collect feedbacks and the other side you improve your strategy based on new feedback so in some sense you have a data set that is growing over time the the longer you try the more data points you're gonna see and and that will help you to learn um I'm better and better so I guess so um Okay so I guess that's my last slice about reinforced learning any questions [Music] oh oh sorry oh uh or after like an empty like the information is completely right right so is the feedback uh uh seen after each type of decision or is it after something else right so so there are many different formulations this is a great question so so the most typical way typical formulation is that you see the feedback right after the decision you make um but that sometimes it's not realistic for example let me see what are the examples so um I I think okay maybe I'm blanking on what are what are the best examples to show but in some cases you don't have the feedback right right after and sometimes even you have the feedback right after the decision you cannot change your strategy right after decision so um just because for example there is a computational limit or you have to really do something physical to change your strategy on a humanoid right or maybe there's some communication constraints so uh so there are multiple kind of different formulations reinforcement learning I think if you have delayed reward I think that's called the delayed reward problem and sometimes you also have this so-called deployment wronged in the sense that um so this notion of number of deployment means that you can only update your strategy for for example five types right so you cannot just constantly change your strategy and then you can ask this question what's the best way to to do this for example I guess one example is that um you suppose you are using reinforcement to control a nuclear plant right so you probably don't want to say that you just keep telling you you run algorithm like a um like you run algorithm and the algorithm keep telling the nuclear plant to change their strategy to control them right like every day that sounds like risky and and also kind of like inefficient you know there are many problems with it right so probably you're gonna say that I have to do some experiments you know for a little bit for six months and then I figured one strategy that I almost guarantee um uh I can guarantee that this new strategy is working better than the old one and then I deploy it and then collect some new feedback quite so and also I guess maybe another thing this is a great question and another thing um I I would like to mention is that in many of these problems you know there are multiple uh Criterion for example for reinforcement if you want to control the nuclear plant there's a safety concern right so then you have to have to care about whether your strategy is safe or not right for the human noise probably it's fine for the human not to fall down you know to some extent but still you cannot really let it fall down so often because it will hurt your Hardware right so it is frustrating the other constraints for example there are constraints about you know how how long is the tuning type right that's the typical metric and there is also a constraint about how kind of like a powerful or how kind of multi-purpose on these models are right How likely they can solve multiple tasks So So eventually like uh this is a very um like especially if you look at a research Community there are different people care about different metrics um just because all of these metrics you know have their own applications right so um so so this so it's the the real kind of scenario is much more complicated than this in some sense okay so I guess um in um there are a few other lectures about other topics in the course um which are actually in between some of these um big topics so one of the topics we are going to spend two lectures on is deep learning Basics so deep learning if you heard of the word so maybe some of you have heard of it so deep learning is um the technique of using the so-called new neural networks uh is your model parametrization so um so this is this can be used together with um all of these tasks right it's kind of like a technique that can be used in reinforcement that can use in Surprise learning and express learning and in many other situations so and this is something that um um is very important because you know because of deep learning uh took off around 2014 2013 in the last seven years we see this tremendous progress of machine learning because of these techniques a lot of things you know are enabled by this different techniques so uh and we're gonna also discuss a little bit about learning theory uh just for one or two lectures um so in some sense actually we don't really talk that much about the the the core theory in some sense the goal here is to um uh understand uh some of the kind of like trade-offs of some of the decisions that you should do when you train the algorithms right so what's the best way to select features what's the best way to make your test error as small as possible and also we're going to have a lecture on how do you really use some of these insights to tune um an ml model in practice you know what kind of decisions um I as though as the machine learning as a the as the algorithm implementer you know what compositions you have to pay attention to so and so forth so um I guess we're gonna have a guest lecture on on the broader aspects of machine learning especially robustness and fairness um I guess machine learning has a lot of societal impact especially because machine learning Now is working you can really use it you know in practice and it will create some kind of societal issues actually a lot of societal issues um and and these are things that we should pay attention to I'm not an expert in this area we're going to have a guest lecture James though who work a lot on this to talk about fairness and robustness of machine learning models okay I guess this is uh um all I want to say for today

Live Lecture Transcript
Stanford CS229 Machine Learning I Supervised learning setup, LMS I 2022 I Lecture 2

so hello uh welcome to 229 uh so we're starting a block of three lectures that I get the privilege of of spending some time with you and kind of walking you through the building blocks and Basics before I get into the plan for those three lectures I want to make sure we understand a couple of logistics so I I posted something on Ed that kind of explained why I was setting up lecture in the way I am you are not obligated to read that but if you're interested go ahead and read it super happy to take feedback and discuss any of that one of the things that I liked about the pandemic was that more people were asking questions during class and I think part of that was because people were you know using the anonymous feature on Zoom quite a bit and I and I wish we still had that we don't in this class for various reasons so what we're going to do instead is we're going to have this Ed thread that I just set up that says lecture two 330 in class question thread and feel free to fire away questions on there I may not take all them I reserve the right to skip them Tas May jump in and answer some um and I'll try to follow up on anything that's there but it's really helpful to me that that you ask questions and happy to talk about whatever you want uh really be relevant to the class is helpful but like pretty much whatever you want um second thing there are a couple of downloads that I put up before my lectures I put up two things one is a handwritten note of what I'm going to talk about which are the same notes that I use I modify them a little bit and then also a template in case you want to follow along again you don't need any of this stuff you can just sit watch it on video watch it here ask questions do whatever you want but it's just so that you know the material that's there and that you know things like data that I want to show you and look real I can cut and paste that in and you can have it in front of you while I go through it okay all right so that's the logistics I will use I'm going to try and use the iPad I like using the Whiteboard feel so this is a good compromise because it slows me down if I get excited I'll start talking all kinds of nonsense so this will focus me a little bit more on the class and you'll see how long I last all right so what we're going to do in this first three sections of the class first three lectures is kind of build up uh increasingly sophisticated machine learning models and your what you're going to see is that they are very very similar to a model that you probably already know and love which is linear regression if you don't know linear regression don't worry today's lecture is effectively going to be talking about linear regression with slightly fancier notation and you know some little bits around the algorithm but it's basically just fitting a line okay it's it's really hopefully going to be something that you've seen and you can grab onto and then what we'll do in the next lecture is we'll generalize this from regression which is the kind of traditional fitting align to classification now I have a couple of twists we choose our notation a little bit carefully and what that allows us to do is show that that way that we're looking at classification and we'll talk about what classification really is allows us to do a much larger class of models which are called these exponential family of models and they're going to kind of rear their head throughout the course so we're going to see a precise definition that allows us to have a huge number of statistical models and kind of treat them in one way so we don't have to understand the details of every little model we have an abstraction of how to find its parameters how to do inference on it let's get a prediction out of it and kind of understand it and kind of understand these algorithms I'll try to highlight for you as we go through there which of these pieces actually carry over to what I would call kind of modern or industrial machine learning feel free to ask questions effectively the way we solve these algorithms or what we solve these underlying optimization problems is exactly the way we run everything from how images are detected to how you know search works in various different corners of it to natural language processing to translation weirdly enough this abstraction kind of carries over for all of that and the underlying Workhorse algorithm which we'll see is called stochastic gradient descent and so we'll try and introduce it in that absolutely simplest setting okay and so that's the idea it's going to be building parallel structure for the next kind of three so linear regression classification and then we're going to go through this generalized exponential family and they will have a very parallel structure if you go back to the notes you'll be able to pull out like oh this is the solving part this is the model part and what we're going to do there all right then tangyu takes over teaches you a bunch of awesome stuff neural nets all the rest of that stuff kernels then I come back and teach you unsupervised and there again is a different structure there but it's very very similar and graphical models and the rest make it make an appearance there okay so today our plan is to get through first just some very basic definitions um we'll be a little bit pedantic there but that doesn't mean you shouldn't ask questions means if you don't understand something you should and I haven't done my job so just fire off a question in any form you like then we're going to talk about linear regression which as I said is is fitting a line except we'll be fitting High dimensional lines eventually so we're going to want to abstract that away we'll talk about batch and stochastic gradient descent which are two algorithms and machine learning as tangyu talked about we're not great with terminology this algorithm is called incremental gradient descent in the 60s it's been around forever our incremental gradient methods actually it wasn't even it's not even a descent method formally doesn't matter the point is these are old things that people have been using for a long time and weirdly enough it's what we use every day like it's as I said this is like a Workhorse algorithm that you're going to see and then I'll very briefly cover the normal equation because I think it's a curse on your homeworks um you know and it's like you know also gives you some practice with Vector derivative so you do need to know the vector derivatives stuff to make your life easier in this class you'll have to compute occasionally compute a gradient or compute a derivative and this is a place where you kind of know what the right answer is so when you compute these derivatives like you know it's an easy place to check yourself but I wouldn't say that like normal equations are like the most important thing you'll learn in this class it's just you know it's all you should know what they are it's not hard okay all right great so let's talk about supervised learning all right so this next section as I mentioned is going to be all supervised learning and it'll all follow kind of the same general schema right and what I mean is we're going to try and have some what we call prediction function and basically all that's going to be is a function H which will use this notation consistently that goes from some set X to some set y okay before defining this formally let me just give you a couple of examples so one idea is that X could be the set some set of images right so we can look at in images a bunch of images and we could ask does it contain a cat right that was actually like a very important machine learning problem at kind of one point in time people still work on that right you know what's the object that's in this image that would be a prediction right we are wise here would be a set of labels that say things like cat dog things like that all right it could also be text right so we could look at text here and we could ask questions you know that you know maybe we arguably should be better on in machine learning like is it hate speech all right right and so we ask here you know this x here these are all examples of data types that we want to work on and these are all labels or y's that we're talking about okay now we'll look at as tangyu showed in his lecture we'll look at house data now historically house data has been one of the most common machine learning and statistical uh tasks it's in like every stats 101 course so you may have seen this before I kind of hoped you have um and when we look through it we're gonna I'm gonna point out the real data that you can use to try this out in a competition like kaggle there's a kaggle where you can download house prices from Ames Iowa and try and guess how much they you know how much they should sell for things like that right people actually make money on that by the way right not everybody sometimes hard if you followed the news right Zillow tried to sell houses and estimate them and flip them and they lost a bunch of money Blackstone if you care about private Equity I managed to make money doing that right they bought houses and they were able to predict how much they were going to sell them at so this may be trivial as it seems um is there actually problems that people care about okay anyway so we need an abstraction so we have this X and we have this y we need something else to make this a supervised problem and we talked about it yesterday we're given a training set okay so what is a training set well formally it's just going to be a set of pairs this is just introducing notation you have an X1 and a y1 okay now comma all the way x n to y n all right all right now x i here is going to live in x it's summing coding of an image maybe it's the bits that are in the image that would be a reasonable encoding maybe it's RGB values that's in there if it's text maybe it's the ASCII characters or Unicode characters that are in there it's some bag of bits okay now we're later going to abstract this away and almost always work in a vector space we'll talk about where those Vector spaces come from but that that's kind of where the the data actually lives and y i is going to live in some set those are going to be our labels oops right so now our do given that information is we have to find a good age X to Y okay and we'll call often we call it h because it's a hypothesis all right all right now that notion of good is going to occupy a fair amount of what we worry about over the next couple of lectures what does it mean to be good right in some intuitive sense because I have these examples of x's and y's one reasonable thing I should expect is I I kind of get them more often right than random chance right that's like kind of a very basic idea of what would be good you show me an image it has a cat in it I get most of the cats right now you've used enough machine learning to know like we don't get it right all the time right and it's still useful so we'll have statistical Notions we'll try to get it right kind of uh you know on average now more advanced things like just recency biased because Tatsu was talking about it in the class before on the board you could also worry about how well you do on some groups versus other groups some groups you know you're predicting really well on but other groups have qualities and you're not predicting as well on them you could worry about that and say I want to do my prediction I only care about is being you know as well as I do on any one of these predefined groups okay so you could have multiple Notions of good we're going to stick with the simplest and basic which is like how accurate am I at the task in this okay but this mathematical framework can accommodate all of those like when you actually write it down the tweaks that I just mentioned to come up with those uh different what they're called loss functions is really really kind of straightforward mathematically they'll kind of go through the same thing okay so all I want you to take away from this is we have a training set that's what's provided to us these y eyes are going to be supervision they're in some set our goal will be to find a good h among all the possible functions and by the way the class of functions from like one space to another is enormous right so we're going to have to restrict that in some way and that's kind of the setup for supervised learning okay right now this here we will often refer to as the training set or the training data that's there and what we're really interested by the way in which is probably a little bit counterintuitive the first time you hear it is we're not doing strictly machine Learners we're not doing strictly what's called interpolation we're not just trying to predict back on the X and Y pairs that we have we're going to try and worry about how well we're going to do on a new X and a new y so why does that make sense imagine someone shows up with an image odds of that like you know they just took it with their phone right my phone is just littered with pictures of my daughters okay so if I take a new picture of my daughter and probably the label should be the same as the last thousand pictures I took but it's going to look a little different right so when I show that that picture I don't care how well I did on the last picture that I took over I care how well I did on this picture right on that on those X and Y Pairs and that's a little bit weird and that means that implicitly what we're going to assume here is that these x's and y's you should think about is drawn from a large population of images right that are out there and we want to do not we were sampling some piece of it and we want to do well on those images that are going to come in the future that's why we think about it as a prediction so it may not be great to just return the label of every X and Y we've ever seen right we have to in some way kind of generalize is the technical term to those new images okay all right so the reason we call this a prediction is we care about new X's that are not in our training set right now if you look at that and you're mathematically minded you're like how the heck did you say anything about that and hopefully you got a clue there if you don't if it doesn't make sense yet don't worry we're going to make some assumption like we randomly sampled from all of the images and how well do I do on another randomly chosed image okay that's what we're going to do in some way the set you train on though better be like the set that you evaluate on that you take your predictions on or you're out of luck if you train your model on pictures of my daughter and ask to know about cars I don't know how it's going to do right so there's clearly some link here okay now weirdly enough although I say that one of the big trends in machine learning that's going on right now in fact of course that I co-taught with Tatsu and Percy last quarter was about these large models that we just trained to predict kind of everything that's on the web and they seem to do pretty well on things okay so just want to highlight like it's there's a really strange notion of good you spend your whole life trying to think what good is if you're a machine learner okay a couple more things as I said I'm just going to go off on tangents if no one stops me all right so if Y is discrete this is just terminology so it's a discrete space we think about this as classification okay that's the terminology you could think the simplest version is yes or no does it contain a cat yes or no binary classification you could also have a bunch of different classes is it a car a plane a truck what model of car is it those are classifications they're enumerated sets the other thing which you're probably familiar with from you know calculus and we'll talk a little bit about today is when Y is continuous and this is called regression so this is an example of something that's discrete this cat yeah and the house price this is going to be an example of regression and that's what we're going to look at today in lecture three we switch and we start to look at classification which has some subtle differences okay awesome all right let's look at some data any questions about the setup or or kind of higher level questions about what it is what goes on here all right sounds good okay so let's look at some some real data here I'll try and get it all on the screen so I'm going to look at this house price data as I mentioned this is the Ames data set which follows a very famous data set just for historical reasons of Boston house prices that you can go look at and download you can download in one line into pandas if you want happy to put uh you know information online about how to do that this is real data of real houses and Ames and so what I'm showing here is like these are their real IDs I just randomly selected some to kind of make the picture pretty right just be honest and then here's their sale price right so this is their actual sale price and the data and this is their lot area this is kind of like some notion of square feet that's actually present this data set I think has something like 93 or columns inside of it I've just selected a small set of them we'll come back to that in a second now one of the things that I did here is like the first thing you should do when you're encountering a new set of data and I cannot emphasize this enough is look at it the number of times that like people especially engineers in Industry like take their data and like start running fancy stuff on it I'm like well did you did you look I still remember when I was running a machine learning team at an unnamed large company and they're like why are you sitting in the cafe just like labeling data just like looking at data sets for like days it's like I don't know what's going on I want to figure out what's actually what people are actually doing on this data set and it's it's really important okay so when you're doing your projects like first plot it so here's a plot right x-axis square feet y-axis price and clearly there's some like General upward trajectory Trend here we're going to be more precise about that in the next slide right you get bigger houses they cost maybe as you can think about it you're like that's not quite true like if it's in a really desirable neighborhood um like you know costs more and if it's in a less desirable neighborhood maybe it costs less so they're clearly other factors those are gonna be called features in a minute but this is our first model okay so let's look at one other feature so we can also look at the number of bedrooms right so you see here a plot these are categorical values that's why I put them in there I mean they're kind of continuous in some way you can still treat them as numbers so that's fine you see there's some spread you know among three bedrooms and among four bedrooms and the price is the waxes so what do we want here going back up for a second what do we want actually we want to get a function what's our hypothesis go from it goes from lot area and it predicts price okay that's just notation okay this is what we're after okay so you show me this data and my goal is to produce some age okay now they talked about there are lots of functions that could take in you know a lot areas and return sale prices it could scramble it it could do whatever it wanted it could you know go look up from an oracle whatever I wanted to do there are tons and tons of functions we're going to look at a simple restricted class of functions in just a second okay but I just want to put that in your hand like this is actually a pretty hard problem so we need some some representation for H okay so how do we represent that age now we're going to look at a class of models which is called linear although if you're a stickler you'll realize right away that they're affine I'll explain why I allow myself to cheat like that in a second okay so here's a here's a model that we could use okay okay so the idea here is you give me the variable right X1 which in this case would be like the square footage or of whatever you have and then I will multiply it by some Theta and this Theta is going to be a weight we'll call it or a parameter of the model and this is how I'm going to form my regression okay looks like a line right so far so good right now let's see if I can show you a line there's a line that does it okay okay this is that's basically that line through the data that we just looked at okay now I want to actually come one in one more second how does this actually map onto this oops scroll down sorry for the bad scrolling here I'm going to go to zero remember my H is going to look like x equals Theta 0 plus Theta 1 X1 well what does it look like just so you make sure the picture is clear this here is Theta 0 right it's where I am it's a response at zero and then this gives me the slope right this is the of slope Theta 1. okay and then when I go to predict what do I do I grab a point let's grab this one I project its value onto the X and this is where I predict its price would be right this is the price of this one does that make sense okay all right awesome okay so this looks like a relatively simple model but if you look at it like you know at this scale not so bad honestly right there's some kind of linear Trend there there's some errors or what we call residuals in a second we'll try and minimize those these errors but this is this is like our first predictive model okay and as I said it's something that you're hopefully quite familiar with just in kind of fancier notation for the moment all right awesome okay so now I'm going to go sorry for the skipping I'm going to go and say okay how do we generalize this right so imagine we had our data set we had X1 X2 so on and we have a bunch of features and I'm going to use my features for my notes but hopefully this doesn't cause you any panic I have size I have bedroom lot size and as I mentioned in the actual real data set there's like 80 90 of these things and have price okay okay and remember price is my Target this is my why and these are my x's so this is uh you know I'm just going to put numbers here don't worry about them I don't know why I wrote These in my notes but these are the ones I used just for the sake of consistency so write these 45k 30k 400 900 doesn't matter too much okay the thing that I that I care about is that this is my notation for the first data point in the second data point and this is X11 this is X12 this is the second feature okay right now I called this a linear model right but if you're a stickler and you took a bunch of things you're like no it's an affine model you have this you know Theta 0 hanging out there the way that we get around that is we're going to assume that Theta 0 for every model x0 for every model is identically one okay so that's just a convention don't stub your toe on it that is x i zero equals one and I claim you should convince yourself for one second that means that what is linear in this new set of features is my old affine models right and I just put I'm just putting a one here every place okay all right that allows me to just simplify my notation okay so what's my what's what's the model the class of models that I'm looking at here well they're linear models again with that terminology and they're going to look at Theta zero times you know x0 which we know is one plus Theta 1 times X1 Plus data and I'm going to call it D times XD okay and this equals sum J goes from zero to D Theta J times x j all right and remember I'm just going to write it again x0 equals one and NB means you know no well none okay all right now this allows me now I have a very high dimensional problem now High Dimensions don't work like low Dimensions I won't go into a whole thing about it but High dimensions are very fun and interesting spaces okay you can you can build really interesting machine learning models by taking your data doing what's called embedding it and then training a linear model on top and that actually in some areas is actually state of the art of what we know how to do so those models have potentially you know hundreds of features that are underneath the covers for us these features right now are going to be all human interpretable they're going to come from the table so when you give me a the row X1 I fill in the value this value here with 2104 I fill in this you know the X2 value and so on and as I go okay so I just fill in the values as I go that's how I form my prediction okay a little bit more notation right now if you don't remember I'm just going to introduce Vector notation here these are column vectors they're going to look like this and this is just going to save me time and space and you know fill the things okay X1 is going to be a vector 2. with X11 X2 X12 so on oop sorry about that I wanted to start at zero x 1 0 x 1 1 and so on and remember this thing is one which we've said many times and this is whatever the value is up there 2104 okay in general this is going to be the size feature the bedrooms feature and so on clear enough right these are the parameters and these are the features all right so why be so pedantic about this piece it's because we're going to use this in several different guises these parameters are going to mean different things as we change the hypothesis function over time and we just want to make sure the mapping is clear so just make sure the mapping is super crystal clear in your head of how I take a data point that looks like this and map it into a feature Vector that looks like that that's all that I care that you get out of this and then we have some different vectors and y i is going to be the price in our example is price okay now recall this notion wasn't we didn't pick this by accident this was a training example this pair x i y i is a training example this is the ice training example right just the iPhone and the set okay so far so good now I'm going to create a matrix here capital X that's going to have one row for every example oops so on X so there are n of those characters by my notation and so where does this Matrix live well there are n rows and recall because of my convention that I added a extra Dimension which I always made one it's D plus one and I'm just highlighting this and being pedanta because I don't want it to bite you when you realize like why they have D plus 1 where did it come from it's the one and this is someone who say this you taught this course many times someone's going to get bitten by it I'll say it many times okay it's uncomfortable when it happens okay so this is now I can think about my training data as a matrix awesome okay so now we have a bunch of notation I've basically bored you to death with a hundred different ways to write down your data set but I haven't answered the question that we actually cared about which is how do I find something that's good right how do I find an example of something that's good all right so now let's look at here so why do we think this line is good you remember this from how you fit it you think it's good because it makes small errors right like if it were all lying on the line right on top of the line the distance from any point to the line would be zero and we think the line was pretty good if we could kind of minimize those errors okay and this is the error this is the residual now for computational reasons and historical reasons we'll look at the squares of those residuals in just a second okay don't worry too much about that you can do everything I'm telling you with the absolute value of the things right you don't want to do the signed value of them because what does a negative error mean right you should pay a penalty is the intuition whenever you make an error all right so let's look at this all right so we're going to look at our H and I'm now going to write it sub Theta J goes from 0 to D Theta J of x j okay so now picking a good model I can actually make some sense for what do I want well I want somehow that h of theta X is approximately equal to the Y when X and Y are paired right if X and Y come from a new example you show me a new image it's a kazak cat or not that label may be opaque to me but it exists I want my prediction to be close to that y on average or for house prices you give me a new house I predict its price is as close as possible I may not get the exact dollar but it should be penalized a lot if I'm off by a million dollars maybe but not if I'm off by ten dollars right that's kind of the the intuition here right so how do I write that down the idea is I'm going to look at this function J which we're going to come to a couple of different times and it's this is that one half is just normalization I'm going to look at my data and I'm going to say take my prediction on the ice element y i and square it okay now this is our first example of a cost function and I wrote it in a really weird way but I want to come back to why I'm doing it this way okay this is also called least Square so you've probably seen this a bunch of times and that's okay and if not don't worry we'll go through it there's nothing there's nothing mysterious okay so let's unpack it so this thing here is the prediction it says you give me a point x i what's my prediction on x i some Y and that says it should be close to whatever the training set said why I was remember what we're given we're given x i and y i pairs that are together image cat house information all of its description and the price we should be close okay we're penalized more for errors that are far away I could give you a big song and dance about why this is appropriate and indeed there are lots of statistical song and dances about it but really we're doing it because it's easy to compute everything that I'm going to do you just want something that's kind of sensible right like you should be penalized more the more wrong your guess is Right roughly speaking in this example okay now what does it mean to pick a good model well our model is now determined solely by those those Theta J's right if we knew the Theta J is our model would be completely determined that was the trick I pulled on you and I said oh we're gonna how are we going to represent our hypothesis we're going to represent it in this class that means now we reduce from all the crazy functions that you could have ever dreamed up any computer program that you could ever have written that was functional to the class of functions that are represented by these weights the wild thing is there's a lot of function you can represent that way okay and we'll see that over the over the course of the class okay especially when you start to get really high Dimensions Okay cool so which one am I going to pick yeah please do constantly awesome question yeah very Advanced question so the question is hey you wrote this one half there it seems unnecessarily and potentially confusing why would you pay the cost to do it and the reason is when I take the derivative in a minute it will cancel out make my life easier okay but there's no and the other point that you made is and I love the way you said it this is exactly right we don't care I wouldn't call it that we care only about the gradient but we only care about the minimizer for the loss function so if your loss function costs 10 or cost 100 doesn't matter what you care about is what Theta minimizes it you got that concept exactly right so I hope that makes sense when we're setting up the cost function in some ways sometimes we give it an interpretation almost a debug it to understand what it's doing but really all we care about is what is the Theta when we minimize over all the thetas of J Theta this is what we're solving for right so we we basically want to solve this J Theta now as we'll see in a second for linear functions we can do this for more complicated sets of functions it's not always clear that they're even you know it exists a minimizer that we can that we can reasonably find okay right so there could be these wild functions that take bumps and everything so I'll draw one for you in a minute right when we talk about solving it but for linear functions what's amazing and why we teach the normal things you can prove what H Theta is in this example wonderful Point okay but that's the central thing we're going to set up these costs so that we get a model out we've restricted the class of what we're looking at to something that's relatively small where we can fit the parameters then we just have to minimize okay awesome right this is this this is what I mean by optimization by the way just solving this equation okay I haven't told you how we're going to solve it yet but hopefully this is good now just for leading a little bit ahead for the and also to kind of stall in case anyone wants to ask a question what we're eventually going to do is we're going to replace this J with increasingly complicated potentially functions that we're going to look at one for classification one for other statistical models but we're going to do almost everything that comes after this part to all of those models so once we kind of get it in this form where it's like a prediction and some penalty for how how poorly it's doing we may use different cost functions everything that comes next we'll be able to do for all of them okay that's why we set up all this kind of kind of elaborate notation for like fitting a line it is still by the way boggles my mind how much machine learning you can do by just fitting lines like just higher and higher dimensional lines but we can talk about that some other time okay awesome okay all right so how are we going to solve this now there are many ways to solve this if you've taken a linear algebra course you're like oh I compute the normal equations and then I'm done least Square so your Matlab or numpy person you're like oh I do you know least Square solve or whatever it is backslash whatever you want to do we're going to solve it in a way that sets us up for the rest of machine learning because machine learning will deal in functions that aren't quite as nice as linear regression quite a bit and in fact the trend has been when I like first got into machine learning and Antiquity we were all about what were called convex or bowl shaped functions just roughly we were really obsessed were we getting the right Theta right we're like statisticians like at Large Scale can we get the right Theta is there one individual Theta modern machine learning done care we don't even know if we get the right answer we don't even know how there's a paper I was reading from deepmind this morning that was like oh you should run your models longer no one noticed right how do we not know when to run the models longer we don't that's the world we live in so how does this work so imagine we want to we want to this is our cost function okay now just as an aside I want to say the linear function doesn't look like that so don't think about the linear function looks nice and bowl shaped Okay the reason that's important as I was just saying is a local minimum this is a local minimum so is this so is this roughly speaking is global when you're convex that doesn't make sense to you don't worry about it okay four convex we'll come back to that point later in the course but I just want to say like don't think of this function I'm drawing here as what happens with least squares we're just optimizing A J for right now okay all right so how are we going to do it we're going to use a very simple algorithm we're going to start with a guess which is going to be Theta 0. how did we pick this gas felt good randomly set it to zero all reasonable things to do their entire machine learning papers by the way written I've even written some which I'm not sure if I should be embarrassed or proud of that talk about how you initialize various different parts of the model okay for us though it won't matter for our least squares and some of the other models we're studying because we'll be able to get to the right solution all right so now imagine for the moment I found you a model I found your initial model well it's clearly from looking around imagine I'm just looking I'm the point and I'm looking clearly I can go down from here right so the natural greedy heuristic is compute the gradient what does the gradient look like here it looks like this oops I can make it do this fancier okay you see that good I compute the gradient and then I I walk downhill sound good right tells me to go downhill from here right I'm at whatever shape I'm at this gradient will also tell me what to do now there's some problems right just as an aside what if I were right here oh it doesn't tell me what to do but don't worry about that it's a local maximum I'd be toast but here tells me to go downhill okay now once I go downhill how far do I go again feels good I pick a value it's called a step size so my next value is going to look like this t plus 1 is going to be defined to be 5T minus some Alpha Theta J Theta T now my notation is a little bit weird here imagine it's one dimensional for the second okay compute the gradient go in the opposite direction that's all that's going on this thing here is called a learning rate embarrassingly I think I've won awards for papers that are about learning rights but they are not very well set so you just kind of pick a value for deep learning people now have all kinds of what they call adaptive optimizers if you look in the literature about how to set these values for you um you don't want to set it too big or too small there is a theory about how to do it for linear things but don't worry for you you just kind of pick a value okay just imagine like what could go wrong what happens if you pick it too big well then you kind of shoot off over here right you pick it too small then you make little bumps like this right you don't make enough progress it's not too hard to think about what what should happen here and then what happens well I get a new point this is my Theta 1 and as suggestively done here I iterate I compute the gradient and I bounce down and then hopefully I get closer oh sorry that is just a this is my notation uh for the gradient with respect to Theta this is a partial derivative with respect to Theta right so imagine it's one dimensional and I'm just setting up for the fact that I'm going to use multiple Dimensions it's literally just a gradient with respect to Theta the derivative in this case now now what I'll do is I'll compute that J for all zero to D characters and that gives me my high dimensional rule okay please uh yeah so right now I've just shown it I've just shown J as an abstract function I haven't decomposed it as a sum that's a great Point let's come back to that in one minute exactly what happens when we have a data point it's going to be my next next line other questions okay is it clear so I did actually a fair amount of work there and tricked you just so you're clear I went from one dimension to D plus one Dimensions by just changing the sub index and did them all by themselves so make sure that that sits okay with you right please yeah so how can we understand it on a graph what do you mean by on a graph like on this graph in particular awesome yeah yeah so just imagine that so the one-dimensional case carries what you need to deal with so you're in a particular basis right meaning you have like Theta 1 Theta 2. so imagine I'm standing in two dimensional space I can look down one axis and then I have a one-dimensional function then I have a gradient there that gives me the vector in this direction then imagine I turn 90 degrees orthogonally I look 90 degrees there I get another one dimensional function I compute its gradient now the gradient is actually if you look at the derivative it's actually the all those vectors put together one after the other in component but that's exactly right yeah so yeah but you're asking exactly the right questions right so just picture it as the tangent to the curve if that helps you in high Dimensions if not don't wonderful questions okay so what do I hope that you understand here's some rule you have the intuition that what it's going to do is it's going to bounce slowly downhill okay now if you start to think about high dimensions and I think this is why the question came starts to get a little weird what does it mean in high Dimensions you can imagine like something that looks like a saddle if you know like a saddle then you're like oh gosh what's going to happen when I get to the top of the saddle clearly I can go off the sides and get a little bit smaller right that would be good maybe it goes down and stops but I can get stuck on the top of the saddle too and weirdly enough it's called the saddle point don't don't worry okay sound good right we're not worrying about convergence right notice this algorithm has a very clear error mode here we found what looks like the global minimum but what if we started here we would go bounce bounce bounce and we'd find this one now how do you stop this algorithm you stop the algorithm when it's stop when this update becomes too small okay and you set that tolerance maybe you set it to What's called the machine Precision like 10 to the minus 6 16 where you set it to you know 10 to the minus eight or you want a quick solution you know 10 to the minus three or something the point is no matter what you do you're going to get stuck here with a with a descent method because it's going to go downhill and get stuck here and you're going to miss this much better solution that won't happen for linear regression we won't talk about why at this exact moment we can prove it in a little bit but for things that are bowl shaped every local minimum is a global uh minimum then we're in good shape that's why we cared so much about these things 10 12 years ago we care about them you know occasionally now less than we used to okay all right so let's compute some of those some of some of those derivatives getting back to the earlier asked question which was hey what does this mean for a sum okay all right so remember RJ had a very specular form so we're going to compute the partial derivative with respect to some sub J of J Theta okay so this is the the derivative here oops the derivative with respect to the jth component okay now we take the sum I goes from 1 to n I'm going to put the one-half inside because I can and then this is linear and we'll come back to what that means in one second okay I just did a little bit of work here not much I just rewrote the definition of j which is this sum and then I took the the partial derivative and I pushed it inside because it's linear okay we should know that gradients are linear okay now when I do that I get something actually fairly intuitive and this makes my uh you know heart sing times partial derivative Theta J of x okay now this is I cancel the 2 with the one half back to the question about kind of the cooking show preparation and that is standard by the way now look what I have here which is kind of nice this thing is basically the error but it's signed tells me which way I'm making a mistake you know kind of too high or too low right that's all that thing is this is the the misprediction or the error okay now I have the derivative with respect to the underlying function class now why did I bother to write it out this way clearly I could have skipped the step of doing this and jumped right to the end but this is this is going to be general for almost all the models we care about that's why I did this okay so what is it in a specific situation we'll recall h of theta of X was equal to Theta 0 x 0 plus Theta 1 x 1 plus you know Theta 2 x 2 plus Computing the derivative of this pretty easy it's just oops Theta j h Theta of X is x j right please superscript over X on the right here on the right here yes oh this should have a superscript oh I'm so sorry great catch this is at that data point wonderful catch thank you I generalizable because your H is normal equation or some trigonometry it could be whatever you want all I care about is this is the error times the derivative with respect to that underlying model this is a very basic version of like what looks like a chain kind of rule and we're going to use that like nobody's business so if you didn't know the chain rule before this class you will definitely know it by the end because we use it Non-Stop but yeah this is just set up for that that's why it's generalizable it's the error which is totally generalizable for any model that has to do with prediction times how you compute the derivative like what's the change of the underlying model we'll be able to generalize that and in this case it's just XJ all right so now right getting back to this what is our whole rule it looks like this Theta J Theta J T minus Alpha sum over all the data answering the earlier question at this point we're doing what's called batch gradient which we'll come back to in one second minus y i times x i j now notice I'm going to try and do some highlighting here I hope this is okay for people to see and I apologize if you're colorblind and this doesn't doesn't help you too much but these are the same okay hopefully these are distinguishable colors these J's and then the i's are the other index that's going on and these are the data points themselves okay so I look at every data point and I'm doing the jth component of each one right now by the magic of vector notation here's what I can do I just write this as this H Theta x i this doesn't change this is a vector equation okay so this is basically looping over all the J indices at once if you're unfamiliar with Vector notations one of the reasons I'm doing this quickly is I will do it second hand throughout the course it's not deep it's not like it requires a lot of stuff just requires a little bit of reps kind of repeat on that please same brand for a wonderful question so Alpha you will typically set for the for an iteration right when you take a step you typically you can change it across steps so one thing is here I've said Alpha does not depend on uh on T the iteration step but in general it usually does you usually Decay The Learning rate over time so that's just what's done in practice that's done for really good things what you don't typically do is have Alpha depend on the data points itself because then it's kind of almost functioning like a free parameter at least in classical machine learning but in both optimizers one of which was invented by our own John duchy and other folks you actually do change the alphas for every different coordinate which was you know I think his first paper was at a grad and then out of Delta so people do things like that that are a little bit more sophisticated and why they do those I'm happy to explain offline but right now just think of alpha as a constant like it's small enough that it's not going to lead you too far astray like if it were too big you jump too far and maybe you could do a little bit better but you know maybe not too much in fact there's a very very basic rule which is called with gradient descent rule is is actually very widely used very very widely used with just one alpha wonderful question and those are the right questions to ask like how does this parameter depend on what's around it start thinking like that as you go through the course that's really really helpful to understand okay so far so good so at this point we know how to fit a line which doesn't feel like a huge accomplishment maybe but I think it's pretty cool um and we fit it in this kind of obfuscated General way that's going to allow us to do more models I claim but I'll verify that in two classes this vector equation here is just showing you like all the things that we computed this is specific to the earlier point to the line right this is this gradient here is this guy those are the same that's why this model popped out we'll come back to that in a minute okay now a topic that is practically quite important for machine learning is and it was hinted at earlier is and I'll copy this equation is what do we you know do in practice so one thing that we may not like about this equation is this thing is huge in modern machine learning we'll often look at data sets that have millions or billions of points right well it's not uncommon to run models where you're like every sentence that has been emitted on the web in the last 10 years is a training example or every token right every every word and would be just enormous right at that point it'd just be a huge thing so even doing one pass over your data is potentially too much okay that's a really extreme and crazy version of that uh that's a really extreme and crazy version of that but you can also Imagine situations where you're looking at hundreds or thousands of images and you potentially want to look at fewer so we'll come to how we do that in a second sorry yeah oh it's t and t plus one it's the it's these are the steps remember we started at Theta zero so superscript uh zero was our initial guess here and then we moved from one to two to three to four and so this is just the recursive rule that takes you from Theta T to Theta t plus one e is just whatever exactly so you just imagine it as a it's a it's a it's a you know kind of recursive way to specify where at particular T and here's how we evolve to t plus one exactly right you got it perfectly exactly right so Theta T when we go back to here oops sorry I hope that's not dizzy and I always throw a way to skip without making you sick is this Vector it's just a particular instantiation of those vectors one for every of the D plus one components please stuff yeah so we will take steps as I said until we converge typically or we can take a fixed number of steps I'm eliding that because for this particular problem I can kind of give you a rule of thumb I can point you out a paper that tells you how to set Alpha in general for machine learning as I was kind of very obliquely referring to we don't actually know uh how to tell that we've converged and part of the reason is when if you knew your model was this nice bowl shaped then you could actually prove that the closer you get to the optimum the smaller your gradient is getting and you can predict kind of how far away you're going to be basic for A Nice Class of functions for nastier functions and the ones that we're going to care about more you can't do that so it doesn't make sense to say that you found the right answer and so I don't emphasize that for these models I can give you a beautiful story happy to type it up online and tell you but but in general for machine learning honestly we just like run it till it feels good like oh the curve stopped it stopped getting better and that was this deep mine paper that said hey for these really large 280 billion parameter models so their their Theta has 280 billion parameters in it they're like we didn't run it long enough if we kept running it it was better and like everyone who works in machine learning for long enough in the last five years has a situation where they forgot they were training a model hopefully like you're not paying for it on you know AWS or gcp or something and then you come back like a week later and it's doing better than you thought and that is a very strange situation so I don't have a great rule for this for your projects it will be clearer I'm telling you the real stuff though [Music] so we will only use it in the forward direction of going T to t plus one but you know you could imagine that it's reversible if you wanted oh wonderful question yeah yeah so in the sense that like if you shoot past let's go back here so if you're here and you shoot past your step is kind of too big for the gradient you kind of trust it too much then in the next iteration the gradient will point in this direction right and so you'll step back so it will actually have kind of this ping pong and that's actually a you actually want that to happen it turns out the optimal rate I mean I can bore you with this for days the optimal rate is actually when you're doing that skipping for for whatever reason yeah but it's more intuitive for people to roll down the hill yeah wonderful point you got it exactly right please uh so is it possible for the update to be zero even if H Theta of x i is not necessarily yeah so um so it's not possible for it to be exactly zero everywhere but it's possible to have gradients that are not giving you any information wonderful question absolutely wonderful question it's because it's a linear system right so that's not full rank for the linear algebra nerds wonderful question say you have like um or something right but you flip it so Theta zero is equal to zero but on the other side when you only get the local minimum over there and not the actual like exactly right yeah and that's what I'm saying like uh we used to worry about that quite a bit now we just say it's good I wish I could tell you something better than that but we'll get into why that's true but yeah when your function is in a good class and good here formally means like convex and bounded in some way then you will provably get to the right solution we'll talk about those conditions later I'm just the reason I de-emphasize them now is because modern machine learning actually works on functions that look like this not on the other class of functions and so that's less important uh for students and then you know you would rightly say like you told me all this stuff I memorized all these conditions and then I got into the workforce I'm like none of them worked and no one uses them like yeah that's true but it's you're exactly right and so people worry about initialization where do you start so that you're kind of guaranteed to get a good model in fact there were a couple of awesome Theory results and one from my group one from 10 news that said for certain class of these nasty non-convex models if you initialize in a particular way you would be guaranteed to get the right answer actually I'll show you one in week 11 a simple version of that where if you initialize cleverly there's not a unique answer but you'll get the right one every time yeah or sorry class 11 not week 11. yeah yeah people try random initialization the problem is this model the trend is for models to be really expensive so you run huge models so any one run could cost a couple million dollars like I was looking at the Amazon's gpt3 service they cost like six million dollars a month to run so like you know do you want to try to run it multiple times like if you got money go ahead but you kind of want to try and do other tricks people used to do a lot more random restarting now we've kind of it's really sad to say this is the state but we've kind of absolved like flexonomies like like if you train these models you kind of know uh you know what are the right parameters and what is everybody else using and not everyone tries and explores everything let alone how long you tune it you know what optimizers you use we kind of all use the same stuff um but we don't have great formal justification for it maybe I'm exposing too much it's not as bad as it sounds it there's like there actually are principles in this area I'm just like telling you the plates that are broken because they're more interesting to me and we're going to come back to that so the the solution is like do I wanna there's a phenomenon that a lot of people know about in machine learning which is if I take my uh my model and I exactly fit my training data maybe it won't generalize well like it'll be it'll fit to some error some noise in the data and this is roughly overfitting we cover that in lecture 10. in lecture 10 at least when I taught it last I also talked about something which is in modern machine learning we realized that actually sometimes that concern is overstated for some models there's a wonderful paper by Misha Belkin that said you can actually interpolate perfectly fit your data and optimally generalize for some classes and models so that trade-off isn't as clear for modern models as it was for old models may I just stop telling you about this stuff but yes in general overfitting is a problem you can overfit a model and believe your training data too much but it's this area is fascinating I can obviously rant about it for for weeks so wonderful questions yeah yeah this is absolutely great okay so what do I want to tell you so I don't want to tell you normal equations I thought that was pretty clear from the from the beginning so you can read about those if you want I'll type up notes Andrew's notes are great on this point but I do want to tell you this one little bit with my last couple of minutes about batch versus stochastic mini batch because this is it actually is is relevant and useful okay so when we last left off we were looking at this equation and when you notice this problem that n was really big and I just hopefully told you like n is really big and so is D the number of parameters is really big so this is expensive I wouldn't want to look at all of my training Data before I took my first step because probably my initial guess is not that good that's why I'm training a model like if my if randomly initializing the model which is something people try to do gave me good predictions I just used that so obviously I want to take as many steps as I can so here's what I'll do I use mini batches so what does mini batching do okay I won't get too formal but basically what I'll do is I'll select sum B let's say at random okay I'm being vague here what random means I wrote a bunch of papers about this you can either pick uh you know randomly select them or you can Shuffle the order and in conventional machine learning we Shuffle the order for a variety of reasons and then I pick B items so B is going to be much smaller than n okay all right and then I update I'll call it I'm going to call it this because this made me make it more clear I equals one and or actually I'm going to write it a little bit Strangely I apologize for this notation notation is better in my notes but I want to write it this way because it's easier to say x i y i that makes it more clear what's going on I hope okay what's going on so I select a bunch of indexes B and then I just compute my estimate of the gradient over them okay I could even pick B to be size one just pick a single point if someone was alluding to earlier and take a step now what are the obvious trade-offs here on one hand if I pick a step that step is really fast right if I pick a single element it's super fast to compute relative to looking at the entire data set but it's going to be noisy it's going to have low quality I may not have enough information to step in the direction I want to go on the other hand if I look at the whole data set it's going to be super accurate about what the gradient is in fact I'll compute it exactly up to numerical issues but it's super slow now what people do is they tend to pick batches that are on the smaller side right and you pick them kind of as big as you can tolerate and I won't go into the reasons for this underlying Hardware happy to answer questions about it but basically you pick batches that are kind of as many as you can get for free Modern Hardware Works kind of in parallel so you'll grab and look at like 128 examples there's not much you know more expensive than looking at one okay on a modern kind of platform now I'm using these noisy kinds of proxies and you may think am I still guaranteed to converge and the answer is effectively yes and under really really uh harsh conditions in fact yeah I'm very proud of something that my first PhD student I and and collaborators Ben Rector and Steve Wright wrote about this paper called Hog Wild which is very stupid has an exclamation point but also got a 10-year test of time award for saying that you can basically run these things in the craziest possible ways and they still converge these kind of stochastic sampling regimes okay I won't go into details about that my point is like this thing is actually fairly robust this kind of take a bunch of error estimates and step them and in fact almost all modern machine learning is geared towards what's called mini batching if you download pytorch or jacks or tensorflow or whatever you're using odds are it has native support to give you mini batches okay and that is basically just taking in oops taking an estimate this piece here and using that noisy estimate and why might that make sense well imagine your data set contains a bunch of near copies if your data set contained all copies then you would just be reading the same example and getting no information right If instead you are sampling that same example you would go you know potentially unboundedly faster and if you think about like what we're looking at when I told you images like the images on my phone for my daughter there are a lot of pictures of my daughters a lot okay I'm a regular dad I take lots of pictures so that means there's a lot of density and so machine learning operates in these regimes where you have huge dense repeated amounts of data okay all right so this is going to come back we're going to see this next time we're going to see it in particular when we start to look at various different um um loss functions we're going to generalize How We Do prediction to classification next time and then to a huge class of statistical models called exponential family models to go back to the top I skipped just to make sure you know what's here and what I skipped we went through the basic definitions we saw how to fit a line we went through batch and stochastic gradient Descent of how to solve the underlying model we set up a bunch of notation this is going to be one of the drier classes where I'm just like writing out all the bits of notation and we saw how to solve them those will all carry over to our next brand of models the normal equations if you run into problems blame me I'm happy to take a look through them they're relatively straightforward and the notes are pretty good but I'll look at Ed if you run into any problems there and happy to answer questions with that thank you so much time for your time and tension and I hope to see some of you on Monday

Live Lecture Transcript
Stanford CS229 I Weighted Least Squares, Logistic regression, Newton's Method I 2022 I Lecture 3

hello so welcome to lecture three this is going to be about classification and regression this moves us from our first task which we were doing last time which was It was kind of regression how we fit a line into a class that into a task that will look really really similar at first but we'll have a couple of subtle differences and we'll go through that which is classification remember we talked about classification was for discrete objects like is it what's the animal on this photo is it a cat a pig a horse something like that those are the types of problems that are pretty prevalent in machine learning and so we'll talk through kind of those basic issues today what we're going to do though is we're first going to start with this probabilistic view of linear regression and the reason we're going to do this is we're going to walk through again in that sitting where it's hopefully relatively familiar what's going on how we give a generative model is the the term for it for this underlying kind of optimization class for linear regression so we're going to interpret it probabilistically and that interpretation we're going to be able to use for classification and then again on Wednesday for a much richer class of models which are all these exponential family models okay and I will assert at a high level like to try and keep in your head these things all look the same we're trying to get to this an abstraction that lets us solve them do inference with them and kind of Reason about them in a similar way so this is one key building block so we'll start with that probabilistic view of linear regression okay then we're going to talk about classification and at first blush classification is going to look just like something we could solve with linear regression so I just want to make sure it's really clear in your mind when we use classification when we use linear regression and kind of what the little problems are challenges are as you go through actually doing that then we're going to introduce the Workhorse of machine learning logistic regression this is something that you know I probably use every day in some form or another it has different names and deep learning now and the way people use it sometimes called like the linear layer and soft max if you're a deep learning Aficionado don't don't worry about it but this is the kind of the standard Workhorse and we can say a ton about how linear how logistic regression works and it was not invented by Machine learning people this is a an old and classical algorithm that our statistical friends invented we use it in slightly different ways than maybe they originally intended and I can get into those in a little bit now as I mentioned there's going to be parallel structures so we're going to talk about logistic regression we're going to talk about for why not linguistic regression I mean sorry linear regression then we'll talk about logistic regression which is confusingly enough a classification algorithm although it says regression in there don't blame us blame the stats people and then once we do that we're going to parallel exactly as we did in the last lecture and talk about how to solve it okay and when we solve it you're going to be introduced to a method called Newton's method which maybe you've seen if you took a kind of a stats course at some point or a calculus course and we'll reintroduce a way to solve it and Newton's method when it's applicable is really really fast meaning it converges very quickly but each step of that algorithm we'll see is quite expensive and so it's not really appropriate for a lot of the places that machine learning people care to use it okay so the messages from this lecture if you get is kind of what is classification why does it differ from regression what is the Workhorse model and logistic regression and then a method to solve it and then we're going to come back at the end and kind of compare and contrast the different ways that people solve these different things right as last time there is a thread that started online if you feel more comfortable asking your questions anonymously last time we had a bunch of great questions I'd love to keep that going super happy to to talk with you about anything that's there but I will keep the lecture three question thread up on Ed if you want it okay awesome let's get started so we're going to start again with our friendly squares right so just to give you kind of the format you should think about these tasks you're given something and your goal is to do something with it so we're given some x i and y i right for I equals 1 to n and recall this is the training set and right and in this case x i oops x i lives in some r d or Rd plus 1 as our convention is D plus one recall because we had that convention that there was a bias term where every every single entry had a one appended to it if you remember that from last time if not don't worry just remember like why is there D plus one there it's by convention and we had a Target variable Y and this target variable which I'll I'll highlight in purple this target variable was a real valued number right so this is picture picture align for the moment okay and our goal was that we wanted to find some Theta element of also r d plus one such that Theta was the argument or very very close to it because remember ARG man we can't really solve these exactly even though we like it over Theta of sum I equals 1 to n y i minus h of theta X of I squared where h of theta X of I equals Theta dot X actually I'm just going to remove the x i because I don't care true for any example okay I'll put transpose here just to make sure it's clear we I have a DOT there but awesome okay now I'm using this slightly more General notation this h of theta and that looks like a little bit of overkill for a DOT product but we're going to use that in several ways through the next couple of lectures so apologies for that if you remember here we had this the way we Define this Theta is we said oh it minimizes the losses or the residuals squared we didn't give any justification for this and what we want to do is go in this next part go kind of one level deeper and ask this kind of why question why did we pick to minimize the sum of squares now this will introduce us to one of our favorite friends in this course which is the gaussian distribution and we'll talk about why that's a plausible thing to do right you could ask why the gaussian distribution and I can wax with you philosophical I'll give you a sense of it but we'll come back to that in one second so our goal is okay we have this equation but kind of where did it come from and by thinking about where does it come from that's going to tell us how to generalize it right that's the that's the plan for what we're up to all right so this is our first model in the class really like generative model we're going to assume that y i looks as follows it's going to equal Theta t x i I'm going to unpack this in one second plus some Epsilon I and this character here this is an error or a noise term okay all right so let's unpack this because the first time we're seeing one of these things okay so this thing here maybe this makes sense to you you're like oh there exists some true Theta that's out there that's what this is saying this model is saying there's some Theta maybe I'll call it Theta star just to make sure it's clear there's some Theta star that's out there some you know one that's hidden from us but all of my data was generated by the taking that parameter with the features and generating the Y okay this would be a situation where all of your data laid perfectly on a line right because it's just saying that like you know given the features I know exactly what y's value is now what we're saying is something that's not quite that strong that's that would be a noiseless situation we're adding in a little bit of noise and when machine Learners or statisticians say noise what they mean is like stuff we can't really explain that's the kind of thing to think about it we're modeling it up to this okay and maybe we know a little bit about the noise and we'll talk about what we might expect from noise in a second but like we expect that there's some kind of random gyration maybe this accounts for in kind of physical settings some measurement error right some classical Jitter that's underneath the covers maybe there's something where you know if you're more kind of sophisticated Bayesian you think it's you know subject to your information I only know the features X and there's some unmodeled piece that's in the noise and I'm willing to kind of minimize that okay so what are the properties you would want of this error okay so this is a forward model by the way it tells me I don't know Theta but I know how my data is generated right that's what I mean when I say generative models like I know if you give me an x i and presumably knew how to construct Epsilon you could get a y i value okay now we don't get to see Epsilon I by the way it doesn't appear in the training set it's just a mental model for how the data are actually linked together okay and that's going to be fairly important when we start to generalize these models right they have certain kinds of Errors we can characterize Okay so what are the properties that we would expect of Epsilon I okay so first notice that it's Epsilon super I that is that noise is different per Tuple it's not like there's some noise offset that was just added to all our data and shifted every single point if you like we're going to have a random model you get a random sample from that noise okay and that's what determines what the y i is okay right so what would you expect from that well it's random we probably want something where the expected value over all the Epsilon I's over over that random process is zero this is sometimes mean it's unbiased okay now this is on one hand like a deep philosophical statement and other hand kind of a trivial statement the Deep philosophical statement is we're kind of saying that these errors if you think about it's kind of unreasonable like if I average over infinitely many of them they're not going to appreciably change what the true y value is right they don't have any information that's inside the model that's really what it's saying I may still get a sample where Epsilon I is 0.1 or 0.2 or negative point one whatever their value is but on average I'm just making a statement of the population like I don't care about this value it's going to be averaged away to zero in a precise sense okay now on the other hand if it were not a zero value that would be kind of a strange thing because we have a bias term suggests that you could actually just kind of incorporate that standing bias in the Theta star okay so I don't want to go too far down that path but like operationally this is not an unreasonable thing to say and I want you to think about it as kind of a statement of information like I modeled all the features in the X's right those are all my my features the house price remember the the lot size all that stuff and there's some thing I haven't modeled maybe the house looks a little bit nicer maybe it reminds people of where they grew grew up as children maybe it was you know that there's like a famous house or something that probably doesn't count for noise but there's something about it that's unmodeled as a statement of information okay the second thing is a little bit more subtle the second thing is that the errors are independent okay now we don't always make this but this is going to allow us to do some pretty healthy mathematics and let's talk about why what would happen if it failed and what this means formally is I'm going to write down a strong form it says that these two things equal the expected value of Epsilon I and I mean it in a very strong sense if you know about various different Notions of Independence and uncorrelation don't worry okay all right this is for I not equal to J that's what that little little piece is here let me write it bigger so you see it 4i not equal to J okay what does this mean okay so if you remember your notion of Independence what we're saying here is that they're statistically independent and I mean in a really strong sense like knowing the error for one Tuple doesn't tell me anything about the error for another Tuple this is consistent with my earlier kind of interpretation of Errors like how much information I know about it if I did know something about that error and I could model it then I'd have to have a kind of a more complicated model here okay all right any questions about this so far all right awesome okay now with this setup there's one other thing so so far I made two assumptions at this stage I hope you think they're like plausible to make progress and that's one of the things by the way about machine learning that I think people kind of get uncomfortable about I certainly was when I first started in kind of statistical modeling that like you're like well is that really true ah kind of not the right question to ask it's like is it a useful assumption to make to make progress like what am I giving up by making it which is a much harder thing to assess it's not ever true like if you look at real errors they're very infrequently gaussian distributed right that's kind of terrifying why do we use it everywhere well it still works pretty well because we're not assuming too much about the underlying data now if you know something about that data we'll come back in the next lecture and tell you how to put more information about the error but I just want you to get a sense like okay these are kind of strange modeling constructs now one thing that we'll care about which is a function of this is how noisy is it we need a measure of noise and so a natural thing to assume is that and we we can relax this assumption let's imagine that they're all kind of a uniform background of Noise Okay so everyone has the same variance this is a standard variance assumption okay the sigma squared so there's noise we don't know anything about it we know it's unbiased and we know that it has about the same magnitude it's not wildly different on some piece of our data versus others and again it's kind of like a statement of you know if you want to be really philosophical like an ignorance prior like we don't know anything so how would we know that this part of our data has more noise than the other okay it's just an assumption to make progress please [Music] until like the expected value of that square oh because it's oh yeah so this the variance here the variance formally is Epsilon squared minus the MU so normally we have a variance but I've alighted that because the the uh this first term is zero so it is actually the variance I just wrote it as the square there so it is Epsilon minus the MU the MU is just zero wonderful question thank you so much for that please so the error here is a sample from a value so it's actually a discrete value that's underneath the covers so it's like the way to picture it is like imagine I don't know I hate invoking deities but like imagine there's God and she's got her table right and then you got the value of all the x's and she has her Theta zero and she produces a y then for whatever reason she adds a little error to it that error is a specific specific scalar that changed y from 0.2 to 0.4 and I'm just saying that's the piece that we want to model and the reason we want to model that is because what we're coming to so does that make sense the types check it's a it's a scale or not not a function there the the reason we want to get to that is we're going to solve this problem kind of up to noise and we're going to worry a lot in the theory we won't do it too much in this lecture but we worry a lot in the theory of like could we solve it up to the noise floor like if you're making decisions that depend on how like noisy it is and your data is you know has a sigma squared of one and you're trying to make decisions where your values are like 0.1 apart intuitively something should be wrong there you're kind of reading into the noise so we'll worry a lot about how our procedure scale with the noise so you can kind of think about this as saying like there's some average noise and you know it's noisier or not if it were zero then our data is perfectly clean okay that's the way to think about it for now and if my explanations about like scaling and other stuff seem like obtuse and weird please don't worry about it we'll come back to a picture of the gaussian and it'll be hopefully a little bit clearer in a second okay other questions all right now here's the remarkable thing here's how the gaussian comes up it comes up for a really interesting reason which is if I tell you that I want a distribution such that uh it's unbiased and it has this Sigma squared I know it's variance and I assume nothing else about it right the bayesians used to make a lot of a lot of noise about this then that distribution is uniquely the gaussian okay so you don't have to know that in some fundamental sense but it leads you to this conclusion that is a distribution that has these two properties and you're not assuming things about how it's like third and fourth moments like if you wrote a three or a four there I don't have to assume what they are right they're they're just given okay okay so let's see um if I can skip to it okay so it turns out this is the unique distribution this is unique in some sense that doesn't really matter too much that's more like philosophical of the above and I've been a little bit too imprecise to really appreciate that but that you should kind of take away okay so this is our our friend the gaussian let's go through the notation first of what we mean so this Epsilon I here getting to the great question earlier is what it what it says is Epsilon I is drawn this is what the twiddle means drawn distributed to n of mu Sigma squared and I'm going to draw that in a second this is a normal distribution means this is the mean this is the mean of that normal distribution and this is the variance okay and here's a picture of it we'll get to it in one second okay right this is the mean right here and this is kind of how the distribution looks and so Epsilon the way it's picked is I will sample with probability proportional to the height of this curve right here maybe I pick a value here and that's how I get the Epsilon I and I'm repeatedly drawing from this underlying distribution okay that's what that's the mental model I have of Epsilon now is that actually what's going on I don't know don't know God don't know how that works but it's our model of how the world is going okay sound good all right now as we go through this a couple things this distribution is actually fairly peaked um so maybe you've seen this like a central limit theorem or something before in earlier classes at some point you've seen this idea that if I take a bunch of things and add them together they kind of converge to this distribution I won't make that statement precise but there's a reason this thing kind of comes up if you have a bunch of additive errors they end up looking when you average over all of them they end up looking gaussian okay so if you have a lot of little tiny additive errors they end up looking gaussian there's too much Philosophy for why this thing shows up if none of that matters to you don't worry it shows up and we're going to use it okay all right so just to make sure you understand this function and what it looks like here's the mean value of it if you see the sigma version so this is the square root of that Sigma squared you see that within one Sigma you have um here 63 percent of the or 69 percent of the mass these are by the way these notes you can go download the templates and they will have those things and this picture is from Wikipedia so you can also just look there please uh we will do a lot with population statistics we will not do things with sampling until a couple of key points and the difference between those two will be kind of immaterial when we do the actual salts but it's a great question yeah and if that doesn't make sense to you don't worry yeah so in our setting before when we had Epsilon I that's exactly right I should have written this for us great call this should be zero for our Epsilon I in general this is the notation so mu is equal to zero mu equals zero great point okay awesome all right another thing is this is the function right here that we're looking at now when you look at this you start to see why least squares may come up there's this quadratic looking thing in here okay there's a one-half and there's a sigma squared and whatever this is the normalizing constant that's just if I integrate the entire area under this curve this function that just makes sure that it's one that's a PDF okay that's all that thing is you'll see it a bunch of times in various different guises here okay but this is the function okay now let me unpack this notation for you you may not have seen this before this is not conditional we'll come back to this I'll hammer on this a couple of times this says the probability distribution density of Z and then this semicolon is not conditional formally it means these are the parameters of the distribution you don't condition on the parameters this may be a little bit pedantic but we will stick to this in the class you have mu and sigma Square those are like things you plug in right so why does this matter when we reason about the the normal distribution we're going to have these parameters the mean and the sigma squared we just plug them in and then it gives us a distribution okay and that's going to come back in one second when we get to what's called a likelihood function okay these are our parameters let me write that on here these are our parameters okay is the notation clear if you're familiar with conditioning this is not conditioning you can still condition you can write it in a bar and we'll do that in one or two steps you should be familiar with conditional probability for this class not the most advanced versions of it but you know basically what it does okay awesome all right so now let's write something that's conditional so what is the probability of y i given x i and as we said I'll write here Theta who or right here Theta which is our underlying parameter well it's going to equal what 1 over square root 2 pi that's the normalizing bit I'm going to move this down sorry X of and then here it's y i minus Theta x i squared over 2 Sigma Square okay so far so good okay so this is the probability distribution what does this it says given that I saw x i I saw the feature what is the probability distribution over the y i what value should I expect okay to come out of this right and that I have this Theta model which is our parameter here okay so our parameter okay we could put Sigma squared in there too okay now we'll write this in a more compact form x i okay this is the bar okay so this is now the conditional probability okay it says given that I saw x i condition on all the probability distributions under Theta this is the probability distribution over y i and I'll often write that this is this conditional distribution is n of theta t x I Sigma squared so this mouthful is the same as this mouthful does that make sense this is just notation at this point and hopefully the fact that it's a generative model kind of adds up go ahead foreign yeah so great question so here what I'm saying is I'm basically asserting by Fiat that because the only random variable is Epsilon I that x i here like so this really is there's a the difference between these characters right here is Epsilon I right that was by Fiat in the model when I did it earlier right I said oops sorry to scroll I I really wish it didn't look so nauseating but it does so because of this model I could substitute in here so this value here is nothing more than Epsilon super I and just a different guys which tells me all these pieces but it has to be conditioned on x i because I saw that like I saw that variable when I had to add it in right so that's how I get a distribution over y i wonderful questions are there more yeah yeah oh yeah so someone asked on the thing is e-i-e-i the the product of the two and the answer is yes thanks for the question someone's asking if this is the product up here and yes this is the product these are just multiplied by one another there's no hidden operation there yeah sorry the graph paper makes sure that I write in a line otherwise like I'll end up writing all crazy but I can understand it's not awesome for rendering other questions foreign okay so why did we do all this maybe I just like torturing you with notation the truth is I really don't like notation but we're going to use this in several different ways and so hopefully right now you can kind of piece it together and say like okay I kind of could see a model underneath here and what we're going to do is we're going to try and justify the optimization that we did for least squares by picking the most likely parameter so let me explain what we mean okay so before I do that notice here one fact that I've kind of hidden from you a little bit picking Theta picks a distribution let me make sure that claim is clear before I move on okay what do I mean once you tell me Theta and I have the data fixed then all the distribution over the Y Eyes Are Fixed does that make sense so in some sense by picking a Theta right once I have the sigma squared fixed I'm picking a distribution now over all what the Y I should be and that's going to be interesting because what it means is as you pick a different Theta I can compare how well does it line up with my data so intuitively right if I pick a Theta all my data lies on a line and I pick the Theta that exactly fits the line that should be much more likely than if I pick a different Theta where it's scattered my predictions are scattered all over the place and they're really far away so that the thin parts of this so let's come down and write that a little bit more precisely but that's the intuition of what's going on here okay so ask me ask me a question about that okay so for this we need a notion which will be very much used in this class which is the notion of likelihoods and this allows us to pick among many distributions okay so at first that sounds pretty fancy like how are we going to pick among these distributions right it's a huge unmeasurable class if you know what that is all this nasty stuff but we just have to pick in our situation among the different thetas that could fit our data okay and we're going to pick the one that is most likely so let's write that down right now so what is the likelihood of theta okay it's going to be the probability of all the Y's given all the X's given Theta right or can or with input Theta okay this just says How likely the date is and clearly as I vary Theta I'm going to get different scores here for How probabilistically likely all the Y's are let's break it apart if it doesn't make perfect sense what that statement means when I start to write it out mechanically hopefully you'll see how it decomposes and then please ask me a question I'm going to write something which at first may look actually I'm going to write here a bit unmotivated I can break this down into many smaller assumptions or many smaller pieces okay why is this the case why can I take the big thing and turn it into a product of the Small Things what am I using exactly I'm using Independence and the strong form of Independence which I which I kept bringing up that told me that I could write this big product over all the vectors as this as this product among all of them okay and sometimes you'll hear this referred to as the IID assumption independent and identically distributed okay all right cool please yeah so Theta there should be a zero and a sigma squared I'm being a little bit glib about what happens with the I could imagine a model this is a wonderful question thank you for letting me say this I could imagine a model where because the way I've specified the model it's implicit that mu is always zero but I haven't told you what Sigma squared is for right now imagine that Sigma squared is fixed I told it to you ahead of time so I don't have to plug it in here I could also fit it right I could look at my data and see among all the thetas that are there and all the noise levels what's the most likely one and that's actually a slightly different model but here I'm imagining that Sigma squared is fixed but it should kind of go under this rubric and you're like why are you being so sloppy about that and the reason is because later we're going to be much sloppier about it because we're going to introduce notation that says it's all the parameters in the problem okay but wonderful question you're exactly on on target for this look please foreign no no so here we have this probability because it's conditioned on X we've removed all the dependence on the data so like everyone gets to see all the data and now all that's left that's unspecified in the model is the epsilonize if they were all zeros you'd be able to get the Y eyes exactly but the only Randomness that's left is that Epsilon I that's what we're doing and that's kind of what we cheated on here when we we said this guy is really Epsilon I as well wonderful questions you folks are really on top of this the other questions please [Music] no no so there's there's really not there's really not much to to say here all that there is is we went through this model where we said why eyes are of this form now that we've conditioned on x i we know this and we're plugging in Theta so you're giving me a particular Theta to evaluate and now Epsilon I is a randomly is a random variable it has yet to be determined so there's a distribution over that the distribution of Epsilon I is given by this equation because this is exactly equal to Epsilon I and so this now gives me a say I don't know what Epsilon is but it has a distribution that looks like this so if I sampled it that's a weird statement I want to be clear that's a really weird statement it means that if I picked enough Epsilon I's I'd expect it's mean to be here whatever mu was in this case zero and I'd expect kind of the scatter plot to look like it was inside here or like actually the histogram to look kind of like this like if I bend how many were in each thing and eventually converging to this distribution that's exactly what I mean awesome questions these are great okay oops all right oh man I even had it down here all written nicely sorry um we'll go back to my messy version okay so here we've gone from from this piece to this piece and then here all I'm doing is because these are the Epsilon I's which I've we've assumed Independence in the strongest way I can move to a product okay we will do this throughout the course a lot of machine learning is based on IID because it's an okay assumption does that mean the errors are not correlated no no of course they're correlated but we're not modeling it that's all it means it's not true it's just a good model okay great now I substitute in one more thing equals product i1 to n and then I'm just going to write out the distribution Sigma 2 pi times X of so y oh sorry what did I maybe forget a minus sign why I minus Theta x i Square over two Sigma Square okay why did I do this all right so I just wrote this whole thing out oops I just wrote this whole thing out right now the reason is we don't use this so minimizing this seems like a nightmare and so what we do instead is we use a simple transformation of this which will make it nice and additive which is called the log likelihood okay all right now I want to make sure of one thing let me go back there should be a minus here I messed that up this has to be the it has to be a positive square otherwise it will spiral off to Infinity I'm sorry this isn't my lizard brain I messed that up okay clear enough they're Epsilon here right otherwise it's the wrong shape yeah please oh two questions one is there a negative in the original formula also yes period yeah I made a mistake one two three yes oh exponential function so it just means this this character here sorry about this x of X it may be more familiar to you as e to the x there's no e to the power x and x is everything in the bracket everything in the bracket wait I thought the original function was appropriate because effectively we're competing a negative scene by doing the real minus the predicted rather no it's squared right so this character's School great point it's my mistake awesome okay is that clear I don't want to make sure that's clear it's a small detail and it is in the notes maybe I don't know all right okay so far so good all right wonderful okay so we have this function with all of our with all of my bugs that I've introduced that we're catching on the Fly which is awesome we're going to introduce a new function it's going to be the log of our old function say why are you doing that and the reason is what is law what does log do for X functions well it brings the contents down right which is nice and it also uh separates out things that are products so we have a big product we take a log we turn into a big sum that sum looks a little bit more like what we were expecting intuitively from our from our least squares let me write it here so it's sum I equals 1 to n right because we turn this product into a sum 1 over Sigma 2 pi minus y i minus Theta x i Square over 2 Sigma okay I just took the log of the exponential please [Music] oh log Sigma excellent point let me move this oops yeah it should be log Sigma you can see where their typos and things I don't care about that term is going to disappear in a second but awesome awesome find yeah Okay cool so what do I care about here the thing I was just about to say is this term doesn't depend in any way on Theta right and so remember when we talked about minimizing the the loss function we're like oh if I added a constant it didn't matter and this is a constant the sigma squared that doesn't depend on my data anyway so I can just kind of toss it away in contrast this thing very much does depend on my data and Theta right comes on data and Theta is that clear yeah please submission side is sort of a blue trip so think about it like this yeah sorry awesome questions yeah wonderful okay so now what does that mean if I want to find the most likely function that corresponds to doing what I claim it corresponds to Max over Theta L of theta why is that the case Well Log is a monotone transformation right so this original thing I wanted to maximize the probability log is monotone right looks like this and all the rest and so log of theta is the same as as maximizing that then this term is just a constant we talked about how that doesn't really matter too much so I can drop that term and then I have a minus here so it's the same as minimizing over Theta 1 over 2 sum i1 to n y i minus Theta x i Square and then you say well what about that Sigma squared what happened to it well as we talked about last time it doesn't matter if you scale the loss by a constant it's still the same minimizer we don't care about the value and what is this character that's least squares okay and we call this thing j Theta right this was J Theta in the last lecture okay so what was important here I walked through this fairly slowly um and what I the reason I wanted to walk through it like this and you should run through this is because we're going to run this same Playbook again and again we're going to talk about what the error is for these these kind of linear models then we're going to try and reduce them to this likelihood computation oops this likelihood computation will almost always use the log because it turns it into an additive problem and remember stochastic gradient descent likes to work on additive problems this is of a nice form that we like to deal with and then we solve the underlying equation and so there'll be kind of this mapping that I give you a distribution and then out comes a loss function and that's going to be nearly automatic after this lecture in the next lecture to be able to do that for a pretty wide class of models then how do we solve them it turns out we're going to solve them all the same way awesome okay so is that clear is the probabilistic interpretation of least squares or fitting a line clear please please go ahead foreign [Music] so if you had Sigma Square here I'm not going to show you how to fit this right now but there's another model where you have it this is called with known variance this is what I call fixed design with known variance uh linear regression if you also don't know the sigma squared you have to learn that too and there's a parameter right Sigma comes out it doesn't come out quite nicely to the least squares formulation you have to do a little bit of extra work to estimate Sigma but you can do it and I think it may be a homework problem so I'm not going to tell you too much more about it but it's not it's not complicated yeah it shouldn't be complicated but great question for now we're assuming Sigma squared is given you do not need to make that assumption please no either way all right all good all right so um at this point we've gone through that that interpretation let me make sure if there's anything else fantastic all right let's talk about classification little primer on classification this is where we are we're going to talk about how classification works why regression isn't the thing that we would necessarily want to do in this scenario and then we're going to run the same Playbook I assert to be able to solve the model okay uh that is estimate the Theta underneath the covers all right so here what is classification what are we given we're given not surprisingly X I's and Y is no change so far 4 I equal one to n okay but y i we're going to work on binary classification in zero one okay and the values of zero and one aren't super critical you could have minus one and one I actually prefer that because it makes some of the math a little bit nicer that's not what we're doing in the course you could have just categorical values there are discrete encodings of the variables okay now we often think in terminology why I also like the minus one we call this often the negative class this is just convention right there's no intrinsic meaning to these things this is our model and this the positive class okay so like a negative Class A positive class could be we found the tumor right there is a tumor in this image versus the negative classes there's no tumor or this is a cat this is not a cat right we're doing binary right now you can do multi-class which we'll come to later which is you know there's a cat a dog a pig a horse right now we're just doing two okay okay great so you look at this data and you're like oh okay I plotted it you've told me there's zero one encoded so you could use basically so we can use linear algebra and Vector techniques and all the rest so zero one here's some data right and you're like oh why don't you just fit a line right like I should just like you know kind of fit a line maybe the line kind of like I don't know goes through here or something like this and it's fine right and indeed for a lot of problems if you run linear regression and just kind of say like is it closer to Cloud to one than zero and round at the end like you can get out a classifier but it kind of feels a little bit weird especially because your data there's no reason it should be nicely clustered what if like there were a blue point all the way over here or over here or way over here what's going to happen to your line well it's going to start because it's fitting those residuals to go crazier and crazier if you like in this direction right naturally it's going to skew more and more towards more of the data and so whatever decision boundary you kind of put there you're going to get into kind of stranger and stranger situations okay now that's just a motivation for why you want to treat something that's natively categorical so let's let's go through the function here maybe you've seen this in a stats course already this is logistics or logistic regression so we're going to do one trick here over linear regression our hypothesis is going to generate something of X is going to live in 0 1. okay so this is a graph here of zero one uh that we're going to get to in one second and H of theta of x is going to be written as G of theta t x where which will equal uh 1 plus e to the minus Theta TX over 1. okay now this function here G of Z equals 1 over 1 plus e of Z this is called a link function okay the terminology sometimes also called an inverse link function the literature goes back and forth doesn't really matter so you say why did you do this well our model is still going to be linear in our features but we're going to feed it through this non-linearity and that non-linearity is all of a sudden going to make sure that it kind of saturates when it gets too big and saturates when it gets too small so it's not going to have the behavior if we looked at our old data right let's go back up to our old data it's going to kind of have a function that looks more like this does that make sense but at least at a high level okay so that's the intuition okay and this function here has a special name it's the sigmoid so you may see that if you use you know modern deep learning packages you'll see sigmoids or things floating around that's what they are they're just this function that kind of Smooths it over now you may ask like why don't I use a different link function you could there are lots of different link functions to use this is by far the most popular for a variety of reasons one is that you can turn it into kind of what they call probabilistic estimates which we'll get to a little bit later please [Music] yeah let's get through great question how do we how do you do multi-class let's first get through how we actually do the binary class that's a great question you can think about a standard way to do multi-class is to do what's called One versus all if it bothers you where you say am I in class one or any other class class two or any other class and you can kind of you can put them that way there are more sophisticated schemes there's a wonderful paper from 20 2004 that talks about how those more sophisticated schemes don't always pan out and it's written in a very aggressive style which I find interesting and entertaining Anyway by a guy from the media lab Okay cool so at first this looks kind of weirdly motivated but there's there's some motivation for it which is just that it has this nice property and it's smooth and it kind of looks close to like a threshold function now the other thing when I say it's smooth is we could also Imagine the function that was like a step function that you could use that right that seems like a natural thing when you're below zero then you know return when you're when you're negative return uh you know zero when you're a positive return one right that would be a thing you could do in deep learning these are sometimes called you know there's there's you know it's a sine function the problem is the derivatives would give you no information here right if they were flat so this is smooth so like it tells you like a kind of a nice smooth transition and that will work better with modern optimization that's one thing we want out of it please let's explain what h of X and G of Z are with this functions name uh remember recall this is the same notation we had earlier this is the hypothesis sub Theta this says how do we do prediction so the way I do prediction in this model um in the logistic regression model is you've given me Theta which is some parameters that you have that chooses your model then you give me some X which recall is like your data point and then what I'm going to do is I'm going to produce a number between 0 and 1. and the way I'm going to produce it is I'm going to run I'm going to take their dot product as I was doing before and then I'm going to run it through this function and I'll come to in one second how we interpret those scores but you can think about those scores as being closer to one means I'm confident it's in the class and closer to zero means I'm not confident in the class and what I was saying is this function looks like it was picked out of a hat and it really wasn't the reason it wasn't is it has a couple of properties it's smooth and it transitions nicely between zero and one and I was trying to explain why those properties were important and so that's where H data links to this image does that make sense the key of beta transfers isn't actually equal to the thing to the right of it in the parentheses it is so so if you look G is this function here but Z is a scalar right and so it's just substituting in Theta TX for Z yeah I just wrote it this way so I'd have more room to write the numerator and then here I wrote it one over because that's the more standard way to write they're equivalent great questions please oh yeah a link function is a general class of G that you could apply that's some kind of non-linearity one that you may have seen if you ever played with a deep learning package of something called relu or rectified linear it looks like this right so there are other link functions that are out there there's probits and logits and all kinds of things we're going to use this one but I want you to be aware of it because I think you have to to try one other link function on a homework and the phrase is used in the literature and it's very mysterious if you don't hear it first very good questions sometimes it's also called an inverse link function that's a separate issue cool awesome all right so how do we interpret those scores now this is the twist that gets us into probabilistic modeling which we're going to generalize so we say the probability that y equals one according to the model is equal to H Theta of x now this is a testable statement okay now just to complete it also what's the probability y equals zero this is going to be proportional to X Theta of one minus H Theta of X Y because probability is sum to one okay we only have two classes now this is actually testable if you took a bunch of data and put it through and looked at the probabilities and bend them right so you took all the predictions that were between 0.5 and 0.6 and 0.6 and 0.7 and you counted them up in every bucket how many were accurate this is testable you can see if the model is what's called calibrated okay and that's very useful that like the errors are meaningful and so you can check that it's a it's more of a condition than they're right or wrong now in modern machine learning that's less important but you will hear people talk about like the probabilities or the scores that come out of these models and using those scores for something and this is what they mean they'll sometimes use the log of this which is called the logit okay but that's how we interpret what the model tells us that's why this link function is important that it's between 0 and 1. cool it doesn't damage optimization it's not obvious but it doesn't damage optimization is the other major thing okay so let's use that information to write our likelihood function the probability of Y I'll emphasize that it's a vector this time x I don't really like that notation but it's okay is well why did we get here oops well this is again the independence assumption kind of rearing it's you know ugly or not head right we're able to go from the entire data set to a product over all the terms nothing surprising there and then we'll write this in one form which hopefully makes a little bit of sense x i this seems like a cheat but it's actually okay 1 minus H Theta okay so why does this seem like a cheat it's a weird way to do it okay but it'll come become nice in a second so what I'm writing here is I'm saying the probability is the probability I said that it was true now what is y i when y i is 1 I select this term because this term is zero right so think about when Y is one this character is one this character is zero so this goes to one and this is the only term that matters when the true label is is one it's exactly reversed okay when it's zero I should say when it's zero this term is one and then this term goes away does that make sense just think through like the cases y i zero or y i is one so far so good so it's kind of like encoding both simultaneously I get to see why I so really only one is present but it just makes my arithmetic a little bit cleaner below does that encoding make sense cool right all right so let's take the log of L Theta we're doing exactly the same thing that we did before one to n now I'm going to write it write this out it's one i y I log H Theta x i plus 1 minus y i log and oops one minus H Theta x i okay so so far so good but now notice this is in exactly the form that I need for SGD to run that's pretty wild okay this is just a sum over everything I can just write gradient descent or anything else I wanted in terms of the thetas and I'm all good these are these are functioned underneath the covers now one other thing which I won't arrive but you can see very easily from this okay so just just to be clear same recipe I want to write down what I mean by same recipe we have Theta t plus one equals Theta t minus Alpha Theta I J Theta now when we do this something oh so right now actually we're sorry we're gonna do gradient Ascent because where this is still maximizing probability we haven't pulled out a negative term sorry about that but one interesting thing pops out so you should verify this we'll see if we can do it we won't do it in class but you should see if you can you can do this Theta J of come on of L Theta equals the sum I goes from 1 to n of y i minus H Theta x i times x i j okay so this is pretty miraculous if you look at this what it says is if I look actually at this underlying function and I take the derivative it comes out in exactly the same form that we had when we were doing linear regression it's your prediction error times the X I now the prediction itself is different right before the prediction was just Theta dot x i now it's this this H function but this gives me something I'm like these models are very very similar right they're like how much error do I make then take a gradient step with respect to the data that that tries to minimize that error and so this is the sense in which I mean like these models really all are kind of like all the same we're twisting these pieces at the edge for how we model things okay and so that means actually after you you pop all this stuff out you can use exactly the same Rule and this rule is extremely General okay and that's surprising like this rule of like I just take my predictor and then I do and I do the derivative like that's kind of shocking that like a large class of models and in fact that's what we're going to generalize in the next lecture to make sure that we understand exactly the breadth of that any questions to this part of what we're talking about please oh right great question so remember the reason that we got this minus sign here sorry to go back oh the minus sign was our was our Nemesis the last time that popped out and so this turned our Max into a min right we didn't have a minus sign here and we were maximizing the the loss that we put in and I didn't I didn't oops I didn't change anything so when we were we never had a minus sign pop out of here but when you actually go through and see it a minus sign does pop out you have to take my word for it or you just do the calculation see okay but here that's why we have gradient descent because we're maximizing the loss not minimizing the underlying function please oh this is XJ is the jth component so here I did this J's are the same so I was taking the derivative with respect to the jth component of theta and so that's the underlying derivative same way if you remember in the linear regression we calculated the the derivative with respect to each component independently exactly right well if this is yeah this is the exactly right yeah I don't have anything to add now um yeah oh great great question why I is the label so and here that's what I was saying I said in an extremely confusing way for some reason so why I is fixed I know why I get to see why I it's a label so when I have y i is equal to zero then this term is zero so this thing is just one and this is the term that's inside it's like a switch statement when y i is 1 which I get to see right for the values that it's one then only then this statement goes away and I and I have only this character if I could draw faster with colors that's a terrible color here we go does that make sense so it switches between both based on what Y is it's just a compact encoding of both cases that's why it's a little bit awkward yeah great question please so we compute it so the the thing here is this derivative here this this log and I'll make sure this is clear we wanna like this I'm asserting I haven't shown you this but the way you compute it is you take the derivative you put it inside you say Okay y i doesn't depend on Theta this term does you compute the derivative of this character internally and then that is what I'm saying you can simplify it to down here but you you compute it like that's up to you to do once the model is in this form you just use the rules of calculus to compute it yeah exactly this follows this notation I will use reflexively without thinking this is the log likelihood I mean change colors Yep this is the log likelihood and this is the likelihood likelihood okay this is on the probabilities this is on the logs of them great questions cool please so we'll almost always do gradient descent so one rule of the course or not rule but one thing is you typically use the log likelihoods for a variety of reasons but one is that they're nice for optimization and so that's what this link is meant to show you very cool awesome all right I will pause a second all right so at this phase right now we've seen another model what we're going to see next lecture is we're going to generalize this with a little bit more math and so the thing is it's like you know maybe it's a terrible terrible metaphor but like you know a frog with boiling water or whatever but like you're you're getting more complexity and you're not noticing it right we started at lines like I know how to fit a line then we had some probability distributions okay they came in and then we started these predictors that were actually instead of just giving you a value of regression they were actually giving you a probability we interpreted those as log likelihoods now we're going to make next lecture we're going to make the probabilities more complex and that's going to allow us to to generalize before we do that I want to show you one other thing which is the which is the Newton's method which is another solution method so that we can compare and contrast with stochastic gradient descent and give you a chance to ask questions since we were a little rushed at the end of last lecture because I screwed up okay sound good all right okay so let's talk about Newton's method we're now talking about forget about your modeling side now we're talking about optimization right so Newton's method is the following we're going to be given some f from RD to D it's got to be a scalar out okay at this point actually doesn't but and what we want to do is we want to find f of x equals to zero so it's root finding this is in general a hard and intractable problem sometimes it will work sometimes it won't work okay if it were really nasty function if it's continuous great so why does this have anything to do with what we care about just as an aside remember your your uh thinking here if you want to minimize say l Theta and it's convex or has a nice shape that's the same as L Prime theta equals zero sorry if that's too small right so if I want to minimize something it's the same as finding or finding the roots of its derivative right assuming it's convex double shaped okay so they're related clearly all right so what how does this thing actually work so the idea here is and probably you've seen this method at some point maybe in a cowgirls class or somewhere and it's it's a good method but it's it has trouble with machine learning and I want to talk about why okay so here we have Theta zero we take our guess F of theta zero and we compute the gradient okay remember the derivative in this case because it's one dimensional is the directional of maximal increase right that's the function of the way the function is increasing that's what the the derivative is actually giving us now what we're going to do is we're going to follow the derivative to where it crosses the axis okay so our guess is going to be Theta 1. now you should kind of convince yourself it's not true everywhere but almost always if you think about picture of function in your head that crosses zero this is going to be a pretty interesting way to find the zeros and to get closer in fact this method is insanely fast for a large class of functions it's called what's called quadratically faster which I'll emphasize again but it means you get two you get twice the number of digits of precision as you run it's wildly fast okay when it runs in terms of steps that it takes okay so this distance we want to call Delta so Theta 1 is going to be equal to Theta 0 minus Delta what is Delta how far do we step then we have an algorithm here right and then we'll repeat it right just to be clear we go up here we would compute another derivative and so on and we would we would zoom in on this this would be our Theta 1. or Theta 2. okay so we have to solve this key step so how big is this well if we look at it F of theta 0 equals F Prime of theta zero times Delta okay it's just a triangle rise over run that's all I'm doing that's it okay that means Delta equals F Prime of theta 0 which I'll write in kind of an obfuscated way times F Theta of zero okay oops that is that looks terrible let me erase that there you go inverse okay so I have to do an inversion okay so this gives us the rule Theta t plus 1 equals Theta t minus F of theta t over F of theta T Prime okay this is our roof finding algorithm and as I said this thing converges crazy crazy fast right so it like you know if you go to 0.1 then the next iteration will be 0.01 this is error going to be 0.0001 right this is the error this is what quadratic speed means that's insane you don't have that many digits on your uh you know on your device like it'll you know get to machine Precision very very quickly now this algorithm looks great like in one Dimensions it's quite good but there's a problem with it when we scale up to higher dimensions and the problem we scale up to higher Dimensions is right here the way that you write the higher dimensional version of this rule is Theta t plus 1 equals Theta t minus and I'm going to write the the typical way we do this H inverse gradient and I'm going to put it in the way that we would use it okay so what have I done here let me let me unpack this it's a little bit obtuse okay so when we want to when we want to generalize to vectors so we want to generalize and use for minimization we get here so Theta is remember our front end Rd plus one right L Theta becomes our our F Theta right as we were using it above right I've written it as a gradient with respect to this this thing here if you remember your your Calculus this is the Hessian how big is that thing well it's in D plus 1 cross D Plus 1. all right this thing is small this thing oh it's not small this thing is small it's in a this is an RD now one thing that is thing definitely by the way if you don't remember what the hestian is H I J equals in this case uh I'll write it as L Theta is the Matrix of second partial derivatives all right okay so it's all the mixed partial derivatives okay if you remember this from your Calculus class if not don't worry I'm sure a brief refresher will be fine a couple things that are great about this algorithm first is notice there's nothing there there's no step size there's no Alpha this thing just runs okay this is a great algorithm in machine learning Antiquity like 2003 and 4 2006 people use this algorithm because it carried over from statisticians this is how statisticians would solve logistic regression so like if you go into R I think up until very recently maybe even still and you say like solve logistic regression it will use this algorithm under the covers and the reason is it will get super super accurate right it'll get all that fill up all your digits and be very very efficient in terms of how many steps it takes but each one of those steps for a machine learning problem could blow out your memory if you imagine you have a machine learning model that has a billion parameters a billion squared is a lot right it's huge it will blow out your system and so people have ways of relaxing this uh over time that they try to get more information in but it hasn't historically been worth it okay so does this algorithm make sense do you recall this algorithm happy to answer questions about it all right so let's do a rough comparison and if you want please ask questions about I mean anything I guess but you know relevant's fine oh I think I have a chart for this okay okay so let's look back at the methods we've seen because I want to put them in context we saw this SGD algorithm pure SGD every iteration took one data point right we looked so I want to compare the methods so we're clear on the method name how much they cost per iteration that is every time I take a step and change the model that's what I mean by pre iteration how much compute do they do as a result of that per iteration and how many steps do they take to the error to the air right this is kind of the conversion straight off so SGD has a pretty bad estimate of the underlying gradient but you can go super fast relative to the size of the model so you take many of them and you kind of make up for it in some situations so let's see this so to compute here this is proportional to D does not depend on the size of your data set there are situations where you can train these models you don't even see all of your data you only sample a small actually there are models that people pay money for that they have huge huge collections of of data and they only ran on the first like 30 percent of it and they released the model there they're like hey we sampled from it it was fine right it was fast enough if you ran even a single episode of batch gradient descent batch batch grading descent you would have to look at all the data points which would potentially be much much slower okay so it takes time at least o-n-d put data's here although I don't really mean them formally okay and then there's Newton's method Newton's method also looks at all data points it's extremely expensive we won't talk about how expensive you can get it slightly down from this but and I've written papers with other people and a lot of people have tried to improve this method but it literally like it's huge it has this D Squared is going to kill you okay you can try and get around it because you have to compute the interaction those those remember these partial differentials here these are like the interactions between every pair of variables that you have that's a lot of information quadratically more okay so that's where their D Squared is okay now these things are super fast I'm gonna be a little bit glib here because I'm not going to State the true precise running time this thing is really fast if you want to get to Epsilon error you take log 1 over Epsilon steps right potentially a little bit less than that too but it's fine that's super fast okay like you have an Epsilon of 10 to the minus 16 log of 10 to the minus 16 is like take a couple hundred steps and you're done that's wild SGD a couple hundred steps it's likely still spitting out random values okay in contrast at The Other Extreme this is like Epsilon to the minus two this is like Epsilon to the minus one approximately these are very vague Notions these are this is only under some considerations I just want to give you Engineers intuition of how well these work okay and the point is is that like there's a clear trade-off here of how expensive each one of these points are versus how many steps you have to take so if like you had a Computing device that made it absolutely instantaneous to look at all end data points simultaneously then maybe batch gradient descent makes sense because you would just take steps really really fast if you had an oracle that could compute Hessians right which is what people tried to do for a while and compute them really really quickly then you would prefer this algorithm right so it's a trade-off between size and speed now we tend to operate as machine Learners in situations increasingly whether it's a good idea or not I happen to like the idea of huge huge models trillions of parameters are the new like thing people care about it's wild Computing a trillion squared if you thought a billion squared was bigger trillion squared is bigger right but about a factor of a million it's huge so we can't run on those those kinds of models and we tend to train on data sets that are much much larger over time now that how what much larger means changes every generation of Hardware like every two to four years what we mean by that changes but like you know we train on the web like all emissions or like all of the we still can't train on all the video right there's more video that's put out there than we can possibly train on we would like to be able to do that eventually Hardware will catch up and hopefully the same dumb algorithms will work that's our that's what we're praying right now we have no we have no justification for that statement okay now the one thing that I highlighted last time is G the one thing I highlighted last time was there's a little character that squeezes in here called mini batch right we talked about this very briefly what minibatch does is instead of said electing one points it randomly selects B points now its estimate is somehow better than SGD but not not kind of theoretically doesn't change the curve the point is for modern machine learning you can do a sample of B things in parallel in the same wall clock time that you can do one and that's what's kind of distorted us to use these batch methods really candidly there's a little bit of error reduction in the noise like you get a better estimate of the gradient but really it's because it's free for the compute device the way a GPU works or any of these kind of batch kind of parallel systems you put in D points they can do them all in parallel so that's the thing that's lurking under the covers because after the election people ask me like well why would you prefer that you're still taking the same number of steps in batch gradient versus SGD and it's because of this parallelism that's underneath the covers we can we've built Big parallel machines Humanity right like your phone has an ungodly number of teraflops in it like super computer level teraflops some number of years ago and we'll continue on that thing so that you can get your photos tagged I mean I don't know that's how it works anyway so those are why we do mini batch right okay so far so good all right any other questions all right so the last thing I'll just put on the on the thing here is in classical stats these were all things that people cared about classical stats D was really small and N was you know kind of moderate size like if you look at where if you talk to like your friends in the social scientists who are like you know maybe they're not doing the same thing now but for a while ago when they would solve these models when they would solve these models D would be like a hundred right and they really cared what their responses were down to you know very very fine levels you have to run for a really long time to get that level of accuracy for SGD what machine learning is about in a really fundamental way is like taking these kind of bigger models and kind of solving them approximately and weirdly enough they end up pretty robust which is something kind of horrifying we don't understand it please oh yeah so it means at least so I mean like the Big O style notation it means asymptotically it grows at least this fast it's a little bit slower but I don't want to kind of get into it wonderful question yeah please [Music] awesome question so one one access that you could also look on here is how how well do they handle kind of noise in the data and SGD turns out to be kind of remarkably robust and you know there's some versions where you can prove this so when you're optimizing so there's folklore around this we'll talk a little bit about this but SGD because it's noisy some there's some belief that it doesn't get stuck in local Minima as frequently as some of the other algorithms do if you imagine this picture right right here imagine that it went back up all right then somehow like you're using all these second order information to race you down to the closest local Minima that's potentially not what you wanted the entire time so there's some folklore theory that says SGD is a little bit better and I say folklore because we can only nail that down in some cases they're basically theorems that say of the form like if your data looks like this then this happens or for certain things I'll show you in a couple weeks this happens for like solving certain Matrix equations you can you can prove that it happens there so that's another access the other axis which you may think about if you're an Optimizer is how numerically stable is the underlying algorithm and here's the thing that's pretty wild about machine learning the trend has been not to make more numerically stable things so if you care about how a computer works you have doubles inside double precisions floating Point numbers now you know if you saw nvidia's last announcement they're going down to fp8 which means instead of 64 bits for a number they're using only eight bits there are people right now training with integers those methods we really only know how to do over SGD because these methods you you kind of Can't Get Enough meaningful information in there so there's another argument about how kind of statistically robust they are um and how numerically stable they are they're not very numerically stable there's a lot of tricks we're pretty primitive there compared to like you know the optimizers of the world but yeah wonderful questions awesome fantastic um any other questions okay great so we're going to end a little bit early today uh what we're going to do uh on the and and know like in general like you have to stay at l445 but today we got through it um next time we're going to talk about our exponential models these are going to be models that have a more complex link function and allow us to model more of the world that's around us and kind of interesting noise things see you have fun I'll stick around for a couple questions

Live Lecture Transcript
Stanford CS229 Machine Learning I Exponential family, Generalized Linear Models I 2022 I Lecture 4

all right uh let's get started so today we're finishing our first kind of piece of the tour of the very basics of supervised uh learning we're going to talk about these family of models that's called the exponential family of models and why we care about these models as we talked about is they're going to allow us to generalize basically the kinds of models that we were using before to a wider range of error modes okay of different kinds of errors and they'll also come back and play a starring role when we start to tackle unsupervised learning where we don't have access to a Target variable and the underlying mechanics that we'll use here will set us up quite nicely for that just in terms of pacing in terms of the course what happens is I go away for a little while telling you is going to come in and talk to you about a bunch of different things kernels svms and deep learning and then I'll come back to teach you a little bit about the unsupervised learning piece which is again like a you know two-week block where we kind of see you know kind of from first principles how those things work and that area I have to say just as a plug for what's coming um that that area is something that's been really exciting kind of thrilling over the last couple of years how much we can learn without label data or with really weak sources of data that's been like a revolution in machine learning so hopefully I can share some of that excitement with you okay uh the threat is up the lecture threat is up on Ed if you want to ask questions as usual and everything's online um before the lecture I didn't put out a template today because I'm going to handwrite almost everything so all right so what are we doing today we're going to learn about these exponential family models and they're basically going to be what you already know with slightly fancier notation basically we've been ramping up the fancier notation each time and generalizing as appropriate how we want to go through them we'll go do the definition and the motivation and the definition at first will look like at simultaneously like a little bit weird and like kind of like oh that doesn't really mean anything it doesn't have any content and then it will also look to you like it's impossible to satisfy and that's kind of true right so these are fairly interesting objects we're going to be looking at but they have a very nice kind of canonical form we'll then do a bunch of examples a couple of different examples and the notes Here the master notes here are really good I would definitely recommend going through them the type notes just so you work through a couple of details this is something that like you're going to get like a high level piece of how we go through it just do the calculations once and you will be convinced of like all the different claims that are in the lecture if you try to reason about them without doing the calculations it just makes your life more difficult than it needs to be so just just go through it once it shouldn't take uh take too long but I'll give you kind of a high level tour today so we'll do that definition of motivation we'll do a couple of examples and then last time we were talking about uh this question of how do we deal with multiple classes right last time we were talking about binary classes yes or no now if we want to have multiple classes out there you want to know if there's a dog or a pig or a horse or whatever in there this is called multi-class classification and we'll talk a little bit about our friends softmax what you'll really get out of this is that it will look kind of to you in the end like oh okay that seems pretty reasonable but you'll learn about some encoding that is fairly widespread called the one hot encoding which you would need practically if you were going to actually use any of these kind of things I believe also your homework is out but I don't don't quote me on that I think it's out now and I saw there were some questions I had a class about that any other questions before we get started oh please oh yeah I'm the wrong person but you're free to ask like just tell you like I don't know oh yeah yeah so we are blessed at Stanford with many great things we have wonderful weather we have like incredible faculty we have the best students on the planet um and we're also going to create course support until I have no idea all right so let's see what's next Okay so the exponential family now I want to be clear like I have mixed feelings about how I present this because on one hand I want to convey to you like The Unbelievable historical significance of this and why you should know this uh kind of by rights of machine learning on the other side like there's an argument to be made that a lot of modern machine learning is not going to use this this formulation in this framework but if you start to read papers it's canonical enough that it will come up in various different places okay so I don't want you thinking like oh this is all you can do when you model machine learning this is like where the field is stopped it's important historically it is very nice to understand it has a bunch of properties we care about but it's it's not the state of the art right it's not what we it's not what I go home and you know use exponential family models it's weird that I go home and use any of these things but but and I do um but it's not this one okay all right so what we want to do uh is we want to have the following idea here is that and this is why it was it's so beautiful and and will come back as a form that we want to think about if P has a special form which I'll show below special form then some questions come for free some uh you know inference learning come for free now what do I mean by for free I mean what you already know automatically applies to them okay and when we start to worry about more complicated models this will form like a subroutine that we'll use again and again like oh if we can reduce it to that form then we're in we're in good shape that'll be the way we get to things like unsupervised learning all right now the form looks like this okay now one thing I should I should highlight as I go through this so this is the data which you know you already know this character so data labels this thing is called the natural parameters okay and I'll Define the form in a second the reason I want to highlight that is one place where you're likely to get kind of tripped up when we go through this is that there are kind of three sets of parameters and I'll come back to that later so if you're confused there'll be natural parameters canonical parameters whatever doesn't matter you'll see them all written down at one point and that will kind of explain the mappings between them but there are many different names for parameters in this lecture and and that's like the essence to understand it and the reason that's important is the natural parameters if you like are so we can write this form this functional form P of Y exponential this is where it gets the exponential name T of Y minus a of okay so I'm going to unpack this for a second okay now this form says basically my probability distribution factors if you like or can be written in this form not every probability distribution can okay the way you show that a probability distribution can be written in this form is you write it in this form okay there's no secret shortcut here right you have to be able to express it as some linear thing in the parameter so this is the parameters here these natural parameters times some T of Y I'll unpack that in one second what T of Y is minus this thing which is the partition function okay so that's what it says it says that your your function right there are many functions that are in the world that could be probability densities this one has this technical form okay we'll unpack this this shouldn't be like obvious that these things are important or exist so T of Y is called the sufficient statistics efficient statistics now in this course primarily we'll use T of y equal to y we won't kind of massage the data but you can kind of think about t of Y as capturing everything that's relevant to your data right these are the things that you're modeling that are in your data and so in this example like we're keeping everything T of Y being equal to y means just it's y itself okay now another thing people get confused about this is necessarily the same dimension foreign right why is that well we take their dot product okay this is a DOT product here you can think about this I'll write it above just so you clear also you could write it like this if that's more clear to you it's an inner product between the two okay so to take the inner product and for it to be meaningful those have to be vectors of exactly the same Dimension okay so you have if you want to have so many parameters you have to have so many sufficient statistics right okay so far so good B of Y is called the base measure it's not the most critical element here but you need it okay the ex the intellectual content of that is that b depends on y but it does not depend on not depend on beta okay so it says basically if you like what's going on here is this term has all the interactions with Y this term has some interactions with ETA and the only way that ETA and and t y interact is through this term okay it's really a statement about how they interact these functions are pretty powerful right those are just arbitrary functions but when they interact they interact in a linear way sometimes these are generalized linear models okay all right keep staring at it this character A is often called The Log partition function now this is a weird comment that I'm going to make okay and it does not depend on well it's friend it doesn't depend on y just as I just said does not depend on why okay now this thing is picked effectively as a way of normalizing the distribution so it's a probability so it sums to one when I integrate it or I sum up over the discrete values all the Y's it's going to sum to one so that may make you think that a in some way is like not the star of the show you know it's just this thing that kind of like adds up everything but actually this log partition function contains almost all the information it turns out of the function and that's a weird thing but it's true okay so talk about that so this contains a and then you have this linear interaction term where the statistics interact with the data okay now just to make sure it's clear Y A and B are scalars scalar functions so a of ETA B of Y are scalars okay just to make sure the types are clear and these two characters have the same dimension okay so far so good all right so let's highlight where everyone where all these characters are so you just see them visually same and wise okay so far so good all right now here's the crazy thing many of the distributions that you've encountered in your life I don't know how often you encounter distributions but if you encounter them at a relative frequency a lot of them are of this form and that was a huge win for statistics because they said all the stuff we're doing on distributions a lot of it can be mapped into this what looks like as I said a trivial statement and the same time seems also impossible that it would be there so let's look at some examples and see how we map into this form probably you're thinking about you are going through some distributions in your head if you look at them and you're like I'm not sure that it is of that form so let's look at the simplest version of that and see that actually yep these things are of the form so let's look at some examples okay before doing that example I just want to are there any questions about about the content of this and I'm happy to defer so please feel free to ask a question and I can tell you to defer if there's something else clear enough please don't worry about X they'll come back in a minute yeah yeah wonderful wonderful Point yeah there's no X here there's just a y which is your data there's no x's and features and they're going to make it they're going to make a an appearance uh later they will be one of these parameters it's not given it's remember it's our semicolon those are the parameters remember there's a bar which says given which is condition and there's a semicolon which says these are parameters yeah see there's these Ada are the parameters of the model right and and they're going to sweep up all that nasty notation that I talked about last time wonderful questions please why does that mean Q5 is also a Spirit uh and some of the examples that we'll see you later yes yeah it doesn't need to be yeah just for just to make my life a little bit simpler in this in this class it's not a requirement of the model yeah awesome wonderful questions okay this is a requirement just so we're clear these have to have the same dimensions otherwise it doesn't make sense I'm not saying something deep I'm just saying like otherwise it will your brain should segful like what am I taking a thing and multiplying it by okay right because this has this entire expression has to be a scalar for it to make sense okay great so let's take a look at an example so probably the first example that you should think about I would guess are bernoullis right Bernoulli random variables so what are these so we're going to have some Phi probability of an event right I guess the most common thing people use is like flipping a biased coin right for some probability that it's had some probability that's tail something like this so here when we've seen this before Phi it had this form remember this form that we used maybe this looks a little bit familiar one minus y okay so the probability of Y uh you know for one is Phi and when Y is one um this term when Y is zero it's this term okay just a compact way to write it P and 1 minus p is all I'm writing here if you think about kind of a heads Tails distribution all right so this is not obviously of the form let's go get the form let's go get our friend from up above how are we going to put it in this form okay and I'll draw a box around it all right now when we do this we are like well we got to get an X somewhere right I mean that seems pretty natural so we're gonna we're gonna put an X in there and we're gonna X above y log Phi plus 1 minus y log 1 minus 5. okay so far so good we're making a little bit of progress well the problem we have right now is the Y's are interacting in two places right so what do we have to do well we have to bring all the Y's together because the Y's and the fives the parameters like they're not eight is yet well we'll give ourselves some freedom but intuitively like the parameter should all be looped all be somewhere together okay so what is that going to be 5 1 minus 5 plus log 1 by 5. now we seem to be in kind of the right situation because we have this character here which kind of looks like the interaction terms right Y and the and model parameters are interacting and we have something here that's isolated that's just a function of the model parameters okay now it's going to turn out that Phi is not going to be equal to Eta right because this thing here is not of the right functional form so we got to figure that out so what's our what's our best guess for what this ETA will be well why not what it looks like 1 minus 5. okay so we want to set to to show that it's of the right form we want us we postulate that this thing is actually equal to Eta okay now that means this thing here has to be some function of ETA right now that seems at one hand kind of obvious right because it only depends on Phi and that's a local transformation for Phi but we're going to solve for it explicitly if that kind of hand waving implicit function theorem kind of argument bothers you okay right so here our goal is we're going to take Ty as again getting equal to y we take ETA that way and we want to understand what is the value of a and what we claim it is right a of ETA or of Nu is we claim that that's going to be minus log of 1 by 5. all right let's let's check that claim right that shouldn't be hard and so why does that work well copy this guy so this goes to well I just take e of both sides 1 by 5 then I move this thing across right so that I can I can do whatever I like 1 minus 5. equals Phi then I want to make sure I get all the files on one side so I get 5 or 5 times e ETA plus one and I'm off to the races right so now I have 5 is equal to 1 plus e to the minus ETA over one okay now this means by the way that log of 1 minus Phi well that's going to be equal to oh sorry did I screw that up let's make sure I didn't screw that up I'm just going to redo this piece just to make sure because I didn't do it in my notes um so it's going to be oh no it's one I'm right e to the FI okay so now I take 1 minus this right so that's going to be equal log of this is a lot of arithmetic to do in one Peak setting but this is going to be log of uh 1 plus e to the ETA okay so far so good so why does that satisfy me because that's a function of ETA right now as I said it's kind of straightforward from here because these things are just functions of each other but this is technically what we needed to do to show that these things are actually equal and in fact we're in good shape now okay so what am I saying I'm saying like this seems trivial on one hand because you're like wow I could just put in whatever I want but you can't put in whatever you want you have to first separate out the interaction between Y and the firm and the form and then you have to be able to pull out the term that depends only on on new here the parameters does that make sense let's see another example please [Music] right I mean a is a function yeah right that's just a function of a just this happens to be a different one okay now here's what's weird okay I don't know if I should really mention this but you should look this thing actually remember I told you all the action was in there you can kind of look at this encoding this is the log partition function so a log is what we expected this one plus e n thing well if you think about like the different weights on the spaces this is actually encoding the fact that there's like a positive and a negative State and try and think about why that might actually be the case in fact if we start to compute the derivative of this thing it's actually the expected value of y that turns out not to be an accident okay all right okay before we get into that let's go down one more okay so what did I hope that you got it from this it's a tedious thing to walk through you can should walk through these on your own there are three examples you should also walk through the logistic kinds of examples and the others basically the whole thing is I want to make it super clear what the statement means I don't expect anything here to be mind-blowing I don't think like our use of fractions is gonna you know change your lives I'm just saying that like this is the content of the statement clear right you give me a probability distribution in one form I'm going to translate it into a different problem into a same functional form such that it has you know satisfies these conditions and then in that case this Ada is now the this Ada is now What's called the natural parameters okay and you're typically not given the function in the natural parameters right and you're going to be responsible on homework and in other places to do this and the reason why is if you can do this mapping then a bunch of stuff gets easy inference gets easy learning gets easy because now it turns out that you can show and we'll talk about in a second you can do gradient descent on these parameters and it's going to be concave and that's wild that you can solve all these models the same way okay so I just want to make sure that the functional form is clear and the reason we're doing it is because it's going to simplify some stuff please yeah awesome so could you use the T function to massage in the form now in this class if you find yourself doing that too aggressively you've probably done something wrong just as like a heads up because we don't we don't use it too much but yeah you could do that in t if t or like expressed in some way and you were only modeling a piece of it uh as a result of this and saying the probability distribution didn't depend on one part like T was a projection you could do that too but this is pretty hard to get around so I think you're thinking in exactly the right way kind of like how do I get around and break this and basically what it's saying is your interactions are arbitrary and why arbitrary arbitrary and new and the interactions between them occur in the X right and that are linear and once they have this linear interaction term whatever the function T is those sufficient statistics that's what you're modeling up to and some folks asked and I answer some Advanced questions on the on Ed which none of you are responsible to know about deriving things like uh why is logistic regression calibrated in certain ways in data those features those sufficient statistics are what feed into those arguments so up to these sufficient statistics this is how well you do so when you play the game of massaging it you're either throwing away information uh or you're not in which case you know that's what we're doing here yeah so it's a modeling choice you could do it nothing that presents you but it means something about what you're doing underneath the covers okay this is awesome so so now you learn something which again hopefully seems sort of trivial you're like oh I can take some I can take that distribution of like heads and tails and put it into this weird functional form and that would be interesting because one thing you should test your understanding of is can you now given a bunch of samples from heads and tails like estimate the underlying parameters right Computing derivatives here seems a little bit nasty right these are like fives and y's that are up in things it's like it looks like a weird function once I put it in this form all of a sudden like it's nice and convex and life is good but I have to look at estimating this parameter not the original one is that making sense please ask me a question if not all right we'll see one more example and we'll come back to it this is the only important thing that from from what we need to do now let's look at the gaussian example two we'll only do these two examples okay this is the gaussian with fixed variants this one's really good because remember what the probability of Y is going to look like sorry one over two pi X and there is a negative y minus mu Square over two Sigma Square okay let's make Sigma Square equal to one actually make my life a little easier okay just for no reason okay now how do we get that in our favorite form so let me go copy our favorite form seems to be pretty close right I mean we're in pretty good shape what do we need to do well we have to factor it in some way so this constant we can absorb anywhere we don't care about that we have to somehow pull this thing apart okay so how are we going to do that so we're going to put the 1 over 2 pi square root 2 pi here and then we're going to pull out the E minus y squared over 2. okay so I'm just going to factor this right this is going to be minus y squared plus u squared minus 2 mu y over one half that's what this term is going to be right let's just straight multiplication so I factor out the e y squared what does that leave me with leaves me with X of this character mu y minus one half mu squared oops minus one half mu squared okay so what are our natural parameters well ETO is Mu which is why I accidentally wrote it right at the beginning which would have been a little bit weird to do T of Y and a of n equals one half ETA Square oop mu squared okay wow no yeah okay right so because this is Mu now again notice I differentiate this thing what's the expected value of this of this character well it's mu right but when I differentiate a y I get exactly back mu which is kind of interesting this is Trivial here in the last example it was non-trivial it was like a weird function that I differentiated and I got back the actual probability distribution right which is kind of bizarre that I would get that back okay by the way if that's not clear differentiate dysfunction with respect to Ada and then see what you get okay does that make sense okay so just make sure we're verifying everything Yep this looks right uh this is my B term oh sorry this is my B term I'll highlight in different colors this is b y this thing is the part log partition function okay and what I'm just trying to highlight is like this thing contains like a lot of information about the distribution in both of the examples we've seen please no it's a wonderful question so right now we're worried about the case where Y is going to be a scalar which makes our lives a little bit easier and so we're going to look at that but you just have to have that the t y and n and ETA actually resolve to a scalar that they're the same type so if you have if your y has multiple dimensions then you need more natural parameters that's actually pretty important because um that that's why they're and why we call them natural like it's like your problem has you know Dimension D then you need deep free parameters [Music] foreign there is not no you could the thing is I wanted to have Sigma squared be um fixed like I didn't want it to change per data point that was important and so it was easier to just write one there if you put if you put Sigma squared in here and it was just a constant then you would just push it into the appropriate spots and be done they would just fold into this if Sigma squared were something that we're changing per data point right like we were trying to estimate for every data point not only it's mean but it's possible variance like I give you a temperature reading and I say like from all the data I've seen I think it's 30 degrees but I know that I haven't seen enough data so I'm like plus or minus two degrees if I've seen tons of data and I'm very confident I'll say plus or minus 0.1 degrees right that is an estimation where Sigma is part of the model and then you would have another free parameter for it great question and try and write that out I don't know if that example is written out in the notes if you get stuck or whatever please send me a note I'll write it up for you on it does that make sense that capture your question awesome okay yeah awesome so two questions on the on the live thread um the examples to go through on your own are the ones in the hand and the typed written notes which contain these in one more but just go through them on your own like I'll just wax pull whatever one minute if you haven't studied for a mathematically minded course the way that I always do it did it I still actually read textbooks and course notes and everything else is I read them I watch the lecture or whatever it is then I try and remember those key spots and I try to derive them myself it's the fastest way to figure out what didn't stick so if you're like oh I can write the derivative in two minutes and you walk away well okay you know everything for the lecture if you get stuck it's a really good signal that you don't do it if you don't do it and then that builds over time something that you thought was trivial and you didn't actually put the time into will end up biting you right just lesson that I learned from too many years at the University why is the derivative equal to the expected value I'm not going to prove that I will just assert it here I just want to show that oops sorry I just want you to observe that in both cases it's true it's a wonderful question okay it just takes a little bit of arithmetic to show it's a wonderful question yeah yeah okay so I'm just gonna I'm gonna put those assertions in here now so why do we care about this form first is what we said inference is easy okay the expected value of y given ETA is the partial derivative with respect to the Natural parameters of a of n okay I would encourage you to compute this on all the examples okay you don't want it proving the general thing just takes a little bit of extra thing but on all the examples so far you've seen it's clearly true and then why that's true in general is because it's the log of the sum of all the possible outcomes proving it for continuous stuff takes a little bit more effort okay so don't don't worry about it okay but we've seen this as true okay and this this pattern holds the variance is also the second derivative of n okay now this pattern you may think holds like oh the third power is good no it doesn't work that way okay just these first two that's the only ones that matter okay these are the only ones that work okay so why is this so interesting to me one because once you take your distribution whatever the crazy distribution is however wild it is and distributions can get pretty insane there's you know uncountably many of them you put them into this form you basically have a mechanical procedure to do inference and to do uh you know variance estimation inference more important to us but that also means that you can do learning right and in fact learning is well defined okay in particular this function is going to be concave in data okay well let me write it this way the mle remember we did the maximum likelihood estimator for all those things previously is concave okay please that helps yeah so that is definitely a piece of it you have to do one extra step but you're exactly on the right thing that's exactly how you can go and prove it just compute it directly right and see that it's positive the second derivative is positive everywhere then it's um then it's comebacks but yeah so you have to there's a negative in front but that's a monster wonderful yeah exactly right that's that's if you remember last time the way we framed all of our estimation problems was take the log likelihood that was there L of theta and then use gradient descent on that and this is basically saying that the resulting formulation if I use the natural parameters is always guaranteed to be concave please yeah so the thing is you can compute this directly by looking at exactly when you compute the derivative and and pull it out the way that you do it I'm not going to prove it in class but I'll just tell you like it's not a mysterious statement what you do is you look at all of the for the discrete case you look at the fact that it's a log partition means it's the sum over all the possible worlds meaning all the possible ways that y could be assigned right so there's going to be a term in there for each one of them because it sums over all of them that's what it does so maybe this is getting way too abstract and mysterious maybe this is better to prove so if I look here look at this this part of the distribution this may not sum to one right if I just started to do it so like if I took and summed over y oops if I sum y of this expression let's call this g y it may not equal 1. it's not guaranteed to be equal to one okay because it's just some collection of values and some other stuff this thing uh is the the function this ETA here makes sure that it's equal to one so it's the scalar as we were talking about before that make sure whatever this sums to it's going to divide over it so it's sometimes written as 1 over Z the part the part partition function however that means that the way you get it one derivation of it is you sum over all the different values so it is like the sum of everything over one is actually what so this character has to be equal to this right because it has to cancel out it has to be actually equal to 1 when I compute it and that means that it's basically of the form a sum over all the possible values of Y and so if you compute the derivative inside when you take the log of that each one of the Y's is going to come down next to exactly this functional form all right so if if that's too mysterious I didn't want to prove it because it gets like strange but I'm happy to write out the proof it's super super straightforward okay awesome so all I care about this the thing that I'm trying to get across because I'm trying to give you a guided tour I don't want to get to I want to do enough details that you see all the pieces so you can go back and understand how they work but I don't want to get bogged down in things that I don't think are like super critical for you to understand um and also I don't want to do things that I think you should do on your own because doing them mechanically will teach you better than me like inscrutably writing for the hundredth time how to prove this um but if I'm wrong and you want to watch me incredibly right I can I don't know you can log into a twitch stream or something um awesome all right all good okay so clear enough like why we did this so barring these assertions if you get your probability distribution into this form then all of a sudden you get inference and learning and a bunch of other stuff for free however one of the things is as was correctly pointed out there was a little bit of a bait and switch here we started last time to think about various different models and how we put those models inside so where did the data in X go and that's what we actually need to figure out here okay all right so let's talk about generalized linear models foreign that I really want you to get across is these are all design assumptions okay so these are all design choices that you can actually make in your model and we'll get to them and and talk about what you want to do okay and you can also think about them as assumptions all right so first what we're going to say is we're going to claim that the distribution of our label given X for some parameters Theta follows an exponential family okay now I claim without much justification here that this is an important family now you can say it's an important family because as we'll talk about many different data types like fall into this that you've seen so if you look at binary things you want to do y as binary well that's Bernoulli right so we looked at that classification if you want to have real valued wise well we have a couple of them that we could use but we saw gaussians okay if you want to do counts like you're actually counting like uh you know how many people walk by a particular uh thing or how many packets arrive at a server or something like that then that's a different distribution it's called poisson okay if it's oh you want all the whole real line right you don't want you want real positive line well there's two different fancy distributions there called gamma right you don't need to know these per se but what I'm trying to explain to you kind of proof by writing a lot and gesturing wildly is that these oh sorry exponential laplacian's also in this uh if you want distributions just one more then this is called the duration distribution so what am I trying to get across here these are probably most of the distributions you've heard of there are more that I'm not writing down but they all fall into this exponential family now one hypothesis is that we figured out this technology and that's why we described distributions this way but that's actually not true we went the other way around we were doing things ad hoc for each one of them and this tied them up and put them nicely together okay so you pick your error mode and the way you pick the error mode is it has to have the right type if you're observing binary data you want to use a Bernoulli right or something that has a binary type if you're observing real data you want to use a gaussian counts plus on so on okay so there's a data type mapping here right the second thing that you have is that your natural parameters and this is where they come back in are going to be of this following form with Theta element of r d plus one and X also element of r d plus one okay so here we're going to make the assumption that after subject to noise our model varies linearly with some underlying features okay now you're going to see later there's actually a more powerful assumption than you realize if you take your model to be very very large and have a huge number of features almost everything becomes linear in that space High dimensional geometry is very very weird so it's not like if you think in low Dimensions you're like oh there's only so many lines I can draw I can't separate out my data if you take your data and you know put it up into a huge dimensional space odds are it will be linearly separable there'll be a line through it we'll come back to that okay so this is just the thing there and then three once you've made that assumption your inference is super easy right a test time you output e of Y given X and Theta okay I said another way h of state of x equals T of Y given X okay so hopefully this makes sense okay so I'll walk through exactly what's going to happen in one second just to make sure it's it's clear but this means that we're doing this prediction and one thing that we sneaked past you was that when we went to logistic regression all of a sudden we started with these hypothesis where instead of returning like yes or no we just returned a probability distribution over it okay and that was a that was a change right when we're doing regression we returned to just a value here we're just returning actually like your probability that you think y has a particular value that's what you do for inference that's how inference is defined okay so let me make sure this is super clear how this works your data comes in as X it then goes into your linear model you compute Phi transpose x with your parameters this is your box you get out Ada right Theta T becomes ETA and the parameter you have before you feed that to your exponential model X model does whatever it does there's B's and T's and whatever in there but now you know your value for Ada or new whatever you want I'm using both and then if you want to train you do Max over five of log p y x Phi if you want to do inference you do ey X5 okay this is learning this is inference okay so all you pick here is you pick your your data you pick the features and then you run this procedure and everything's kind of you know automated for you in the sense that like um yeah in the sense that you now know a general recipe to do maximum likelihood estimation and do inference it's not obvious how to do that by the way there are scenarios where we don't know how to do maximum likelihood estimation so right now like your universe is like oh everything you've shown me you've done maximum likelihood estimation it's been really easy I'm like yeah that's fair but there's a big world out there of stuff that is hard to cram into this and so what this says is if you can put it into this form maximum likelihood estimation and inference becomes super super easy okay and learning here has a nice form data J looks like this and you can directly check this plus alpha y i minus H Theta of x i x j i so why is that the case well we saw that it was the case in all the other models you just have to go through and compute the derivative and convince yourself but now that it's in this form just Computing the derivatives with respect to Theta as you go through here because it occurs only in this Theta TX we'll get that out so one of the reasons I was delaying proving it in the special cases is because you have to do all of these transformations to put it into the right the right nice form and then when I compute the derivative my life gets really really easy if you compute it in the natural parameters it looks weird but if I mean if you computed in the original parameters it looks weird but if you compute it this way life is pretty good okay and this by the way here is always this thing right always hypothesis okay so far so good please yeah so let's actually it's a great question let me do one more example and then hopefully that will become clear about how they relate um I wanna yeah so let me just run through logistic regression then I think that'll probably maybe answer that question um so it'll show exactly how they fit together terminology okay so there's the model parameter this is Phi there's the natural parameter which in a linear model we always substitute a generalized linear model we always substitute this was the Ada before and then there's the canonical parameters parameters okay so these were like five for Bernoulli okay uh or mu and sigma Square for gaussians okay and this G here we're going to call the canonical response G inverse so G is called a canonical response okay so why do I do this I want to make sure it's really clear what all the pieces are and what's going on here there's some model parameters that's the thing that we're going to solve with respect to that's the thing that we're going to do gradient descent on that's the thing that we're going to do the H data over with respect to Theta is then dotted into the model or the data that's what this x is this is data right here that becomes the natural parameter which then goes to the which the exponential model now tells you how to operate on okay and then I can do everything I want on the natural parameter that's what tells me the distribution and so in the case we're doing logistic regression which we'll talk about in one second you have a linear thing and then your errors are of the form I make an error you know that I sometimes switch to class if you like I get the wrong answer with some some uh probability and then there's this link which are these canonical parameters and this is the content of what we're talking about here is you write them down in these canonical parameters and then they have people write them down in whatever messy form we found them and I'm asserting that a lot of them can be put into that nice exponential form through what's called this canonical response function or its link function and that allows us to treat them in the same way so this is super important because when you encounter one of these distributions you probably encounter it in this form you have to put it into this form and then that lets you do everything that we just talked about in one clean way learning becomes this nice simple rule inference becomes this nice simple rule okay awesome all right okay so let's look at logistic regression just so it's super clear what that means all right so H Theta of x well we said it's the expected value of y given X and some parameters Theta okay this Theta right so we have right so there's uh theta equals one plus one Theta minus n and then the model one over one plus Theta oops e to the minus Theta TX okay so this piece here Theta was our was our or sorry Theta should be driven sorry this was our model parameter this was after we transformed to the Natural parameters that's this character and this is what we wrote down last time so when we went to do logistic regression remember we had a loss function that looked like this this was our sigmoid or logistic function and then what I'm saying is is that we right now to get the derivatives and do everything else which I skated on last time I now no longer have to skate on because I just made it more abstract I transform it into this parameter space and I'm good okay so in one hand as I said it's totally trivial I'm just doing a transformation of how I represent the numbers but it also seems weird that I can do this and I'm inserting that in these cases I can and that's what allows us to go and treat all those different distributions in some way so if I give you some features you dot forward you learn a model and then you have an error like I'm looking at counts I'm observing them counts have a very different distribution than the errors I would expect on zero one things or the errors I would expect on a linear regression I just plug that model in that natural Model N and outfall is a pretty reasonable class of machine learning models okay and you may say the thing that people usually react to is they say something like well what if I want to do something that's more complicated than linear but linear is pretty powerful I can take my features and square them I can multiply them together it's still linear right I can take my feature five could be the you know product of the preceding seven and so this turns out to be a wildly popular class of machine learning models in fact our entire books that are written about generalized linear models there's a citation to McCullough which is the standard reference I'm not sure I advise necessarily reading it but it's uh the standard reference not because it's not a great book just like you know it's long okay please do you think that there will be more improvements in the theory of machine learning such that quadratic and other models are more applicable in these folks right now when you're extremely powerful we're going to make a lot of sense yeah I am I I really feel like I should buy you something so that's a great question so there's a lot of folks that have done through the years but as we'll talk about when you get to kernels things like polynomial kernels and exponential kernels and those are very powerful ways to model the world what I was kind of hinting at before is the linear model has this sneaky out in the back which is you get to pick the features so if you know up front that like you want it that the squares of the temperatures are more indicative than the you know the raw values you can just put that into your model and and learn more and more features and so it's not a question of like you know eventually we're going to get powerful and use those features we can use them today the crazy thing is we can reduce a lot of the things you would naturally do to this model and you'll see eventually you know someone was asking about these infinite dimensional feature models those are what kernels are you can reduce those to linear in an infinite dimension space so it's wildly like uh you know important there to do this the other bit which is also you know my personal opinion on these things one of the things that has really bitten me again and again is that simple stupid things work extraordinarily well with a given enough data and in fact the trend has been larger and larger amounts of data for the last 40 years and every time we think it's going to run out of gas and get fancy a bunch of fancy people academics start writing papers about clever ways to do X Y or Z and usually they get smoked by more data and linear stuff and there's a great paper about this that I can post of like different eras of machine learning when this happened and like the thing that's remarkable about modern machine learning to me is not how sophisticated it is but how we basically do the same thing and just pour in mountains of data like right now there's a particular model that's very hot in five years will it be hot I don't know right maybe five years ago it wasn't I guess five years ago was kind of hot but you know and then a new one will come but the pattern of like we just dump in all this information and just optimize the crap out of these parameters like that works really well so the Sim so the thing I'm trying to get across there is as you said is like the future of machine learning seems to me to be more tied with like under understanding relatively simple applications when we have huge amounts of data underneath the covers um yeah but I'm a zealot there I taught the large language model course with Tatsu last quarter so I'm a Believer you can think it's nonsense it's a personal opinion but wonderful question yeah awesome others all right so again you know same thing I'll do gaussian just just to stall to make sure this is clear because I hope you know if I'm very optimistic I'm here like oh this is obvious uh there's there's no content here I understand it perfectly if we are in that Universe like I will be extremely happy if you're like baffled please ask me a question um this is the same this is a gaussian how do I do prediction well when I have something I pick the mean value that I would have that's exactly the same piece that's here how do I do the estimation well that's exactly Theta TX that's what we were doing before when we fit a line okay same thing so all that's all I'm saying is what we've done so far in the first K lectures we've now compressed to basically one equation one schema of this thing we now know how to do inference and we know how to do learning and maybe it's tough to appreciate in the sense that you're like well I didn't encounter a thousand models before but now all these different models can be shoehorned into this and that's quite powerful and we'll use that quite a bit later when we do you know much more uh kind of advanced stuff right awesome if there are no questions I'm going to move on to multi-class all right so the last thing I want to describe here which is important for you and I think you have to use in your homework is uh how we deal with multi-class classification and I should say the trend has been in machine learning not only these big models that I was just excited and ranting about which you can you know take or leave but is that you train models on a variety of tasks more broad than even a variety of classes you train them to do many things at once in fact weirdly as I may have told you the the thing that we seem to be doing as a field right now is training a model to do something task a and then using it for task B and weirdly that makes the model more robust so the typical task that we do there by the way is predicting the next word which is a really seems like a really basic task you look at a sentence and you produce of all you view the words as individually it's just oversimplified but how it works every token is a class right so is the word cat dog whatever you just take a vocabulary of 50 000 words let's say and then you predict which one do you think is likely to be in the next space so I read the first part of the sentence and I predict this turns the entire web into a training Corpus right because now any piece of text I can evaluate in a multi-class way we train it just to do that and weird Behavior emerges like it can write pieces of code for you it can answer questions in narrative form and only when we train it on lots and lots and lots of data and it's a little bit spooky so anyway so this is what multi-class is for and this is this is actually you know something that we use every day [Music] um awesome wonderful question what is the disconnect between the power of linear models and the need for non-linear components in a neural net wonderful question so right now what we've done is we've said and the exchange was wonderful hey what about more powerful feature representations what neural Nets basically are and why they're so amazing is and they take your data if you like and they pick out what those features are what those X's should be from the underlying data and then usually on the end you just have a linear model that's you know there's little tweaks and variations but that's pretty much what you have so the question of where does The X come from you give me an image of a cat how do I get good features about images that's what the neural net is actually solving and that's where we need non-linearity but it comes in at that piece not at the prediction piece great questions all right so here we're going to look at discrete values if you're familiar with distributions up to some fixed k so we have uh cat you know dog car I don't know whatever else oh I wanted one other one oh bus okay so here K is 4. all right so I want to predict among that set it's kind of weird I promise you that you're only going to see a cat a dog a car a bus you could ask well what if I show it a horse it's not it doesn't have to predict You can predict whatever it wants in that situation right but um for this case imagine that I'm just distinguishing among those four classes or the crazy example I gave you where your classes are every word and say the English language okay all right how do you encode this it's encoded as a one-hotvector it's called a one-hot vector right and the distribution the error distribution is the thing that we just talked about to the k okay so uh such that you know sum y equals one okay equals one okay so there's a vector that's in zero one but it's precisely one thing is is uh lit up so for example you could have you know the cat one is one zero zero zero this could be cat zero one zero zero this could represent dog you get the pattern zero zero one zero this could represent car and so on okay so those vectors basically these one hot vectors they seem pretty wasteful but you don't have to store all the zeros it's not as bad as it looks um but like this is how you intuitively think mathematically think about how the data looks okay clear enough so we've reduced our problem from uh you know dealing with these categorical labels to dealing with vectors now let's try to classify them all right so let's draw a quick picture okay oops so let's imagine our data looks like this so there are some class ones which I guess are cats here there are some buses here which are fours there are some dogs here I'm just drawing all nice and clustered of course your native never really looks like this but that's okay all right so what do I what do I want in this situation okay I want lines so this is you know this is corresponding to one class you know as I said this is the cat class this is the dog class so on so how does multi-dimensional how does this uh how does this multi-class thing work that's too close the colors don't really matter but I've started so now I'm going to finish all right car bus okay so what do I want here what I need to do is I want to pick because we're looking at linear separators for this I kind of want to look at you know what I'll do is I'll pick a line that for example separates the cats from everything else okay so this will be something this will be you know Theta 1. X is equal to zero so this is the line I'm drawing here so I want to pick Theta right so that on one side are the cats and then the other side is everything else does that intuitively make sense right for Theta 2 for Theta 4 what would I like to do well I'd also like to pick something where you know here oops Theta 4 dot x equals zero so I like it so that again the buses are on one side and everything else is there now if you look at this geometrically it becomes pretty clear by the way like there's lots of choices right I could have picked here I could have picked there right what we will try and prefer sometimes called Max margin we actually prefer that it's kind of as far away from the two data points as possible it's like as close to in the middle as possible you can verify that actually makes sense and um you can verify that that's actually what we'll you'll hope will happen I get something like this all right this is X3 so in this case by the way which is really nice everything is nice and linear separable right this side has the dogs on it this side has the cars on it and so on okay so there's one line that explains uh you know that kind of can separate each one of them now the question is how do you pick right so the way you do it right is when you get a point you're going to compute its value against each one of them Theta 1 Theta 2 Theta three I'm just going to draw the first ones first three yeah data four whatever okay and these are going to give me some values okay and the values are going to be basically you can think about as like you know kind of how close are they to the various lines it's a DOT product I'm just saying like this is the line where on this side Theta is going to be yeah so for this side Theta is going to be positive and on this side it's going to be negative all over here right and so I'm just drawing like the deciding line so as you're more cat-like you're getting a higher score from this you're getting something that's like you know a larger score Azure here you're getting a negative cat score okay right so the point is each one of these things because of that is going to give you great question is going to give you some score so maybe it's a cat so it looks like you know this thing 0.1 and everybody else is like yeah I'm not really sure maybe I'm I'm kind of like borderline about all the other classes this is what you would hope would happen okay each model gives me a score and then okay so what happens yeah yeah great question so right now remember like you give me a horse and you put the horse in a center who knows right who knows what I'll get I will be able to run this procedure and it will be confused so one of the things that happens in neural Nets by the way is that they're in large scale models is when you're really high dimensional right and you have a bunch of uh a bunch of these lines and other things there will be Pockets that are actually nowhere close to anything but now look it's totally well defined this character here has a normal this way this one will get a negative it will get a negative score from everybody right now you can look and say if it gets a negative score from every single thing maybe I should be suspicious of it but that's not in general something that will happen it one of these unfortunately will be higher than the others like if it's here it may be closer to cat and so it says oh it's a a cat that was near the border or something like that and it will pick but let's get to the procedure first before talking about the exceptions okay so we have all of these then what happens we exponentiate them right 0.7 minus 0.5 0.1 so on and then this actually leads to probabilities right actually let's make this really negative because like minus 10. either minus 10. then these things are approximately like you know uh 2.1 whatever so on I get the values out and then I normalize them by summing all of them so I sum all these together so I sum all these characters sum Theta I dot X and that gives me some value Z and I divide this number by Z divide this number by Z and that's going to give me a number between 0 and 1. because I sum them up and they're all positive so 0.5 0.17 so on 2.5 up okay the point is is I compute this exponential I sum oops it should be e of this thing and then that is my normalizing term I sum it up so let me write it in a cleaner form it's a falling thing so the probability of Y equals to X a probability of y equal to k is given X and Theta has the falling form it's X of Theta K dot X over some K sum J all right X Theta J dot X okay J goes from 1 to K okay I just described the procedure in elaborate detail here but this is basically what's going on okay this is exactly what's going on it's not basically please [Music] okay so two things one is this makes sure that everything is so exactly as we were talking about before these are each think about these as each like a logistic regression model so in the logistic regression model you take this and get the natural parameter then you exponentiate it if you had an offset like if you had some function there you would still need just as we did in the exponential model you need to sum to make it a probability distribution so that's where the Z comes up so the x is because we're doing these General linear models and that gives us the nice kind of functional form that we wanted underneath the covers that we've been using in all our predictive problems for in the class or not think about logistic regression binary or not and then we have many different scores and then the procedure is just to normalize them okay and this kind of makes sense right it's like this is saying like how strong a classification I am right if these cats like if there's a cat way over here maybe this is a super cat like the clearest picture of a cat you've ever seen in that case like it should get a really high score and you should be really confident in it that's the intuition now is that always true no certainly not a picture of a horse could show up over here we hope it doesn't but mechanically is this clear what happens right yeah so exactly so this is basically a compact form of what we'd call One Versus All which is like okay how confident is my cat detector how confident is my dog detector how confident is my whatever this is car detector I don't know what that is does that make sense and so you just bake off their relative strengths that's how you do multi-class classification at once all right so how do you train this well what you're given is you're given something that looks like this say one two three put four in there you're told it's a cat you have probability one here and you have zero everywhere else this is what you're actually given that's what the label looks like okay your probability your P hat your estimate will not look like that it will actually look like oh I'm pretty confident it's a cat but I have little pieces at each one of the others one two three four okay maybe some spike okay this is at inference time what I'm trying to get across is when you actually look at these things they will give you Pro small probabilities that it's everywhere because it's doing this normalization okay now one thing that people do by the way is something they call label smoothing they take this and they push a small amount of mass everywhere else right so you take the one and you kind of say like I'm going to put a small tiny amount of mass everywhere else and that's basically to account for the fact that your labels are often wrong right you're you contain you know even very popular well-studied benchmarks will have you know three percent of their labels be wrong or something so you can imagine how you would kind of smooth and and why that would be bad when you're training a system if you're like it's definitely not a cat you're like no no there's a small possibility it's a cat I should admit that possibility that's a very different statement if you imagine those two okay awesome so what happens here well the great thing is is like this follows exactly what we've been doing the whole time so we we now introduce the this is also sometimes a cross entropy term right which is equal to this guy but this follows basically our basic recipe which is I said Pui uh equals K Times log P hat uh of Y this equals minus log pyi okay so this is the ground truth label okay so this is in case we don't do smoothing basically our loss to minimize the cross entropy is the same as minimizing the log of our expected probability and that thing has a very fancy name that's a logit and that's the you'll see these negative log likelihood things all over machine learning packages that's what they're doing okay and this equals just so we're super clear it equals minus log of x Theta I dot X over sum X Theta J dot x j goes from 1 to K okay and this is what we minimize that's it and so how do you solve this model just run gradient descent all right that's it right any questions about this um what part of that is to launch it again oh the logit is a log probability great question so this is the this is the terminology for a log probability so this thing comes up the reason I call that is you'll probably encounter that term I just wanted you to be familiar with it and you don't usually predict you don't actually write out the probability functions you don't take the X you actually just take the log of those probabilities and that's what you actually minimize and so you you will use them and they're in log scale so you'll often see like machine learning codes spit out these like you know negative seven negative four or three point two one that's what they that's what they are they're logits you'll see that term logic everywhere yes please uh because the otherwise it would be a maximization yeah it's just to make the function sign so that we have a minimization wonderful question yeah please remember your minimizing yeah what it doesn't look like it has any dependence oh awesome question what a wonderful question yeah it's hidden right here this Theta I this I is the ground truth I right that's what this is this statement is this is the ground no it's just like you picked out that one and then you get a your your loss function kind of like perfectly encodes it if you put in the label smoothing then in fact it's not just one Theta I that's there they each get a weighting associated with them as well but here that was the trick this Yi is the same as the actual ground wonderful wonderful question yeah great question yeah yeah so so here it's the Theta X and then I'm I'm taking exponential but you would also have like an X point over X spin yeah but here for this model I don't do that so if so what you're saying is an alternate model where you take all the logistic regressions and you just say like what's the probability of each one and then you compare them and I'm saying no you do it in terms of the logits here and this is how you bake them off all at the same time the difference between them is not super critical but this is the one we use but it's a great point that they're different so I did kind of by sleight of hand here I said oh this is like you're doing a logistic regression but this again is like saying so if you think about logistic regression as there's a yes class and a no class in the yes class I have the weight is X above Theta T the X this is each thing that this is the weight of every one of those possible worlds and then I'm summing over all of them and so that's why this is consistent with logistic regression imagine a null world that occurred here that said it's either the class one or it's none of the classes and so it's feature I'm just going to default to one because I don't care it could be any scalar the knife gets you exactly back to logistic regression does that make the connection clear yeah so they really are the same I just derived them in a slightly different way wonderful question please um yeah so uh if you've seen so this is a new function I guess for us potentially we have seen it because of the discussion we just had and another guys it actually is the binary cross entropy is the logistic function and so this is a generalization of that and if you've ever seen entropy or cross entropy which I think you know it doesn't matter if you've seen or not this is it right it's just a functional form that we care about it's a kind of a distance between probability distributions I care whatever reason I say this is not because I think there's something mystical here so if you haven't seen entry before I guess this would be mysterious and potentially even if you have seen entropy before because entropy is a mysterious thing um but this is the loss function that you use and it it's the reason you use it is because it generalizes in the way we just talked about I don't think you need to know any of that so please X and Y right there's no Y in this diagram but yeah uh so this here x is a two-dimensional Vector this is a little bit of a weird plot right X is cat as a two-dimensional Vector because I only have two Dimensions to draw on and so I put them there and that's why this picture looks a little bit different than maybe you're thinking about it as like a function or a curve or something but that's that's the difference higher Dimensions but it's exactly right so in higher Dimensions what you would expect is rather than lines which are one-dimensional you'd expect you know D minus one dimensional big planes that were separating everything out hyperplanes and then they would be live on one side or the other and you would care about the distance effectively there and so I'm drawing like the Contour representation of the function right yeah awesome question and then there's no the Y's are encoded as we were just discussing by which index I use right foreign oh awesome question yeah so we'll talk about PCA when I come back to join you and why we use that PCA is a method so the two things PCA fix for you is if you have X's that have different scales or have different meanings like you know if all your temperatures are between 80 and 82 degrees but they're really significant PCA is a way of centering and whitening your data meaning like subtracting off the mean and standardizing and normalizing that and so that's a technique that is very very commonly used in statistical analysis and so we'll talk about that and how to provably find that and what does justifications for here when you're doing things like image analysis actually the the methods have been more toward raw features and raw pixels over the last couple of years where you the things that we're all excited about is to try and have no hand coding in the pipeline you can talk philosophically about why we're obsessed with this but basically the newest models just take the image raw and they try to have as minimal what we call they call it inductive bias but I won't Define that term but as minimal kind of information about the model to learn from them so one weird fact that got me very excited a year or two ago was that we have one model for text and we were using that same model and getting nearly state-of-the-art accuracy on text and images and audio in a bunch of different places and that is the thing that's really interesting and it starts from the raw pixels and it learns The Edge detectors and all the stuff we used to do by hand so that's been the trend here we'll talk a little bit about more about featureprep because that stuff doesn't always work and when it breaks you want to kind of have a library to fall back on wonderful question but that'll be in like I guess week five four five oh my God what a great question yeah what if you can't draw this pretty picture it doesn't make sense yeah that's possible so what if your features are bad right what if it turns out that like your features about cats were like they sleep on couches you're like well dog sometimes sleeps on couches then you couldn't possibly separate the dogs and the cats it's a stupid example but like your features could be could be so weak that they're not able to actually separate your class uh imagine putting a lot more features in and that's why these models that have bigger and bigger Dimensions come in to separate automatically all the different classes but now your real question is like okay well okay there's a fix but I have my features and I train what happens you just make misclassifications and that's actually the default you have a small number of features and then you fit those features and you know you do the best you can so like if a cat jumped over here there's a cat that was here you just misclassified and you'd get it wrong right you go from here over to here and then you'd be toast so that does happen quite a bit sometimes due to label error and sometimes like there's a subfield of machine learning um that is kind of obsessed with this and my students write papers in it there's a great Benchmark called Wilds from Percy and Chelsea and a couple other folks on the faculty that have these places where machine learning picks out the wrong feature systematically like you take a bird that normally is on water and you photograph it with a land background and the Machine learning model is like oh that's a land burn not a water bird there's a lot of that going on so that that absolute 100 happens wonderful question any other questions all right so just to recap what do we do today we went through this exponential family of models and now we've hopefully tied in a bow the fact that we like had this method to our Madness about doing binary and then real value uh we you know we went real valued in binary because we had seen fitting lines we did classification and we tied them all up in these exponential family models we talked about why inference and learning were you know basically the the same in these models that let us generalize to a whole host of them this is the Workhorse of supervised machine learning but the questions that you're asking now are exactly the right questions where do these features come from what if the features don't fit the data how do I get more expressive things you're going to see things about kernels and sem and neural Nets in the next couple of lectures and that will tell you how do you pick your features and how do you get to these more expressive models and that will form the bulk of supervised machine learning then the next section will come to unsupervised and we'll forget the whys and figure out what structure can we get there and that's when we'll get into questions like PCA we'll get into these questions about what are called exponential family models or em models where you have a supervised predictor and an unsupervised thing and this allows you to do some pretty wild stuff like you know fit data from the from quasars and stuff and we'll we'll walk through all that stuff and the fact that we'll also have a thing on self-supervision which is a new lecture uh just this time I guess my student gave it last year but thank you thanks so much for your time attention have a wonderful rest of your week

Live Lecture Transcript
Stanford CS229 Machine Learning I Gaussian discriminant analysis, Naive Bayes I 2022 I Lecture 5

from today I guess um you're gonna see me for at least a few weeks um we're gonna cover um like some more like super starting algorithms and we're going to talk about deep learning and then uh I'll pass on to Chris to talk about Express learning so so I think I'm going to be in charge in the next three or four weeks um and I'm going to use the board partly because I think there is a little bit more memory on the board right like uh like I can write you can you can review things that I can see I I wrote like a like 10 minutes ago even I don't know whether that's you know the best for everyone I think in the past I've surveyed students and someone prefer the board someone prefers the zoom the the iPad so I'll give it a try uh with this but any comments or any kind of suggestions are welcome and we we're open to change the format as well so um but for today at least I'm going to use the board um and I think the the video is able to capture the board almost the same as the the um the iPad I hope um okay so um okay so I'm going to talk about um the so-called generative learning algorithms so the next two lectures will be about this I'm going to Define what does it mean by generative learning algorithms and there are two type of General learning algorithms that we are going to cover one is called gaussian discriminative analysis I guess these are all new words that I have to Define as I'm introducing these things GDA and another type of algorithms is called naive Bayes okay so I guess let me get started so um I'll start by defining what do I mean by generative learning algorithms to kind of Define these terms I think it's useful to compare with what Chris has introduced in the last two weeks so in the last two weeks I think the type of algorithms Chris introduced we call them discriminated discriminative learning algorithms so discriminative learning algorithms so the reason we call them discriminative learning algorithms is the following so in some sense the definition is that if you model or you parametrize the relationship the conditional relationship of Y given X then we call this discriminative learning algorithms and I think you know if you recall this is the the type of algorithm the type of kind of models we considered in the last two weeks right so we model y as a linear function of X maybe Y is linear function of X Plus gaussian noise or maybe Y is linear function of X Plus exponential family or something like that right so for example uh in the most General format in the last two ways can be summarized as you think of the X the Y given X parameters where Theta this is a distribution of Y given X parametric space Theta you write this as some exponential family exponential there's some distributions in exponential family with some parameter with some input ETA and this ETA is a linear function of X right for example you can say this is a gaussian distribution which means ETA and that's just the standard linear regression right so so this is why we call them um discriminative learning algorithms and today we're going to talk about a so-called generative version generative learning algorithms the the basic idea is that you are going to model or parameters here model means is a word means basically means parameterized or you have a mathematical model for the conditional for the drawn distribution P of X comma y a joint distribution of X and Y you know using the simple chain rule you can write this as x given y times Q of Y so you model both these two quantities is this the there's some light is flashing right some should I are you bothered by it or not I'm fine with it just okay no worries okay um I think it flashes after every minute or something uh anyway so you model the drawing distribution by modeling each part of this tool and particularly you model the drawing distribution by modeling the distribution of Y and the distribution of X condition y 0 X and Y are not symmetric Y is the label X is the input and typically they'll have very different meanings y could be something like you know like the price of the house and X is uh the features the all like what you know about the houses right so like the the square feet you know the Lost size so and so forth so um and recall that axis the input or the and and this is maybe something like a label or some kind of class right if you have classification this is about cast class like maybe positive sentiment negative sentiment and so so basically this is the distribution of the input given the label and this is the distribution of the label itself and sometimes we also call this you know a prior for the label a prior for the class or the label because this is what you believe like for example suppose Y is one means positive sentiment Y is zero means you know negative sentiment right suppose you are classifying the text then this is a distribution over two labels where positive and negative and this is the the prior that you have for how many positive examples all negative samples uh are in your data set and and then um so after you uh you mode on paramax this you can learn these two distributions right you can learn the distributions learn P of x and y and p of Y we're going to say how do we learn them and after you learn both of this you are going to still solve the classification problem your goal is still the same you are trying to classify you are still trying to compute so this is the test time you are still trying to compute for example P of Y given X right you're still trying to classify what's the chance of each of the label or you probably want to get the max of y g Max you know we are going to talk about exactly um you care about um but essentially you still care about the relationship of Y uh conditional X and how do you get this you get this by base rule foreign meaning so recall that PO for example y given X is equals to P of x given y times P of Y over P of x so you know this quantity you know this quantity and your you know this I'm assuming you already learned this too right and how do you know the denominator then you can just write this as the denominator is really just the uh you take sum over y P of x given y times P of Y uh maybe just uh for the same quotation let's call this y Prime right so so this is the the standard the um total law of probabilities when you complete the marginal probability of P of X used as the denominator and then you also compute use these two volumes um on the top actually in many cases you don't necessarily have to compute the PO Box we will see exactly how it works but roughly speaking after you know these two things you can know uh after you know x given Y and Y you can know y gonna ask by doing some base rule because by the way feel free to stop me at any point you know just to reach handle us to speak um maybe first it's good so let me repeat the question is it true that the discriminative learning algorithms cannot work on non-iscriminal understand right um no I think the discriminate learning algorithms can also work with other possible uh distributions here so as long as you specify y given X and your parameterize that by some parameter Theta you can in theory you can still learn them using similar type of methodology I'm going to discuss the methodology as well uh um um but if you have expanded family then it's gonna be um there are several benefits for example you know Chris discuss this many properties nice properties of expenditure family if you don't have them then um you don't you cannot use those properties you have to use something else or you can you have to rely on optimization or sometimes it's challenging um depending on the cases but in principle you can you can have other distributions here yeah maybe let's just do this order yeah yeah this is just a general framework so the difference between the two that I can guess is actually you will have parameters because I'm going to parametrize these two distributions and and learn them so um yeah I'm going to talk about that as well foreign so this is a yes so I'm also going to discuss uh the differences you know why like what's the high level differences why you want to do this but I think it's easier to discuss those you know once I tell you a little more about concretely how this works um but so far you are right basically this is a somewhat seemingly Securities way to get P of YG Max right it's not direct right um um yeah I think I'm going to discuss discuss that you know discuss the differences you know probably later in the lecture just because you know it's easier when I have some examples okay any other questions oh would it be possible to write a little bigger please oh sure yeah that's a great suggestion I think that's probably also useful for the recording as well um and also feel free to remind me again because I this this happens to in the past as well like every time after like a few lectures I I stopped writing big you know even after a few minutes sometimes maybe um okay so this is just a very high level introduction um so and just uh so we're gonna talk about two instantiations of this general idea so one is called this one so the difference is it's really just in one case it's a continuous ax and the other case is discrete discrete X so and this continuous guys look it's called This is the gaussian discriminate analysis and the discrete acts we are going to focus on our application which is the the span filtering right so and today I think we're going to mostly talk about the continuous case and next lecture um I'm going to talk about the the spam filtering all right so so so now one example how how do we instantiate this plant um so so for GTA what you do is you say I'm going to suppose X in Rd um I'm going to drop the convention just because here I'm not going to use the uh the bias at least you know in the modeling part I'm not going to use the bias um don't worry too much about it you know it's just though we don't have the X series one I know it doesn't really matter that much so um and I'm so the main thing is I'm going to assume you can say this is assumption you can say this is a modeling assumption I'm going to assume P of x given y is a gaussian gaussian distribution so what does that really mean that really means that you write this you know you say x given Y is following some gaussian distribution with some mean and said Can converts and here note that X is a high dimensional Vector so I'm going to have a high dimensional multivariate gaussian disclosure so and we submit and be some covalent Sigma so um I think it used like a uh it's probably useful for me to briefly that that word um kind of digress a little bit to briefly talk about some Basics about Matic varied gaussian description these are just some very quick review if you haven't seen this um but I'm assuming that you know something about one-dimensional gaussian distribution so just a very quick uh digression so if you have a multi-dimensional gaussian random variable foreign so what happens is that you suppose you have some random variable Z sample from this gaussian distribution which means mu and sigma covarian Sigma so here mu is a d dimensional vector and sigma is a matrix is the so-called covariance Matrix so and the definition so the property you know you need to know is that you know as the name suggests the expectation of the Z is supposed to be the mean of the uh the mean parameter right so and the covarence of the random variable Z which is defined to be the expectation of Z minus expectation Z times Z minus expectation Z transpose this is you know is the The covariance Matrix so so this is how the you know you generate the C from this gaussian distribution parameters by these two parameters mu and sigma and the the resulting random variable Z would have these two properties the mean is Mu and covariance is sigma and and you only need two set of parameters to describe unique like a gaussian distribution um and you also know that um you also know the density of discussion distribution so the density of the gaussian distribution is something like this I don't expect you to remember the formula because I now I remember it after I teach teachers so many times but you know before I taught it I don't think I remembered in my graduate school um but the the formula is that I'm not sure whether you can see this um something like this um and here this is the is the determinant okay great I see some questions um sure maybe I'll start with the one one what does the denominator say what is the denominator so this is 2 pi to the power of theta over 2 and the determinant of Sigma so power of half and I'll write even bigger oh this is just the oh one why I'm doing this oh this is just a definition of the code bar in case you don't know the definition so thank you yeah um yeah I'm just using that as a to indicate this definition um and and by the way this formula you know I don't think we really have to remember it um the most important thing is we have a constant times some exponential of some quadratic form of Z oh Z is a vector yeah that's a good question so this is why this is a little more complicated than God than than one dimensional case right if you are familiar with the randomizable case then this will be still a scared of meal and this will be a long neck together sometimes people write a sigma square right so and the sigma will be just the um the uh um so for one master case this is just a virus and now it's the so-called coal virus and I guess you know if you are um so so in some sense if you look at Sigma of i j this is really just the the correlation between this will be uh the expectation of z z I say the ice chord minus UI times ZJ minus mu J in some sense the entry of the covariance Matrix is capturing the correlation between two coordinates of course you have to remove the mean to match the correlation the right way but you match the correlation of the two coordinates of this random variable I saw some other questions [Music] um yes so x and z are the same thing here I use Z because I want to be my abstract so in a few in later I'm going to have a little more I'm going to I have to change this a little bit uh yeah but this is just the for abstraction I use a different variable the second term is Sigma here so here because there are scalars so that's why I didn't have the transpose so this is a scalar this is a scalar right but and and here the reason why I have transpose is because then I need making Matrix so um I don't know I think some of you probably are familiar with this so I don't want to spend a lot of time on this but some of you probably not very familiar so I I think I used to have some let me show you some other pictures to get a little bit more sense on the covers um let me see how do I connect to this Maybe do they know this um how do I signals anything to them I don't see they are capturing the video the the screen um anyway um anyway these are these slides so it should be oh yeah okay great so it used to be the case that I make slides for this part of the talk I just mix three slides but then I realized that maybe it's just easier for me to show you the lecture notes because then you know where to find them again right so I'm not being lazy here it's just the uh you know it's also easier for me of course um okay so so these are some visualizations of the density function here so the first set of the just look at the figures this is a two-dimensional case right you have for these two and uh and you visualize the density of this um of the gaussian distribution so density you know always look like something like this right so and these are the cases where uh the co-virus is analytic it means that when the covariance is identity it means that so that when the covariance is identity Matrix one one one it means that there's no correlation between any pairs of coordinates right like I and J with ing another same they have no correlation and and the results the um the the kind of the shape of this um discussion is always spherical so basically when it's identity it means that you have equal strength in all the um like like a basically you just have like a on the same strength in all the directions because because like every Dimension like looks the same in some sense um so um so basically that's that's when you um uh see this kind of like very spherical shape of the density function and then you can uh the one thing is that the size of this density function depends on the the scalar in terms of the analytics right so if you have identity then I think this is uh uh the leftmost one but if you make the covalents two times bigger then your density function will be uh supported on in some sense like a most exploring a larger region so that I think that's the uh the last one um and then in the middle one you have a smaller uh covert so in some sense the covalents um is um describing how at least how large this like how large this uh um this the shape of this density function is and also it's declaring two things right one is the the size and the other thing is that what's the correlation what's the kind of orientation of the shape so maybe one way to think about this is that if you look at um the second like a rows of the figures so these are cases where the covariance Matrix are no longer identity and and they're for example in the the third figure here um so you have some correlations between two directions and then you see this the this uh this ellipsoid kind of shape is rotated into that direction just because in that direction the two corners are more correlated so it's more likely that these two chords are simultaneously bigger or smaller so that's why in that direction you have you have more kind of like mass in that direction and you can see that the the difference between these three figures is that the correlation along that direction is bigger and bigger in the first one there's no correlation in that special Direction axis equals to y direction and the second one you have a little correlation so that's why it Tails towards the direction and then in the third one you have more correlation um so so it's even more skilled in some sense any questions so I guess uh maybe another way to look at this is that you can look at the Contours right the um the like of this thing so so basically you look at the uh uh the the level set of of this density function levels that means that the set of um the basically the the set of like points with the equal or equal density right so and then you can see that you get this kind of ellipsoids and the same thing right so so um um so if you have more correlations then this ellipsoid will become you know more tail towards one special Direction so for example here I guess if you can see my pointer so this means that in this direction like a so I think if this is X1 this is X2 right so if you see this kind of Contours then it means that uh X1 X2 are equally are likely to be simultaneously bigger or smaller and so that's why they have correlation uh and uh and if you see in in this one then you're gonna have some reverse type of things right so if X1 is bigger than X2 is likely to be smaller and that's that's when you see this kind of shape um there's no need to you know exactly you know like understand this right so like uh um it's just some kind of rough intuition you know in reality you don't necessarily have to exactly you know uh visualize all of this but these are any questions you know I know sometimes this could be confusing sometimes this could be very enlightening I don't know like depending on but if we ask any questions okay okay so um okay so I guess we'll move on back to the more messy stuff um Okay cool so so I've introduced the multivari gaussian discussion and now I'm going to go back to the gaussian discriminate discriminative analysis so we are going to parameter as x given y as a gaussian distribution so so by the way I think I forgot to mention that here in both of these two cases the Y is always discrete um you can you can make white non-discrate as well but here we're only looking at a case where y the label is always discrete so now let's let me continue with the GDA so so as I said why is this great and we are only going to assume that there are two labels say one zero and one zero could mean for example um I guess I don't know why oh I I think I missed one small thing here but let me just so I guess uh one of the running examples we used to have for this uh uh for this uh gdr application is that you can think of like you have some kind of like um I guess for example cancer classification so like a benign a monument classification so you have some maybe X1 X2 two dimensional uh inputs and you see a bunch of data like this so so these are cases where you have in eye cancer think of maybe X1 and X2 as a measurement right of the patients right so maybe blood pressure or some size of certain kind of tumors and uh and and for every patient or every case you have you know whether this is a benign cancer or not right these are the the Bad Case right malignant cancers so and and the question is that you want to kind of classify this right examples into two classes right so that in the future if you see one more example one more example here maybe you want to know whether this is a benign one or not and the label is basically here let's call this label zero on this label one so that's kind of the the the the target applications we are thinking about so now I'm going to parameterize what is x given y right excellent y and I need to specify two cases where one one case is that what is the X distribution of x given y zero and the other cases there was the distribution of excellent Y is one I'm going to make both of this gaussian distribution so I'm going to assume that x given y 0 is a gaussian distribution and the gaussian distribution has mean mu zero and covalent Sigma so here I mean the high dimension okay so mu zero is in Rd in this case these two and sigma is in r d by D and for the other one my modeling assumption is the same I'm going to assume this as Mu 1. and sigma Okay so the same covariance that's just for convenience I can use different covariance Matrix but here I have to use a different mean because clearly if you fade a gaussian distribution to this part bunch of points and you have a gaussian distribution for these kind of points you're going to have different mean right so that's why I'm gonna have mu 1 here and mu 0 here so mu 1 mu zero Sigma these are the parameters yeah so this is mostly just for convenience and for like you can make them not the same Converse Matrix then um in terms of like the optimization in terms of learning this uh these things is going to be more complicated um so it's still learnable um at least with some Advanced Techniques but it's going to be more complicated so so here is really in some sense a simplification uh simplified assumption this oh um oh yeah so that's a good question so this is like this so you're given this event y 0 it was the distribution of x [Music] and that's a good question right so uh so how do you model the accident y right so in many cases you have you have many many different choices right you have different covariants you know you have different means or you can even model them in different ways so here I think you know at least you know um if you look at the data you see that the distribution of X you know Y is one and X gamma y zero sounds quite different so probably it makes sense to model them separately right if you model the whole thing as a John Golson I think it doesn't look like a ghost that's pretty much the reason okay who so so are we done so we haven't done with the modeling yet because we only model X given y right before remember that we also have to model P of Y right you need to P of y and p of X and Y to know the joint probability distribution and then you can use the base rule so how do we model the P of Y this is relatively easier because P of Y is only a distribution over two possible choices right why I only have two choices zero and one so basically you just have to have two parameters right so one parameter is supposed to model P of Y is one let's call this V and then you have P of Y is user zero let's call this one minus V what's the sum of these two has to be zero so sum of these two has to be one so um and so in some sense you say Y is from this Bernoulli distribution with parameter V this is just another way to say this okay so basically in summarize what are the parameters so the parameters I guess this goes back to the question someone asked this question right so we do have to have parameters even for the general learning algorithm and the parameters are mu zero mu one Sigma and Phi and our goal our next step would be we want to learn these parameters so that we know P of x equals y and p of Y so that we can compute P of Y and X okay so the next part is about fitting parameters okay so how do we learn the parameters from data right so we learn the parameters the general principle is maximum likelihood I think probably you know Chris has talked about this word maximum likelihood in you know probably once or twice in the previous lectures but here the maximum likelihood is a little bit different I'm going to compare what's the difference between this likelihood from the uh from the one that we discussed before so first let me Define what maximum likelihood here means in this setting so by maximum likelihood I mean I first have to Define likelihood so likelihood is this basically the chance of seeing a data given the parameters so it's a function of the parameter so if you have these parameters V mu 1 mu zero mu zero mu 1 Sigma you can Define the likelihood of these parameters this is the chance of seeing all your data foreign given the parameters so you hypothetically think that all the data generated from this dispute distribution and and you look at the what's the density of the of your data under these parameters sorry oh it's even bigger okay yeah sure okay so and let me let me also clarify the notation here so x superscript i I think probably Chris defined this right so we're going to use this through other uh throughout the uh the lecture lectures so x i y i this is the ice example so so we have this data set with other examples I'm only I'm looking at the likelihood of all of these examples under the parameter V 0 mu zero mu one Sigma so for every parameter you have a likelihood and this likelihood uh can have this sounds like kind of complicated but actually you can somewhat simplify it a little bit because um these examples are independent right so you assume that your data are drawn independently from you know uh each examples are drawn independently so then you can factorize this so this is the product of the likelihood of all the examples because you use Independence P of x i y i giving and you can even factorize this a little bit more to say that you can use the chain rule to get P of x i given y i and the parameter the parameters n times P of y i given the parameters note that not all everything depends on on everything else um okay let me I don't think I have a different color so um so here you can have some simplification because y i the distribution of Y only depends on Phi right the MU 1 mu 2 mu zero mu 1 and sigma are described are describing the conditional probability right so y only depends on fee so you don't have to write here these things right because they are the there is no such dependencies and also the same thing x i condition y I only depends on mu 0 mu 1 Sigma it doesn't depend on C so you don't have to necessary write V here even though you write it it's the same so okay so this is the um the so-called maximum likelihood and what you do is you want to say I'm going to maximize maximize this IL V mu zero mu one at the same so basically you say I'm going to maximize so um so the the Learned parameters will be the maximizer of this likelihood function all right if you need to find the maximum you want to find the parameters such that the likelihood is the is the largest so this is the so-called maximum likelihood in our context so uh why the question is why you make this independent assumptions um I think in short you know if I I have a very short answer I think this is almost like always assumed in all machine learning settings even in most advanced settings and and the reason is that um there I think there are multiple reasons you know you can say this is uh in some sense you know one thing that you can imagine is that you do clock data somewhat independently from a very large pool that's probably the simplest way to say it of course there are cases that this Independence is known to for example if you have interruptions for example suppose I first get some data from you and then I do something and then I get some other data from you and maybe these data are not no longer independent or maybe um the second time you provide me data you also look at the first time sometimes you know there's something about this dependencies especially in reinforcement learning like where you have interactions so in those cases we will drop this kind of Independence assumption but in most of the cases we do assume the data are sampled from a large pool independent 2. please find the stuff going right C is a scale yes you are right and the Visa scalar and is also a scalar in zero that's a good question do you have the freedom to change feet yeah uh we are on the fee is a parameter right so you're going to learn feet You're Gonna Learn what is the right thing from date so so how do you learn free so you have to find out the maximizer of this and the maximizer will be when we for example some training that's better using pictures [Music] um you are exactly right you are ahead of me yeah so and but we are going to prove that we are going to show that that's actually the solution so there's a reason for that no you have the very good intuition right the fee is pretty much the proportion of the the positive examples or the proportional positive examples right but we haven't actually so that's actually the case if you use this black adults is right so the maximum likelihood is you are maximizing the chance of the data given the parameters so the parameters are just some you you look at all possible parameters and you see which one which parameter can give the light the most likelihood oh right and uh so yeah like this so so this is the maximum likelihood this is the methodology we're going to use for generative learning algorithm not only today's algorithm but also for next lecture where we have other settings we still maximize select and just to compare this with the discriminative learning algorithm there we also use maximum code and but the meaning of the the phrase maximum likelihood could could be a little bit different so so here you are maximizing the so-called joint the The Joint density right of both X and Y you're maximizing the probability to see um the pairs of X and Y but for discriminative algorithms so for discriminative algorithm so what you do instead is that you're maximizing the so-called conditional likelihood even though many cases people just drop the word conditional when that is clear from the context so in the conditional likelihood is this probability of seeing the the family of labels conditioned on the inputs and the parameter state so and you can also factorize this you can factorize this as so here I'm using Theta as a generic parameter just to be abstract you know because I'm talking about the abstract setting right so you can think of this data as the linear linear model family so and you can still factorize this you can factorize this into using the independence but whatever you do you always condition X so X is considered to be a in some sense a deterministic quantity You observe you don't know how X is generated we don't care about how X is generated you just care about how Y is generated conditional you see X so um and part of the reason why you do this is that you only model y given X you need to model what's the distribution of X so there's actually no way you can do the does this maximum likelihood above in the in the in the in the discriminative sets because the only thing you model is why you can act that's the only quality that you have to parameterize form for so um so so you just go with whatever you have in some sense um right and it turns out that these two are are indeed different you know there are some relationships and there are differences you know which we'll discuss uh uh after I introduce some more uh more examples I think any questions so far this is what we yeah exactly and and maybe you know I think you know um I think this is you know probably the best discuss you know after I give some examples of on the concrete examples but in some sense you can see the differences between these two kind of algorithms and the differences between these two type of assumptions is that here you have more assumptions on the all the data right you you are making some assumptions on both X and Y and here you're only making assumptions on YG Max so so it's really about you know home like the differences will be about you know how many assumptions you impose on the on the structure of your data you know how much like in some sense like there is a whole universe right so you you cannot model everything right so so like so you choose some part of the the qualities you can model and and the decision here is you model both X and Y and decision here is human model part of it and that will cause some differences in certain cases that's a great question so the question was that you know here for the genitive algorithms we have the generative learning algorithms we have assumptions on the features right would that be a problem if you generalize to you know other examples so it depends uh it depends on whether your assumptions are correct or not in some sense right if your exact assumptions on the on the features is kind of gaussian then actually it would provide you more generalization generalization because your assumptions are correct and I need input structures and when your assumption is wrong then it would cause problems so um so actually this is um yeah and this is basically like the main differences right so you um for different algorithms you know sometimes you can have it like as I said you have a lot of variables in this world right because can you probably can even pick some other you know like uh like so basically you have a you can try to Model A lot of mechanisms or you can try to only model a part of it and and what's the decision you know often it's a trade-off if you model too much then you are risking to to model them incorrectly right and if you model two less then you don't have enough um like you don't leverage enough prior knowledge in substance right like if for example if you really know this is a gaussian you probably should not should leverage the prior knowledge um but but you may you may be wrong so it depends the cases yeah this is great questions um I know I'll discuss a little bit more about this more mathematical levels [Music] yeah so so I think the question is you know uh given to me and covariance you know like if you don't know anything else it's the ghost in the best is that question yes I think that's a that's a great question so um so typically you know you are basically right if you don't know anything else then you probably should just model them like if you don't really know me me and covers but on the other hand you know um to be fair you know you know more than the me and the covers right so for example if you really want you can compute the the third order uh correlations between these data points between these coordinates right so in theory you can also because you have so many data if you have a lot of data you probably can model other higher uh higher moments of the data I'm not sure you know the definition of mobile so you look at the higher correlations between the coordinates of the data if you have a lot of data um but gaussian is pretty reasonable assumption and it's still used very often um uh sometimes you people use transformations of gaussian so here we assume they are gaussian sometimes people use like you can transform the Gauss in certain ways but gulpture is pretty pretty reasonable assumption so how do I do the test when Y is continuous is that question yeah so we'll uncover that but pretty much you follow the same methodology you're going to have a different prior or different distribution for white P of Y right so maybe you can model P of Y by say gaussian again you know if you want I'll even have my variables to describe the description the accuracy oh oh so so I guess the question so um in short you know why the why is this critical continuous in some sense is uh mostly decided by your data set right so I think typically if your data set is really discrete right so if you really just have like benign cancer or not right you probably don't want to make it continuous for the same reason as you said you know why you want to make it more complicated right so you have more parameters to learn right but sometimes it's just like your your why is really continuous there's no way you can discretize them or you know meaningful way so um right and also to be fair the the parameters to model Y is often much smaller you have a much smaller number of parameters to model y than the number of parameters to model X for example here if you come if you count so you only need one parameters model y right so even this is continuous you only need one real number to model y probably if you have say for example why is the gaussian description but it's one dimensional right so you only need one parameter but for X it's a high dimensional thing so you have to always use more parameters so so typically it's not a big issue audio make a judgment of how many distributions yeah yeah I think that's a great question how how do you make this judgment how many kind of distributions right so the easiest answer is that you always use two as long as you have two labels uh if you just have two type of things you want to classify you just always have two different discussions two gaussians um of course you may want to go more advanced you know to say even for for the maybe for the benign Kaisers right it's not like really really like all the deny countries are the same right maybe there's two sub populations right so so it does probably require a little bit domain knowledge or maybe a trials and hours you know you could try to generalize this okay so uh let me proceed with the okay so I discuss a lot of methodology so far so now the next goal is how do I maximize this how do I maximize the likelihood right so you need to you need to be able to do this you know in power quality right so to guide the parameters right so this is about computation partly right so what we do is we you know one choice is that you just write down this function uh in your computer and you run some optimization algorithm but you want to do a little bit more than that in math because that will simplify your uh your implementation right so so we're going to simplify this formula so that we can and and actually we're going to do a lot of math so that you the you don't really need a laptop to your computer to compute the parameters to to run optimization algorithm for this right so um so what we're going to do is that um so the first thing is that we know that if you do a Arc Max so we are we care about the arc Max right the the maximizer of this of DC so the the maximizer is the same if you transform your loss function with any continuous monotone function so even either log the maximizer will be the same and tip for the for the purpose of this course this course we Define this using a little L this is the law of likelihood okay while we are doing this no it sounds like we just introduced something even more uh more symbols the reason is that this will make the product to a sub so log of this product log of a bunch of Paradox of range of terms will be equals to the the sum of the log of each of the terms so this will be sum of the log of these two terms and the log of the product these two terms will be the sum of the log of each of them so we log of P of x i given y i um plus the log of p y i given I guess I don't have to write P here for this purpose right so everything becomes a sub and that's that's very important actually because even you do this numerically it's very important to take the log because all of these numbers you know if you do it empirical you see like there are either very small or very big just because you know we call that when you have gaussian distribution there's exponential here so it's kind of pretty easy to see the density function it's pretty easy to be either very big or very small they are not never on the the best scale like you can imagine but if you take the log of it the scale will be much nicer so so the log of the density will be on like some reasonable kind of scaling so that you can numerically use uh and also it becomes a sub so you don't have to do the product so and then how do we proceed you know one option is that you again you can still do the numerical stuff where you can do optimization algorithm to to get the minimizer but here we can actually analytically compute the the maximizer so so the maximizer here how do you compute it um what you do is you I'm going to continue here so um so you really so how do you find the maximizer so there's a small fact I guess probably you learn from the um the Calculus class so if Theta is a maximizer then that means that of some function f Theta I'm being abstract here um so then it means that the gradient of the function at Theta evaluate as Theta is equals to zero so if you are in the maximizer you have to satisfy the gradient zero and actually in many cases this if after is convex then this is if and only if if it's not convex this is still um this is still a necessary condition so for us it's actually convex so it's a it's a necessary and sufficient condition um but for other cases this might be just only a unnecessary condition so because you have this then you can solve the the equation so you can try to solve the equation I'm going back to this is a small abstract fact now I'm going back to this case so basically you say the gradient of the loss with respects to all the parameters should be zero right so like with back to three mu 1 mu 2 and uh and and sigma should all be zero so basically you just have to say by the gradients is zero and this really just means that the partial derivative with back to each of the parameter is zero so now you have four equations and you can try to find the solutions for these equations and and this is I think homework one Q 1 T so in that homework we're asking you to first of all you have to compute what is each of these is right so you have to have an analytical formula for each of this right so what is the the derivative of L with respect to Phi you have to do some calculation to see what's the derivative you have to plug in all of our definition of this p is two P's and you get the the loss function as a function of v a new derived the derivative the derivative respect to Phi and then write out that this is zero and you solve the equations so that's homework q1d and this is a little bit complicated to some extent you know but not it's still manageable and this is you know they are even more complicated things than this in machine learning this is still you know but but at the first time it would be a little bit complicated because all of this has a little bit kind of like complex formulas um right so and what I'm going to do next is that I'm going to tell you what's the solution of this directly so you know this answer of the homework question uh and I'm going to proceed I'm going to interpret while the solution makes some sense you will see the solutions actually make a lot of sense intuitively um and and I'm going to proceed with that oh my god did I switch to that oh my God this is new zero this is thank you so yeah so what's the dimensions of this yeah that's that's a wonderful question so I think often this is a confusion that is pretty often like a um just because sometimes in math they have different things so in the in this class uh the derivative of with back to the the parameter any parameter will have the same shape as the parameter so so this is a one-dimensional parameter so so that means that this is a scalar this derivative is scale and this is the D dimensional Vector mu zero so that means the derivative is Rd and this is in Rd by D ude so this is a zero ISO vector and this is a zero Matrix Okay cool so I need to erase something I guess okay so what other Solutions you know so the solutions are okay I'm going to first Define some notations so uh select u0 to be all the examples that are positive these are the index for the policy of examples indices and wait my back this is U1 u0 is the indices of negative examples okay so under the mle solution the solution will be the following so Phi is equals to U1 over n where n is the total number of examples which is equals to u0 plus U1 so what is this this is really just the fraction of positive examples right so this is the fee you learn so Phi is supposed to be the probability of Y is one right that's your modeling choice and it turns out that if you learn it from data it will be exactly the fraction of positive examples in the data so so this is the most likely fee that can join with your data which is exactly the same fraction as in empirical data um and and of course one minus V will be the fraction of negative examples in the data question okay how do I remember this I have to burn this in my head so one minus V is equals to this is the fraction of active examples yes one U sub 1 is it is the is a set so this set contains all the indices such that y i is equals to what so this is the indices of positive examples Okay so so for example suppose you have here right so this will be the set you want this will be the set u0 and and how do you decide what is fee the maximum likelihood feed will be just you can't common examples in total one two three four five six and maybe 10 examples and you say four of them are positive so that's why fifth is going to be so in this case P will be 4 over the total number of examples 10. and for some reason I'm going to write this p as the photos I'm going to write C also just to this is mostly just for mathematical cosmetically uh you want to make it look a little bit nicer in some sense or more consistent with the other equations I'm going to write next so you can also write this as the following let me explain this notation so this is so-called indicator function so indicator function I'm going to write that one of E I think I think the homework we write it like this you know people different people have different type of brackets but it's the same as long as they defined so one e this is equals to um this is the so-called Indian function for the event e so it's equals to one if e happens and is equals to zero otherwise so let me check whether this um so in this case right so this indicator of y equals one just means that if Y is equal to 1 is equal to one this indicator of that is equal to one otherwise it's going to be equal to zero so so basically this indicator is only one when the label is positive and I'm taking the sum over all examples so that's why I'm basically counting how many examples satisfy y i is equal to one so so that's why this whole thing is just equals to u u y it's probably useful to understand this notation because I'm going to have a little more conflict in formulas than this so this is a four marking subsystem this is just uh I guess on in my mind this is capital uh which is not the Greek lighter mu um yeah I guess in the um yeah when you do it handwriting is not that obvious yeah but there are completely differences right this is a set another is a parameter no relationship at all um why do I started oh let's oh I see I see so that's a good question yeah thanks for us so the absolute value is um maybe I should Define this so this is the side so when you have a set I'm using this as the size of the cardinality of the set like how many items are in the set um this is the notation yeah yeah that's a that's a good question maybe you should take a note on this I think last I was asking this last time as well Okay cool so I'm going to continue with the telling you the solution of this mle okay foreign this is the mle for the parameter mu mu zero this is equals to 1 over this is u0 the SEC the number of negative examples times the sum of all the excise in the set use mu u0 so so this is the sum over all the positive examples and I'm taking some of the the the input vectors the the feature vectors x i so basically this is just the the average the empirical average of X I's you know of a negative axis right so I'm looking at all the negative examples I'm going to take the empirical average of the excise in it and that turns out to be the best estimate for the means of that class oh I see I see yeah that uh good question so it doesn't mean anything empirical average is the same average um yeah there is you know just just think of it as the average there's some reason why I use that just because some other cases here sometimes don't worry about sorry um yeah okay so any other yeah so and and now I'm just gonna I'm just telling you the answer and but this sounds like very intuitive right so like what would you guess you know what's the the best what's the best meaning for this class probably you should just use the average of all the examples at least you know if you see it you know it sounds somewhat reasonable um and um you can guys you know just because these are symmetric you know from the MU 1 is the same thing you're gonna have one over the size of the positive examples times x i the times the sum of the this right so this is the this is the average of positive access okay so and we're going to write this as so I'm going to use this indicator function to write them uh in a slightly different way so I'm continuing here so if you look at this formula you can write this as the u0 the size is equals to as we argued the indicator of y i is equal to zero this is the number of examples where y i is equal to zero because Y is equal to zero means the indicator is equal to what right that's what indicator is saying right indicator is saying is if the indicator is y only if the event is happening so that's why this this is one when Y is zero so this this is why so that's why this denominator is the same as the size of the negative examples so and then the the numerator can be written as equal to zero so you first have this indicator only selecting those examples that are negative and then you take multiply x i and for the second part for the MU 1 is the same you just replace Zero by one so you have and you have you select all the positive examples and you multiply x i so you know why I'm why I'm writing it like this you know one reason is that you know it looks you know a little bit kind of like more um systematic I'm not sure whether you agree with that maybe you don't um another thing is that you know um I think you see this kind of formulas you know pretty often for other cases as well so so it's probably good to unify them in some months in some sense but you know but you don't have to remember any of this you know the I think this this way is the best way to remember them or and any kind of interpreter so you just treat this as a cosmetic changes some cosmetic changes of the former okay and next I'm going to have Sigma so the solution for the mle for Sigma is like this this may sound a little bit complicated okay so let me try to so this is the what is this meal this meal is the meal we have completed above so you have to use the meal you completed about to compute Sigma so these are the means you complete above a mean y i could be mu 1 or mu zero depending on what what's what's y i um and when we do interpret this is that you just look at you can expand the sum into two cases one case is the Y is zero and the other case is y is one so when y i is zero so you have the so those are the Y those are the I's that are in the set u zero and this is x i minus mu zero times x i minus mu zero transpose and then you have you look at the those cases where Y is equal to one and then this mu y i becomes mu 1 and you get this so this makes it a little bit easier to interpret because this if you compare this with the this is kind of the covers but the covariance evaluated on the empirical data so this is the sorry on the on the data set we have seen empirical is empirical is a word that's used to stress that you you are seeing the data sample data so that's I kept using that but you we don't have to use that word so so this is the covariance covariance of excise for those excise in the set u0 for those negative examples so this is the covariance of negative examples and this is the covariance of the positive examples and and it turns out that the the average of the in this sense is is the is the best guys for Sigma it's the it's the sigma that gives you the maximum likelihood Okay so I've got all of this uh parameters so far right so um and now you're going to ask to prove all of these are true and but suppose we already got all of these parameters we can complete them in near Miracle right by plugging this formula because you just plug in all the excise you have all of the data you plug in you get all of these parameters so you've got all the parameters so that's the so-called learning process you learn the parameters and now the next question is how do you make predictions on a new example right you get the parameters how do you make predictions because so if you assume they are different I don't think the formula will be this I I and actually if they are different you can you don't even have a analytical form for the solution of the mle like like the just you cannot Solve IT analytically so here is kind of like for some reason because we are making all of this simplifying assumption you can solve the minimize the maximizer of the mle but it actually is not always the case you can write analytically and when Sigma are different for the two subpopulation you don't have that analytical solution Okay so okay so now we're talking about prediction so let's get it if you want to open some water but you want to understand you know what what is the deny cancer or not right that's your final goal that's that's the final goal of the of the problem so and the way that we do it is that you say I'm gonna output the most likely why so I'm going to Output Arc Max the maximizer of P of Y given to X and the parameter feed mu zero one Etc and note here that this are the solutions of the anole so these are not aperture parameters so I in some sense you can even say I'm obvious notation a little bit just for Simplicity so here this female one mu zero Sigma R those solutions that are computed from this farmers okay this is a matrix right this is a vector this is a vector new theories of vector mu zero is the mean of the gaussian is a d dimensional vector so did I say something here oh okay I guess I erase it right so you assume y given x given y is from this you know from Y is maybe zero this is from discussion with mu zero and sigma so mu zero is a d dimensional Vector Sigma is a matrix no that's T C is the is a scalar is the probability of Y is equal to one and mu zero is the prop is the mean of the mu 0 is the mean of x given y zero and mu 1 is the mean of x given Y is one how to do this yep Okay cool so back to here so this is my methodology I'm going to take the mle so how do I compute this so it turns out that this you know of course I have to use the base rule to get y gonna X because I only know x square and Y I only know why but I don't know what is YG Max so one thing is I have to use phase rule so let me do the base rule for you and it's actually simpler than you may think so because here you are maximizing over y right you are trying to Output which Y is more likely right well it's more likely to be denied cancer or not so basically this maximization problem just have two choices we are just maximizing over two possible choices so you are just taking the arc Max of the two the two point is two scalars they are both probabilities and that's what so just cover these two scalars and which one is bigger and turns out that these two scalars their sum is one because given X in y can only be zero or one so right so maybe let's suppose just for for the sake of simplicity so suppose you call this a and call this B then a plus b is equals to y right and you care about which one is bigger or the a is bigger or B is bigger so if you have a plus b is equals to one and you're taking Max of A and B then what does this really mean it really means that you are asking whether a is bigger than point five or smaller than 0.5 because you're going to choose a if a is bigger than 0.5 right because if 8 is 0 than 0.5 that means B is less than 0.5 so that's why you choose a and and you want to choose B maybe let's write this again sorry a if a is bigger than 0.5 because that means B is less than 0.5 and it's going to be equal to speed if a is less than 0.5 because that also implies B is bigger than 0.5 so so basically the question is that you just care about whether a is bigger than 0.5 or not so going back to this zone I'm doing abstract thing right so if you're going back to this then it really just means that this Arc Max is equals to 1 Y is equals to 1 if the probability of Y is equal to 1 given X and the parameters is bigger than 0.5 sorry my there's a little bit and limited space and if you zero if P of Y given Y is 1 given X the parameter is less than 0.5 so you know which also makes sense right because you know why oh in my back right so which this also makes sense because basically this is saying that if the probability of Y is one is larger then you you choose y you choose one otherwise you choose zero that's it right I'm just mathematically derived that for you um that's it so and if you look at this figure so what's the final decision what's the final kind of like boundary between these two cases this line will be the family of X such that this P of y equals to Y given X is equal to exactly 0.5 so if you if you define this family of axis right this is a family of axis such that the probability y given X is equal to exactly 0.5 and this is called the decision boundary so and on one side of boundary Y is y is more likely on the other side of the boundary y 0 is more likely and the boundary you know you just do some arbitrary type of thing or you just randomly output what you know the boundary wouldn't be very likely to show up it's very unlikely that your Pawn will be exactly the boundary so so it doesn't matter that much [Music] so maybe let me just uh maybe let me just uh quickly because we're gonna have two minutes left let me just quickly say what is this decision module is for the gaussian discriminate analysis right because here what I'm doing here is it's pretty General in sometimes you can see right I didn't really talk about what exactly the parameters are and if you really want to know it know what this P of Y given X is but you have to plug in the parameters you have to use the modeling right so and for G for gaussian describing analysis if you plug in uh you plug in um so what you do is you're following so you do p of Y is equals to one game X this is the thing you really care about so you use base rule so you say that this is equal to P of x you know Y is one and here you only depend on mu one Sigma and you have P of Y is one given and you divide this by P of X the probability of x this is the base rule that we kind of alluded to in the the beginning of the lecture so and then you do a lot of calculation which uh I think this is homework I do a lot of calculation and what you'll find out is that actually this has a relatively simple form so the form looks like 1 over 1 plus exponential minus Theta transpose X plus Theta 0 where Theta is a something of Rd so that zero is a scalar so they are functions or they depend on let me just simply say these are Depends on V mu zero mu 1 and sigma so so basically eventually you get mu all of these parameters and then use this parameter to compute Theta instead of zero and then you get y g Max and that's your probability and then you're on the computer decision boundary let me also do that real quick sorry we're running a little bit late so then you get a decision boundary so so what's the decision boundary the decision boundary is when this is equals to 0.5 and when this is equal to 0.5 is when this exponential is equals to one right then you have 1 over 2 is 0.5 right so when the exponential is equal to one this means Theta transpose X I think sorry let me see I think I need to have a parenthesis here but then we become some abstract here it doesn't really matter that much so um so it means this is equals to zero and and you'll see that you know P of Y is equals to 1 given X is larger than 0.5 is the same as Theta transpose X plus zero is larger than maybe you say larger than zero so so basically you have a a linear function of X that's your decision boundary that's why I keep drawing a line here you know from here you know from the principle you never know why this is a lot right the principle says that maybe this is a some formula of X right that is let's separate this but but the the derivation tells us that at least for this case the decision boundary is a linear function of x they were doing protocol uh so I think I'm gonna have this yeah sorry this is a title here I should have the parenthesis like a yeah I know the signs are not that important um I think yeah we are um maybe you can see with the best way you can come to me to ask the questions and I I can stay here is that the best way maybe yeah

Live Lecture Transcript
Stanford CS229 Machine Learning I Naive Bayes, Laplace Smoothing I 2022 I Lecture 6

so I guess uh last time we talked about um gaussian discrimination of analysis I'll have a very brief review and um and talk about some of the remaining points that I didn't get time to mention last time and then I'm going to move on to another case about spam filtering where we're gonna have uh discrete acts instead of continuous acts so last time we talked about gaussian discriminal analysis and the general idea is that you first model P of x given y and p of Y and what we do is that we say p of x given Y is a gaussian for y is 1 or y0 okay I guess I need to remember right bigger so x given Y is equals to zero is from some gaussian distribution with mu zero and covalent Sigma and x given Y is one is from some gaussian distribution between one and sigma and recall that we have this uh illustrative situations where you have some examples like this these are positive samples there's an active examples and you kind of believe that each of this subpopulation come from a gaussian distribution with different means but with the same covers so that's the methodology we have that's the starting point we have last time and then what we do is that we say after you have this probabilistic model we also we have this P of Y is 1 is equals to V after you have the probabilistic model then you can learn the probabilistic model from data by Noe so so we learn by maximize we take the arc Max over our parameters Phi Mu 0 mu 1 and sigma and we take the r The Arc Max of the the log likelihood you know it's the same as the likelihood you know Mac Arc Max of the log likelihood is the same as the max of the likelihood so I'm just writing the log likelihood which is the log of the probability um of x i given y i plus the sum of the log of the probability y under I guess you know technically under this parameter V mu 1 mu 2 Sigma and I guess technically I don't have to write video just because it doesn't depend on feet okay so that's the the methodology and then we skipped a lot of steps because these are homework questions um and and we told uh and they told you that the solution of this mle problem you can analytically solve it in this case because this objective function is nice enough it's a it's kind of like a quadratic function so you can solve the uh the maximization problem analytically and you get um some formula for uh these quantities right so the formula for Phi was something like um something of this form of this indicator function which is here basically the numerator here is the number of positive examples and divided by the total number of examples and we also have formulas for Mu 1 and mu 2 so mu 1 was something like the average of x i in the positive group in the positive examples so you take the average you divide by the total number of positive examples and you can also have mu zero and also Sigma so each of these has a formula which is a Formula or that depends on the data so this is how you learn the parameters uh from uh from the data and then we talk about given these parameters how do you do the test how do you do the the inference or how do you do the um the prediction right like when you get we already learned these parameters now you are given an example X how do you predict y using the parameters and given ducts right so and we said that the you're trying to compute the arc Max over the two choice of y's and you want to look at which choice of Y gives you the largest probability given X and given the parameter and these parameters are the the solutions you have computed from these formulas right so you compute which one oh sorry not bad this is one you complete which one has the largest probability and also we discussed that you know to know this actually you just have to you know in some sense you you have a decision boundary so uh the decision boundary between the two choices is those cases where is this uh those axes were that is where these two probabilities are exactly the same so where the P of Y is one given X is equal to P of y 0 given X is equal to a half right this is the decision boundary and we have computed the decision boundary which turns out to be something like a linear function so decision boundary turns out that this P of Y is equal to one given X this is equals to um this is equals to something like I guess maybe I'll just directly write out the decision boundary we found out that the decision boundary is the set of X such that uh Theta transpose X Plus Theta 0 is equals to zero where Theta and Theta zero are functions of the parameters that you have learned there are some like um specific formulas uh that um to describe this Theta instead of zero which are the homework questions but Theta says there are some functions of Phi Mu 0 mu 1 and sigma so that's why when you really make the prediction what you do is you say you find out this decision boundary this is the final of X such that Theta transpose X plus zero is equal to zero and then if this quantity is bigger than zero then you'd say it's positive and if this quantity is less than zero you say it's negative this is very quick you know Five Minutes review of the last lecture very very quick any questions if we have multiple labels yeah there will be a decision boundary for multiple labels so um and um you you basically just compute the decision boundary using this methodology you're gonna get a foreign I think if you have the same covariance the decision boundary is still linear um but if you have different models you may have different type of decisions you know it wouldn't be a half because you know you're gonna have multiple choices wise here right so so your decision module will be like uh I think I think it's going to be more complicated so you have to really decide you know when suppose this is like zero one two three or four right so then you really have to just really literally solve this right you have to know when is the case what is the region such that the maximizer of this is equals to say label two so that's that's gonna be something that describes by some linear region some kind of linear boundaries but it's going to be more of conflicted fall you know it could be depending on what probabilistic model you define right so I think if stigma are all the same the capital Sigma all the same I think it's going to be linear and if you have different segment even you have two classes but just take my one and sigma 2 then I know it's as a fact it's quadratic I saw some other questions as well any questions are welcome okay so this is just give you a quick overview a quick review of what we have we did last time um and and you will see that our new when we discussed the new problem we are going to have from similar methodology you define a probabilistic model you solve the mle you get some formula and then like you get some parameters and they use those parameters to predict what's the most likely wise okay so but before going to that I'm going to discuss one important thing which you know many people actually ask in the last lecture at the end of the last lecture they are great questions so the question I'm going to discuss next is that you know why this is different from what what we have seen in the first two weeks right so at the end of the day you have a decision boundary which is linear right so basically at least superficially it sounds like you are using a linear model to decide you are going to use this linear function to decide whether it's positive negative right you compare this with zero and if it's paused if large zero is positive otherwise is negative and this is the same as the the logistic regression that Chris talked about in the first two weeks so why these are why this is different uh from from the uh the so-called discriminative methods that Chris talk about so I think um here is the the way I think about this so um so so if you have GDA on the left and suppose you have like a logistic regression on the right um so first of all in terms of the Assumption they are different so for GDA I guess I wrote The Assumption there so you maybe I just wrote here again so this is gaussian and this is also gaussian something like this and you also have Y which is from Bernoulli and when you do logistic regression then you just literally say that P of Y is equal to one given X you your probabilistic model assumes that this has the form uh one over one plus e to the minus Theta transpose X and and recall that here when you write this in places we are saying that X zero is one right that's quiz assumption like in the first two weeks but suppose you don't have that assumption you're going to have another suppose X doesn't contain X zero then you need to have another set of zero something like this right if you contain the x0 then you are going to have a clean form but they are the same right because you know if suppose let's say for today let's say x uh you drop that convention so exciting contain x 0 then you you're gonna write it like this right and this exactly match the form here so so basically you can see that one thing is that for GDA you assume this bunch of things and you and you found out that it implies that y given X has this form right so recall that okay maybe I didn't write this but like this is equals to one over one plus e to the minus Theta transpose X plus zero right so let's say how do I write this so P of Y is equals 1 given X right so this is a this is a conclusion that we got from the probabilistic modeling right from our mathematical derivation right we conclude that y given X should have this form and in logistic regression you just directly assume it so in in GDA that's a conclusion in some sense right and and I guess you know we have to stress this many times so here you you you model The Joint probability distribution because given if you know x given Y and you know why then you also have the density of X comma y right but here you only always have y given X but you never have anything about X we only have the conditional probability so in some sense the kind of like the the main difference between these two is that on the left hand side you have more assumptions so I think this is the key you have stronger assumptions on the left hand side than on the right hand side and and in some sense the color of the journal um uh the general kind of like a phenomenal General principle about you know how do you model what what part of the world you want to model in your machine learning algorithm right so do you want to model both or you want to model only YG Max right so how do you decide when what how much you want to model the world so the the kind of the pros and cons of the the kind of the trade-off is that if you have more assumptions then typically if if this is also correct assumption if your assumption is correct then uh this pretty much implies you have better performance of course this is a not mathematical statement but I think it's kind of reasonably intuitive because if you have more assumption it means that you you are using your prior knowledge about the world right so here you are using a prior knowledge that x given Y is gaussian and if you use that prior knowledge typically if you use it correctly then you should have better performance like a like you know if I tell you everything then of course you have better performance but if I tell you a little more I suppose I'll tell you everything about mu and sigma and of course your performance is the best right if you tell you a little more about X then you should always have a little better performance so but the problem is with this is that so this is the the good thing about more assumptions but the risk is that you may have wrong assumptions right you might have make a wrong or approximate or kind of like not exactly correct assumptions right right so if you make wrong assumptions then make in most of the cases probably GDA will will be worse out for example what if the data are not really gaussian right so what if this doesn't look gaussian at all and you still make assumption that they are gaussian then you you're gonna have like a um um worse worse performance so and um another thing I want to stress is that even though superficially you see the form here is the same right so Theta transpose so when you make the GDA assumptions you get this y given X of this form but suppose you go through this left hand side and get this and you numerical you compute the source Theta so Theta instead of zero it would it wouldn't be the same Theta instead of zero um as you what you computed from logistic regression so you're gonna get a different side of like Theta and say zero so that's why it makes a difference so so this is a zero from Logistics regression is how do you get it you just directly fake your leading model using logistic regression that's how you gonna say that zero but if you go from here to here then you're gonna first learn the MU the sigma uh the MU 1 mu two a mu zero mu 1 Sigma and then you compute Theta using mu zero mu one Sigma so so that will result in a different set of theta instead of zero that's why it does make a difference um and whether it's better or not I think as I said basically depends on whether assumptions are are correct or how correct your assumptions are probably you never have can have like exactly correct assumption but maybe or something we all sometimes approximately correct then you should do GDA if your assumption is just completely wrong then you probably should do logistical question any questions so far um like we have a different data in Mortal cases so I will just be different again like is it because we're Computing in that equation of the out there directly and using those formulas and then you compute Theta as a function of mu and sigma right so so it's definitely a different process right you're not getting the Theta instead of zero in these two cases using the same process right so in one process it's kind of Securities right you first have to compute mu and then say it's data and the other case you just directly fit this using a numerical algorithm like a reading descent right is it possible that you can get a different decoration X but we have let's say the premise our shoes yep definitely you you may have if you change your assumption you may have a different equation for p of Magnum X and there's an actual interesting point I'm going to mention maybe maybe after I answer are there any other questions okay so then there's actually another interesting point I'm going to mention next is that even you change this actually it's possible you change the Assumption you still have the same formula but on the right hand side so so you can have both you can like if you change the Assumption maybe you still have the same formula maybe you still have a different formula so so this is a comfort case which I think that I think what I said is actually even more surprising right so you change the Assumption on the left hand side you still have the same y given X on the right hand side at least the same form so so this is a example so I guess here I'm looking at uh I think one dimensional so suppose X is one dimensional just you know it's not very important like exactly so so suppose you do x given Y is one is from the so-called poisson distribution um wait how do I personally distribution sorry and then you do this I must misspell this this works sorry um but you do this so you change it's no longer a gaussian it's um some other distribution and um oh I guess X is a is in because this is a personal description so it has to be integer something like integer um and and then you still have y is uh P of Y is one is equals to V right so we change our assumption and then this actually still implies that P of Y given X has this form one plus e to the minus Theta transpose X plus zero so still the form looks similar of course you know if you really numerical computers it would be a different state and say a zero because Theta and say zero here I'm just writing them as a as a generic variable right but actually they are they are they are they have meanings right Theta is a function of Lambda one and lambda zero and so that zero is also the function of unknown one and lambda zero so the form is still same um but you could have like um numerical if you if you use this model in terms of instead of GDA you're gonna get different state and zero so so a linear form doesn't necessarily mean everything right uh it also you know it also depends on how you learn this linear function so you have actually here we have already three ways to learn it where you can use this this model we can use the GDA we can use the largest equation they will all give you different Theta and Theta 0 as a as a final result and which one will be better I think you know if you compare GDA with this poisson version of the the standard floating algorithm then I guess the answer would be that you know probably depends most on whether which assumption is more correct more likely to be correct of course there's also some type thing here because here your your thing is like and but suppose you have a different model which also deal with like R like you know if we basically I'm saying like when you compare it okay forget about this axis in anything I suppose you don't care about that differences then which model will work better probably depends on whether your assumption is correct or not or which assumption is more likely to be correct and and when you compare the general following algorithm with the discriminant one I think it's the same thing right so if your generative assumption is more is likely to be correct then you should gain something from it otherwise maybe you should just use long distal question I think in some sense like at these days you know if you look at um um and also another thing is that um okay so um so and and also um maybe a little more General discussion is that um in some sense your model has two source of like a so in some sense they are like in some sense you have two sources of knowledge the model learns from two things in some sense so one thing is that your assumption and the other thing is you have data right so the assumptions means like how do I probabilistically model all of these qualities and data is really just what you see right so if you have more data of course it's good right if you have more assumption if the assumption is correct then that's good um but on the other hand suppose if for example you have already a lot of data then you have less need to use prior knowledge because your data already are very telling right so like the data is kind of sufficient for you to to kind of like extract whatever information you want then you don't really need to use prior knowledge because if you use prior knowledge you always have a risk to use it wrongly right so so basically in some sense I think the more than our trend is that you know like we're going to talk about the new artworks and deep learning um so in in two lectures the Modern Trend is that now we're in this setting that we have more and more data for many applications and and and then that's why the modern techniques you know like deep learning new artworks those techniques you know use fewer and fewer assumptions about our data so just because you know it's not really worth it right so like I have to think about how do I model my images right suppose you apply these two images right you have to have a model for X for the file image you know does it really work the effort to do that you know probably not you know of course it depends on cases but if you just want to First Cut results you don't have to model your X because modern X is very difficult you know it's very challenging and you may make mistakes so so you probably should just directly go for the more pull off like a discriminative analysis type of approach right so you just directly model y given XP accessor image right but in the in the um in some other applications for example if you think about medical applications right all or some of the other applications of machine learning where you don't have enough data in those cases I think still you have to kind of use as much prior knowledge as possible um and actually many times people even do even much more complicated modeling of your ex right so maybe you can use some other more advanced ways to model your ex because you know how does each chord of X what each coordinate of X means and you know what's their relationship and you put all of this prior knowledge into your modeling for x and then you get finally some wagon X using this machinery and then you predict and that's that's more likely to work so um yeah I guess that's the that's another thing is that if you use more assumptions then you are specializing to your application right that's another reason probably why in the modern time like people somehow don't do this kind of use these paranoids that often because I guess probably heard of me right works and one of the kind of magic about it is that it works for many many cases without much customization right if you use prior assumptions you'll use more assumptions you you are you are you have to kind of like use different assumptions for different applications because for different applications their data probably have different structures you so you have to do it one by one and that's actually what people do um a lot of times right so they look at their domain their questions and and study the structure um but these days you know like as you'll see like when people use device works because you have enough data and you just drop assumptions and you make a model kind of very general not very not specialized at all and you supply it to everything just without thinking much about what the data look like so uh yeah so I guess that's a you know you will talk more about new artworks but this is the a preview or kind of connections to what we're going to talk about next um another kind of like a big picture is that you know one of the reasons as I said you know in some sense I I was saying that you know this kind of GDA analysis is not used that often um at least not used as often as before right before you have to use these kind of things and now you can at least you have the choice to uh to try something like works and and because you have more data so um but still I think if you are able to model the ax you know in many cases you can do better so and also in some cases you just don't have why so even even for example when you have images right so sometimes you don't have why at all you just only have X and in those cases you just really have to model X because that's the only place where you can get information from it and another possibility another cases is um uh we are going to talk about languages right like uh especially like this lecture I'm going to talk about language as well but you know later when we're also going to talk about languages you know solving language problems with new artworks and they are you know you're just getting a kind of a um like a lot of like text from the from the internet right and there's no labels there's no way nobody's tell you like which like which web page is is about which right so you just have like raw attacks you don't only have acts and in those cases you really have to model X3 there's no way you can get around this so so so so still like modeling acts is is very important it's just like um for example it's less important for certain kind of applications because we have more data any questions thank you Okay cool so I guess so now I'm going to move on to um the next uh uh the next uh question so um I think the the question is this the so-called one on classification so you are trying to understand whether a piece of tax is a spam email or not right so like you have an email spam filter and you want to know whether your email is a spam or not and we're still going to do generative learning algorithm and and we're gonna have this great ax so this is another example how you do this challenge for learning algorithm your model X given Y and you execute this like a pipeline in some sense and and learn something out of it okay so um so the first thing so I'm going to you know get into a little more details you know how do we really approach this question so the first thing you probably have to what okay these are just examples um right so I guess um um so the first question uh to a first question we have to do to approach this is that how do you represent a text right attacks are symbols right like a ABCD right so um you need to make a numerical at least to to to to to to make the computer recognize them right so to in some in some naive way at least right so so the question first question is how do you change the tax to some you know acts maybe you call this feature right this is a um You can call this feature vector or or representation or something like that so you want to change this to X in some Dimension d e and then you model X so so first question is how to represent text so there are many ways to represent text so um so the way I'm going to tell you is a very naive way this is like a um a probably I shouldn't say naive like but this is like a very simple way like uh on this stage we're gonna have like a you know if you really deal with the taxi you're gonna use a more advanced deep learning based approach which we're going to cover a little bit in the in probably three or five weeks so um so this way so here the way that we do it is very simple so what you do is that um maybe I should have some so what you do is you say you have you first look at the vocabulary suppose you have a vocabulary of maybe 10K words so and suppose you say you list all of these words in your sequence based on alphabetical order I guess if if you open up a dictionary the first letter the first word is for probably always a I think the second you know are coming to some dictionary the second word is this word otherwalk I think it's a kind of animal um and the third one is uh the wolf I think it's another kind of animal something like this and then you list all the words you know and maybe at some point you're gonna have a word book and eventually the last word I think in many of the dictionary is this this thing I don't even know how to I don't even remember how to pronounce it I think I used to know when the first time I teach this lecture and then I forgot after a few years um anyway so you listed all of this and and then you say that um um you have suppose you have a piece of text right so maybe say suppose you have a sentence or maybe an email suppose this email just has one sentence uh something like I buy a book so you want to turn this into a vector and how do you turn it into a vector so the way that we do it here is that you turn it in a vector that is of dimension um this axis of Dimension d where let's say d is the size of the vocabulary T is equals to the number of words so and then on this Vector that represents um piece of uh this sentence is going to be a zero one vector so X is actually you know it's really from 0 1 to the power d there are only two choices and every entry so you have so many entries and what you do is you say if this word shows up in the sentence then you have entry one in this entry so the word a shows up in the sentence then I have one here and the artwork doesn't show up in that sense sometimes I have zero and then at some point you have this corresponding entry book the book shows up in the sentence I have one here and maybe somewhere I think there's a word probably I here in the list and then that one would also have a one that that word also corresponds to one and for all the other entries that all the other words that don't show up uh in the sentence you just fill in zero for the corresponding entries so and you call this x your representation or your feature Vector uh for uh for for this email for this sentence so basically technically I'm just going to say that x i is equals to one if and only if uh the ith word occurs in the email so there are actually many other ways to encode even before you know using deep learning techniques um but but this is probably one of the simplest one and you can see that this this representation of the sentence is in some sense like a super um I guess like simplistic because for example you don't care about the orders of the world right suppose you have another sentence I a book by right that sentence still has the same representation just exactly the same and it doesn't care about the frequency of the word for example suppose I have a sentence I buy a book and a a kind of pencil then of course the the representation will change but this two word a and a here you know will be kind of you will still have a work according one here it's because the word a shows up in this sentence but you don't care about how many times the word a shows up in the sentence so so you don't care about the frequency of the words in this sentence you just care about whether each word shows up so um and you know there are many other proper issues with this like uh what else um yeah I guess probably these two are the most important thing where you don't have to order and you don't have you don't care about the frequency um but that's what we're going to deal with because this is easy and you can um somewhere kind of like do all of the math uh with this kind of model Okay so now what's the next question the next question is that we need to build a generative model for X gaming y and we need to have a model for y and then we do mle and we solve the parameter so and so forth so [Applause] so basically I think I can just erase this and now I'm going to redefine experience right so that's what I'm gonna do okay so let's take um and how do you proceed so now because this x now is a binary Vector it's only taking 0 and 1. so you need a distribution that can generate binary vectors right so you cannot use gaussian here um and the kind of the techniques that we are using here is the so-called naive layers so what does this mean is that um this means that you just assume Max 1 up to XD or maybe I'll erase this you know are independent conditions on y so given y you just independently draw exponent after x d of course this is not realistic right this is definitely not exact you know how realistic it is I think that's subjective but at least this is not exactly how people generate emails right you are not saying that I'm going to generate a spam filter I first decide I'm going to generate generate a spamming email and the first thing I decide is I decide why and then after I decide why I just trying to reward randomly like like right that's probably not what how how people write spam emails right so and also that's not how people write the the usual like good emails so um but it turns out that many in many cases these kind of assumptions are pretty um already pretty good so in the homework actually um actually we haven't decided whether we are going to include that homework question but at least you know there are there are cases where um you can see this kind of things can be very effective right actually if you just really use this model even you make this kind of crazy assumption and you learn some parameters and use this model to expect on classified spams I think you're going to get more than 90 accuracy maybe these days you know as of like a 20 2012 maybe it's not that effective because all the the spammers they are they are adversarial right so they know what your prediction algorithm is they can change their algorithm to kind of fool you but but at least this is a reasonable one if you go back 10 years ago for sure like so um so so it's kind of interesting right so even you make you know obviously kind of not exactly the right assumption but sometimes you can still because the Assumption problems somewhat correct you know to some extent you can still get a useful kind of outcome from it and for our purpose I think here um I guess you know to some extent I'm not really that um I don't care that much about assumptions I think it's more like I'm trying to demonstrate the methodology um like how how do you like I just want to give a new example where you execute this probabilistic model this flow this this pipeline right um and show how how to solve them one example right so the question is how how does the text the lens of the text matter right so here um in so one interesting about this is that in this representation the lens of the text doesn't really matter you can encode any lens into a vector of Dimension d which is you know you can say this is a good thing or bad thing you know um um but but so so basically you can encode any lens um any sentence or any documents into a single vector and how do you how to decide which uh what is the window size you know here I don't think it matters that much maybe you just take entire email um yeah of course you know if you change the the the I think I think you should you should just include the entire email because that's the the unit you are working with right like for every email you are classifying whether it's a Spam or not you are not classifying it whether a sentence is of spam or not so that's why you treat an email as a single example okay all right x12x3. does that mean that like if you want like One X appears that tells us nothing about whether another X is likely to appears or does it mean that all X's are equally likely to appear like one y material um I think it's it's more about the it's more the first okay so so because I do like certainly not all the words are equally likely to appear right so I so basically I'm assuming that given y given you have decided that which whether this is spam email or not um every word you know is is uh is they are they are independent with each other but but they they may have different kind of probability [Applause] okay so I guess let me proceed so so what does this really mean okay now I'm going to do some math right so to kind of expand this and parametricize it so this really means that you have this P of X1 give an XT given y you write this as P of X1 given y times P of x d given y and now I I can I just need to parameterize each of this problem distribution by some parameter so and if you think about this what is this uh this is this is really just the distribution of Bernoulli distribution because X I can only have two Choice zero one so basically you just have to describe this probability by two numbers right I'm actually by one number right so so basically what you do is that you parametrize parameters of the model is you have fee on say j so there's some in the index which I'm going to explain in a moment you say this is x j is equals to one given Y is equal to one so basically for y is equal to one you're asking you know what's the probability of x j is one right and you you denote that probability as this and then once you have this you know the probability of x j is equals to zero given Y is 1 is going to be one minus v j given Y is one and this uh this um this thing is just a notation it's not like a um it's equally the same if I write J comma one uh I just like I write this subscript because it's a little bit more intuitive but it but I just I just need an index in some sense doesn't make sense so basically for every J I'm going to have a parameter for either J and and one I'm gonna have a parameter that's called Phi and this parameter is in 0 1. right so and and this parameter describe this distribution and for y is zero I'm also going to have a parameter so so I'm going to write this as J given y zero so this is the parameter for the distribution of x j given y zero yes it's between 0 and 1. this is between this is inter this is uh the bracket uh the hardback okay okay so so basically I'm saying that if I this with this parameter and this parameter I can describe all the all of this I can I can write out all of these numbers because I I describe all the quantities right because for example what is p of x j given actually 0 given y zero this is going to be equals to 1 minus V j y is zero okay so and then I also have need to have a a like something for this to parameterize the description of Y we call that we call this V before right in in the in the GDA case and not just for the for the sake of like a distinguishing it from the other fees I'm going to call it v y but this is the this serves as the same row as fee uh in before in a GDA case any questions foreign [Applause] of the parameters and you and this is the probability of the data given the parameters so what are the parameters the parameters of v y is one of the parameters and also all of these fees VJ given y 0 and v j given Y is one so basically I have V1 given y zero up to 3D given y 0 and then fee one given Y is one to Phi d y is y right these are all your parameters so on my likelihood you know here there are two um uh waste I can expand this so the first thing is that because by definition the likelihood is the product of the likelihood of each of the example because your all your examples are independent this is not naive place yet this is the examples I implement so you can just write this as probability of x i y i given all the parameters and here if you are careful then you know uh okay so it's basically all the time I guess all the parameters I'm going to write I think in my notes the notation is this so but I think this really just means this is uh just a convenience notation that denotes all of the parameters this is the same as this um okay and then you first you so so far is the same as the GDA and then you can also do the chain rule to make this x i given y i conditional parameters okay given the parameters and then times P of Y I gave me the parameters so when I use dot dot dots I just mean all the parameters of course sometimes you can drop some parameters because they are not they don't matter and then I'm going to again factorize in the dimension of X Y now I'm going to use my G like this naive face assumption right which is the factorization across the coordinates of X right we call that this is x sub I is the coordinate of X the superscript I is the iso example so so what I'm going to do is that I'm going to use that assumption for each of the examples so what I'm going to cut is uh I from 1 to n I'm going to put this in front just to make a simple make it easier um and if I'm careful I I only have to write Phi right here because the description y only depends on v y and then I'm going to factorize this thing across the coordinates so I'm going to have a product um across the corners have D coordinates and then I have P of x sub j i is the gist coordinate of the ice example given the label for that Y is example and all the parameters V j y just means I guess maybe I'll just uh so v j y this just means a shorthand for this family of parameters as a mix maybe I was just sorry this is a bad notation um so v j y just means a shorthand for this collection of parameters Okay so [Applause] um [Music] so you mean here um yeah that's right so right if you only look at Yep this J and this J yes you only care about the you just care about the j under there's the fixed j under the Y is 0 and Y Square that's great yeah right so so so we have two times that we factorize this probability so so the first time is here so here I'm using the fact that all the all the examples are independently sampled so that's why I I see the drawn probability is the overall examples is is the product of the probabilities of each of the example I know for every example um of course I first do the chain rule to get x given y That's and then I factorize this one into this product again and this is the level of the knife phase this is using native phase Okay cool so and then so I guess you can expect you know what we're going to do we're going to maximize this and we know that if you add maximize this it's the same as maximize suppose that's called this L right so max minus L this is the same as Arc Max of log l and log l is going to be a sum of the log of this probability so log l will be a sum you turn all of this to sum and you have to log in in front of the terms right so you have log p y I can v y Plus here we have a double sum sum over I from one to n sum over J from 1 to D and the log of this and then you analytically plug in all of this right so for example for this one you can you know what is this right this is equals to what is this this is equals to v y if y i is one if this is equal to one minus v y if Y is equal to zero right so and for each of this you can write them as a formula or for of the data and the and the parameters and then you you do the maximum likelihood so the maximum likelihood uh I guess I'll also just tell you the solution um so if you write look at the gradient of l is zero right this is the right this is the con it's a sufficient it's a necessary condition for for you you are being failed to be a maximizer okay I should write why and you compute this gradient and you solve this equation this is a family of equations and then this solving it gives um some formulas for the parameters on your recovering so the so the final solution will look like this v y is equals to um right this is pretty intuitive this is the fraction of positive examples actually it's the same formula as we have seen for the GDA and then fee j y is one this is the probability to see XJ is one given Y is one it turns out that this is also something simple so you look at maybe let me write down the formula and then interpret it so what is this numerator this is the number of occurrences of ice word right it's only one when the eighth word the ice example contains the J's word right so the J's word right this is x j i is one means that the J's word shows up in the ith example in and and you also require that the iso example is positive example so basically the sum is the total number of currencies of jth word in positive examples and and this is the number of positive examples so you can see that you know even though we have done a lot of like calculation and modeling identify the the formula is pretty intuitive you are in sometimes just counting it's kind of like something about counting right you're doing some statistics right you're counting how many times the jsword shows up in positive examples and you divide that by how many total parts of examples they are right so for example suppose like the word book shows up in 10 positive examples and they are they are like a medium positive samples that means this is five over a minute which kind of means that book doesn't seem to have much correlation with past examples if it is this number is smaller if this number is small it means that it's unlikely to see the J's word get impossible so when it's unlikely you know it's unlikely because partly because the data they don't show up so okay and for the negative examples is the same so you just the right to um it's kind of symmetric so feel of J given y 0 is equals to on something like I guess you can guess what the what it is right basically just change every the value of y to zero and any questions [Applause] okay so um okay so basically we are done with this um at least uh we are almost done there's one small thing that we have to address but in terms of the isometer parameter we are done so and we got a parameter another prediction time as before right so we'll do the prediction as as usual you want to compute P of Y is 1 given X right and if this number is larger than 0.5 then you say this is a positive example if this number is less than 0.5 you say this is an active example so we have to compute this and how do we compute this you know this is again as in our general methodology use the base rule and divide by P of x so this is still the same but there is one small caveat here which is that what if you have a zero divided by zero in situation so before we have gaussian the density no matter what you do the density is always non-zero at every places even though sometimes it could be very small the density could be very small but still your PX in all of these quantities are like all positive it's strictly positive at least you're gonna get the ratio here but here there might be some cases where your P of X is just literally zero and why that can happen I guess maybe let me just give you an example so so you may think that some example just never shows up just because of some um I guess let me show the exam cases right so suppose maybe let's say suppose so suppose um maybe the word artwork never appears in in changing side I never claim that this would mean that this would mean that P if you have a but your test example content continent so let's say Test example let's call it X contains it and now I'm going to claim that P of X will be considered as 0. um why I guess let's um some will simulate this algorithm and see what the fee will we're going to compute from this so otherwise hard work is the second word right so your so J is 2. so um and you know x2j X2 I is zero for every eye this is a mathematical translation of for every example the second word never shows up that's why the x2i is zero and when the X2 is 0 and you plug in it into this formula that tries to estimate this parameter suppose let's try to ask me the parameter V two Y is one right this Parliament intuity means that How likely the second word will show up in a positive example and recall that you know this formula is really about you know the total number of occurrences that is where shows up and divided by total number of positive examples so this will be zero because no occurrences of the second word divided by the total number of positive examples and this will be zero that's still fine um so far it's not a problem so zero divided by a positive number that's fine and the feed to y 0 is the same 0 over total number of negative examples this is also zero so so basically according to your uh estimate male estimate this this word otherwise just cannot show up at all right which makes sense because they didn't so it didn't show up in the tuning side you know you you just you know estimate you also say it shouldn't show up at all in this under this uh this set of parameters so but that's that's a problem because now if you compute P of x for example X it does contain the the second word then you're gonna write this as P of X so how to compute this you use the the total law of probability you say this is equals to case when Y is one plus the case when y0 and of course this is a positive number this is a positive number that's fun but this one is equals to maybe I'll just this one is equals to the using naive base this is equal to x j you know Y is one and you have some a product over J from J to d right and now I know that my X2 is one because this word does show up in this email and that means that P you're gonna have P of X2 equals to 1 given Y is one as the second term in this product right so you're going to have this term shows up in this product but this one is equals to Phi 2 Y is 1 which is equal to zero so just because of the second word you know according to your model is not supposed to show up but it does show up that means that this example just does have zero probability and your probabilistic model so that's why this is zero and for the same reason so this one is going to be equals to y0 and also you have this term P of X2 equals to 1 given y 0. and we call that under a probabilistic model you learned you just think this word cannot show up at all right the chance is zero so that's why the chance to see this word shows up is zero so this is zero so that's why this is also zero so because the zero terms eventually I guess if you because there's a zero here there's a zero here so you get zero just eventually so basically you conclude that this example which is n't supposed to show up like this example has zero probability under this probabilistic model that you you learn so and then that's a problem because now this P of X is a zero this is zero so you have something divided by zero actually this is also zero if you think about it because this is just the one term the numerator is just one term in the decomposition of PX when the numerator is just this term and a p x is the sum of the two terms so both of these the numerator and the denominator they are both zero and you have the zero divided by zero situation and now and what you do so this is a this is the issue and this is a reasonably realistic issue because sometimes you just see a new word in your test example right you haven't seen this word at all in the tuning site so on the way we deal with this is so-called uh LaPlace and smoothing in some sense this is a way to introduce a little bit prior so that you don't 100 trust your training site so so basically what we are seeing here is that you trust your trainings are just 100 like religiously in some sense like a like a like you uh you haven't seen any word the other the word artwork right in the tuning side you just and because of that you trust it you just say this word the students show up at all that's why if you see this if this word is in this ax right so then the probability of X is to zero so so what we are going to do is we're going to say okay just uh you know maybe we shouldn't trust the data exactly we're gonna allow it to allow any new word to show up a little bit with some small chance and and it's in some sense this is a local adjustment um um by using some prior knowledge which is called LaPlace foreign just to the best way to describe this method is start with something abstract um for the moment let's forget about that for the moment and just think about the abstract question suppose you have um so simple simple example maybe you can call this example or abstraction in some sense so suppose you think about you know your estimate um the bias of the bias of a chord right suppose you have a call and this coin is biased it's not 50 50. um so how do you know the the bias of the chord or in mathematical language it really means that you have a random variable Z which is from Bernoulli um where with a parameter fee and this fee is something unknown right it's not the half and you want to know what the fee is and you want to know it by looking at some data right so you draw a few copies from this distribution and you want to know what's the um uh what's the what was feed you want to ask me feedback um by using the data and you want to solve this problem right this is still a probabilistic model we can still do the same thing where you can write out a probabilistic you can write out the mle and you can write out the you can maximize the Moe right so let's uh maybe let's try to do this just uh so suppose you have like maybe n trials and let's call this you know Z1 Z2 and z and and each of these is either one or zero something like this right or maybe I can see my nose is called tail has so I'll just continue something like this so and you want to estimate what fee is and if you follow our general principle right we'll try to write out the likelihood then the likelihood what is the likelihood foreign so the likelihood of fee right of the parameter fee um is the chance to see this data set given the parameter fee so what's the chance to see this data set the chance to see the first one is one minus V right a chance to see the second one is is one um I guess tail means I think I need to Define Teo means what tail means zero let's say has means one right so so the chance to and you have a uh the the the probability to see one is Phi and probability c0 is one minus V so that's why the probability of to see the first example is one minus V and then you time one minus FIFA second example when you multiply a bench and then you multiply fee at the end right this is the left node and and if you organize this right you count how many one minus V they are how many speeds they are this will be one minus V to the power of the number of uh uh tails and times V to pause actually if you really look at this example you will see that the formulas are very very similar actually this example is a toy case for that in some sense um okay so you get this and then you can um take the arc Max of this like log likelihood you take the arc Max of the log likelihood so the arc Max uh maybe let's call this IO fee so the arc Max of log of LV if you solve it you are going to get the following so it's going to be the number of has over the number of has plus the number of tails which also makes sense because you know this is basically empirical frequency of seeing the house I just mean like the the frequency of that you see that has in the in the tuning set right and that's your most likely estimate for uh for fee Okay so and [Applause] right so so okay so far everything seems to make sense right so but now let's consider a somewhat um kind of extreme case so what if you see all the examples you see are Tails right and you don't have a lot of like suppose you just have three Jaws Z1 Z2 and Z3 and they are all tail so according to this formula you're gonna get on the fee the best estimate for V is 0 over 0 plus 3 which is equals to zero but you should do really trust this right so if you do really trust that this this coin just never give you a hat right what does this mean this means that this coin just never give you a hat at all forever right she didn't really trust that um you know this is a little bit subjective right you mean you know if you are really really trust the data you probably can say yes but you know maybe you have some prior knowledge that most of the coins are not that crazy right so like you probably should at least have some chance to see the hat right with some chance so um so in some sense you can say so basically on the flip side you can say okay maybe this is some coincidence right it just happens that you see storytelles even this fee is a half right seeing this example seeing these cases is the problem to see this case is is at least one over eight right it's something like one rate so so maybe it's just Coincidence of the data set so maybe you shouldn't trust the data sets that much um so the so-called Law plus smoothing is is a way to in some sense incorporate a prior so that you you say look my coin shouldn't be extreme shouldn't be too extreme like this so so basically if the LaPlace moving refers to the following estimator so this if you use a plastic smoothing you're gonna have a different formula your fee will be equals to the number of heads plus 1 over a number of heads plus the number of tails plus two so this formula you know you know I didn't tell you any like a mathematical justification actually if you really look in the literature they are mathematical justifications so far I'm just determining the formula but it would solve this problem right like at least to some extent because for this particular case you are gonna get one on on the numerator and four um for the denominator so instead of getting zero you're getting one over four so still you you say okay the chance to see the head is pretty small right it's smaller than the chance to see the tail but you don't have a very extreme estimate so and and you can see that this LaPlace moving is mostly useful when you have not enough data right if you have a lot of data then this plus boosting is not doing much right maybe let me give you a kind of a example for example suppose you have a big data where the number of has let's say I guess I'm making up this right so 100 a number of tails is 60. so if you use the standard approach right if you use the the the standard approach or maybe I shouldn't call like the vanilla approach then this is like a the fee would be equals to 60 over 60 plus 100. right this is uh what is this this is like a I don't know what I say like this is something like this and then um if you use the LaPlace smoothing then this fee will be 60 plus 1 over 60 plus 100 plus 2 which will be um 61 over 162. this is 60 over one 60. and these two are just those very similar just because the one whatever you change here one two right it doesn't really matter that much because the the dominating term is the six and a hundred so so sometimes you you achieve a like you choose you achieve a kind of right balance right if you have enough data then you're prior or like your LaPlace missing is not doing much it doesn't really change much you trust your data and if you don't have enough data then La plasma thing would um would try to make it not too extreme we'll try to make your estimate not too extreme okay [Applause] so now let's go back to our problem so let me see where is the best way to provide this um oh I think I erased them oh I erased the formula but I'll write it again foreign [Applause] so going back to our spam filtering thing I guess actually there is a there is a there's one thing that is left here this is our estimate right and our other estimate was something like VJ wise one is equals to am I writing the super super I think this is I not that right so if you apply this to uh our case so you can recall that you know in this case it's kind of like you are saying that the numerator is the number of times this word shows up in a positive example and and the denominator is like the total number of positive examples right so in some sense the knowledge is that this denominator is very similar to the number of heads and tails because because the health means that this word shows up that tail means this word doesn't show up so and and here the the denominator is like the total number of times the total number of examples positive examples um and here the the the the numerator is the kind of like the has right so basically has means that the words show up in positive in a positive example and tail means that the word doesn't show up in a positive example so that's why this is like has number of heads and this is second number of has a plus number of Tails and if you use a lot plus more thing then um you're gonna add one to the denominator and you add to the numerator and you add two to the denominator so that's the that's the LA possible and the same thing for the other formulas you're gonna get add one and I2 here so that's the uh LaPlace moving and while this solves our problem it solves our problem because now we just never phone we just never estimate any parameter fee to be exactly zero right so recall that when we have this uh um artwork issue right so the issue was that these two parameters for the artwork was exactly zero um yeah let me ask um that's a fantastic question so the question was that whether you want to do the same possible thing for the fee why like fee why was the single scaler to describe the the problems of why um to describe the uh the probability of each of the class right so and you are right so suppose one class just never shows up right and you still only have like negative class of positive cost then you probably should use LaPlace missing for that but I think this is a little bit less important because you know in most of the data set you have to see positive examples and negative samples you have to see a reasonable number of maybe 50 of positive negative and then LaPlace moving wouldn't really matter that much you can still use it but it wouldn't matter that much okay so going back to this so so recall that our problem was that when you have the when you have the parameters you get this zero right you you thought that other boxes shouldn't show up at all right because it's very extreme estimate and now when you add this one and two here on on so what you're gonna happen is that instead of having zero over the number of positive examples you get zero plus one over this plus two yeah I don't have a different color sorry so I have to just modify um um I just only have black pants um but so you get this and then this will be at least no longer so this will be still a pretty small number right this is one over the number of positive example plus two so but at least this is bigger than zero so and the same thing for this right so you're gonna get plus one our on this plus two and this is bigger than zero so if both of these are bigger than zero then when you evaluate this formula you are not going to evaluate to zero so your P of X will be some positive number so then you can get a a number of the P of bike effects and maybe just a very small extension give you have two minutes so two or three minutes so if you have more than two classes you can um this is just a for your interest um so suppose you have like a maybe a dice something like that right instead of like a coin so suppose you have Z which is from something like zero one up to K minus one so you have K choices then uh the LA plus the general LaPlace smoothing would be something like if you don't do LaPlace moving what you're gonna have is that the pro the chance you estimate this to be something like the number of times z i is equals to J over the total number of examples so you count how many examples kind of end up to the choice J and you divide by the total number of examples and if you use LaPlace moving you're gonna add one to the top and you add K to the bottom where K is the number of choices so so this is just a small extension of Laplace smoothing you know I don't think this course will use it again but for your interest um okay cool I guess that's pretty much all for today any questions okay great yeah in the next lecture I guess so we're going to talk about the kernel method and then we're going to talk to deep learning


{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/netraranga/Desktop/Projects/google_gemini/myenv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/netraranga/Desktop/Projects/google_gemini/myenv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import google.generativeai as genai\n",
    "from dotenv import load_dotenv\n",
    "from google.generativeai import caching\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import PyPDF2\n",
    "import os\n",
    "from reportlab.pdfgen import canvas\n",
    "from reportlab.lib.pagesizes import letter\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following datasets are the syllabus and transcripts of the lectures from the 2022 Fall Playlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "syllabus_df = pd.read_csv('syllabus_vf.csv') #pull in syllabus details\n",
    "syllabus_df_1 = syllabus_df.rename(columns={'Unnamed: 0':'Week', 'Unnamed: 1':'Lecture'}).drop(columns=['Deliverables', 'Additional Document Name'])\n",
    "\n",
    "youtube_df = pd.read_csv('youtube_playlist_contents.csv') #pull in transcript content \n",
    "youtube_df['Lecture'] = youtube_df.index + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv('/Users/netraranga/Desktop/Projects/.env')\n",
    "genai.configure(api_key=os.environ['GOOGLE_API_KEY'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are two functions that are used to write the transcripts to individual text files and to merge the regular lecture slides and annotated slides into one file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_transcripts_to_files(df):\n",
    "    \"\"\"\n",
    "    Function to write transcripts to individualtext files\n",
    "    \"\"\"\n",
    "\n",
    "    output_dir = '/Users/netraranga/Desktop/Projects/google_gemini/docs/transcripts'\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        # Create a filename based on the lecture number\n",
    "        filename = f\"lecture_{row['Lecture']}_transcript.txt\"\n",
    "        file_path = os.path.join(output_dir, filename)\n",
    "        \n",
    "\n",
    "        with open(file_path, 'w', encoding='utf-8') as file:\n",
    "            file.write(row['Video Contents'])\n",
    "        \n",
    "        print(f\"Transcript for Lecture {row['Lecture']} written to {file_path}\")\n",
    "\n",
    "write_transcripts_to_files(youtube_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_title_page(title):\n",
    "    \"\"\"\n",
    "    Helper function to create title pages for the PDFs\n",
    "    \"\"\"\n",
    "\n",
    "    packet = BytesIO()\n",
    "    can = canvas.Canvas(packet, pagesize=letter)\n",
    "    can.setFont(\"Helvetica\", 24)\n",
    "    can.drawString(100, 400, title)\n",
    "    can.save()\n",
    "    packet.seek(0)\n",
    "    return PyPDF2.PdfReader(packet)\n",
    "\n",
    "def merge_annotated_slides(combined_annotated_slides):\n",
    "    \"\"\"\n",
    "    Helper function to merge regular lecture slides and annotated slides\n",
    "    \"\"\"\n",
    "\n",
    "    docs_folder = '/Users/netraranga/Desktop/Projects/google_gemini/docs'\n",
    "    consolidated_folder = os.path.join(docs_folder, 'consolidated')\n",
    "\n",
    "    output_files = []\n",
    "    \n",
    "    for base_name in combined_annotated_slides:\n",
    "        merger = PyPDF2.PdfMerger()\n",
    "        original_file = os.path.join(docs_folder, f\"{base_name}.pdf\")\n",
    "        annotated_file = os.path.join(docs_folder, f\"{base_name}_annotated.pdf\")\n",
    "        \n",
    "        # Add title page and original slides\n",
    "        original_title = create_title_page(f\"Original {base_name} Slides\")\n",
    "        merger.append(original_title)\n",
    "        merger.append(original_file)\n",
    "        \n",
    "        # Add title page and annotated slides\n",
    "        annotated_title = create_title_page(f\"Annotated {base_name} Slides\")\n",
    "        merger.append(annotated_title)\n",
    "        merger.append(annotated_file)\n",
    "        \n",
    "        # Output PDF file name\n",
    "        output_pdf = os.path.join(consolidated_folder, f'combined_{base_name}_slides.pdf')\n",
    "        \n",
    "        try:\n",
    "            merger.write(output_pdf)\n",
    "            print(f\"PDFs merged successfully for {base_name}. Output file: {output_pdf}\")\n",
    "            output_files.append(output_pdf)\n",
    "        except Exception as e:\n",
    "            print(f\"Error writing output file for {base_name}: {str(e)}\")\n",
    "        finally:\n",
    "            merger.close()\n",
    "    \n",
    "    return output_files\n",
    "\n",
    "#Get list of files that need to be consolidated\n",
    "combined_annotated_slides = []\n",
    "for file_path in os.listdir('/Users/netraranga/Desktop/Projects/google_gemini/docs'):\n",
    "      if 'annotated' in file_path:\n",
    "            combined_annotated_slides.append(file_path.split('_')[0])\n",
    "\n",
    "# Usage\n",
    "output_files = merge_annotated_slides(combined_annotated_slides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Order of files - use only lectures and annotated slides\n",
    "lecture_1 = '/Users/netraranga/Desktop/Projects/google_gemini/docs/transcripts/lecture_1_transcript.txt'\n",
    "file_1 = genai.upload_file(path=lecture_1)\n",
    "\n",
    "lecture_2 = '/Users/netraranga/Desktop/Projects/google_gemini/docs/transcripts/lecture_2_transcript.txt'\n",
    "file_2 = genai.upload_file(path=lecture_2)\n",
    "\n",
    "# lin_alg_notes = '/Users/netraranga/Desktop/Projects/google_gemini/docs/linalg_notes.pdf'\n",
    "# file_3 = genai.upload_file(path=lin_alg_notes)\n",
    "\n",
    "# lin_alg_slides = '/Users/netraranga/Desktop/Projects/google_gemini/docs/linalg_slides.pdf'\n",
    "# file_3_1 = genai.upload_file(path=lin_alg_slides)\n",
    "\n",
    "lecture_3 = '/Users/netraranga/Desktop/Projects/google_gemini/docs/transcripts/lecture_3_transcript.txt'\n",
    "file_4 = genai.upload_file(path=lecture_3)\n",
    "\n",
    "lecture_4 = '/Users/netraranga/Desktop/Projects/google_gemini/docs/transcripts/lecture_4_transcript.txt'\n",
    "file_5 = genai.upload_file(path=lecture_4)\n",
    "\n",
    "# probs_notes = '/Users/netraranga/Desktop/Projects/google_gemini/docs/prob_notes.pdf'\n",
    "# file_6 = genai.upload_file(path=probs_notes)\n",
    "\n",
    "# probs_slides = '/Users/netraranga/Desktop/Projects/google_gemini/docs/prob_slides.pdf'\n",
    "# file_6_1 = genai.upload_file(path=probs_slides)\n",
    "\n",
    "lecture_5 = '/Users/netraranga/Desktop/Projects/google_gemini/docs/transcripts/lecture_5_transcript.txt'\n",
    "file_7 = genai.upload_file(path=lecture_5)\n",
    "\n",
    "lecture_6 = '/Users/netraranga/Desktop/Projects/google_gemini/docs/transcripts/lecture_6_transcript.txt'\n",
    "file_8 = genai.upload_file(path=lecture_6)\n",
    "\n",
    "# numpy_slides = '/Users/netraranga/Desktop/Projects/google_gemini/docs/numpy_slides.pdf'\n",
    "# file_9 = genai.upload_file(path=numpy_slides)\n",
    "\n",
    "lecture_7 = '/Users/netraranga/Desktop/Projects/google_gemini/docs/transcripts/lecture_7_transcript.txt'\n",
    "file_10 = genai.upload_file(path=lecture_7)\n",
    "\n",
    "lecture_8 = '/Users/netraranga/Desktop/Projects/google_gemini/docs/transcripts/lecture_8_transcript.txt'\n",
    "file_11 = genai.upload_file(path=lecture_8)\n",
    "\n",
    "eval_slides = '/Users/netraranga/Desktop/Projects/google_gemini/docs/original_pdfs/eval_slides.pdf'\n",
    "file_12 = genai.upload_file(path=eval_slides)\n",
    "\n",
    "lecture_9 = '/Users/netraranga/Desktop/Projects/google_gemini/docs/transcripts/lecture_9_transcript.txt'\n",
    "file_13 = genai.upload_file(path=lecture_9)\n",
    "\n",
    "lecture_10 = '/Users/netraranga/Desktop/Projects/google_gemini/docs/transcripts/lecture_10_transcript.txt'\n",
    "file_14 = genai.upload_file(path=lecture_10)\n",
    "\n",
    "bias_slides = '/Users/netraranga/Desktop/Projects/google_gemini/docs//original_pdfs/bias_annotated.pdf'\n",
    "file_15 = genai.upload_file(path=bias_slides)\n",
    "\n",
    "ridge_slides = '/Users/netraranga/Desktop/Projects/google_gemini/docs/original_pdfs/ridge_annotated.pdf'\n",
    "file_16 = genai.upload_file(path=ridge_slides)\n",
    "\n",
    "lasso_slides = '/Users/netraranga/Desktop/Projects/google_gemini/docs/original_pdfs/lasso_annotated.pdf'\n",
    "file_17 = genai.upload_file(path=lasso_slides)\n",
    "\n",
    "midterm_review = '/Users/netraranga/Desktop/Projects/google_gemini/docs//original_pdfs/midterm_review.pdf'\n",
    "file_18 = genai.upload_file(path=midterm_review)\n",
    "\n",
    "lecture_11 = '/Users/netraranga/Desktop/Projects/google_gemini/docs/transcripts/lecture_11_transcript.txt'\n",
    "file_19 = genai.upload_file(path=lecture_11)\n",
    "\n",
    "boosting_slides = '/Users/netraranga/Desktop/Projects/google_gemini/docs//original_pdfs/boosting.pdf'\n",
    "file_20 = genai.upload_file(path=boosting_slides)\n",
    "\n",
    "decision_trees_slides = '/Users/netraranga/Desktop/Projects/google_gemini/docs//original_pdfs/decisiontrees_annotated.pdf'\n",
    "file_21 = genai.upload_file(path=decision_trees_slides)\n",
    "\n",
    "# decision_trees_overfitting = '/Users/netraranga/Desktop/Projects/google_gemini/docs/decisiontrees_overfitting.pdf'\n",
    "# file_22 = genai.upload_file(path=decision_trees_overfitting)\n",
    "\n",
    "lecture_12 = '/Users/netraranga/Desktop/Projects/google_gemini/docs/transcripts/lecture_12_transcript.txt'\n",
    "file_23 = genai.upload_file(path=lecture_12)\n",
    "\n",
    "lecture_13 = '/Users/netraranga/Desktop/Projects/google_gemini/docs/transcripts/lecture_13_transcript.txt'\n",
    "file_24 = genai.upload_file(path=lecture_13)\n",
    "\n",
    "kmeans_slides = '/Users/netraranga/Desktop/Projects/google_gemini/docs//original_pdfs/kmeans_annotated.pdf'\n",
    "file_25 = genai.upload_file(path=kmeans_slides)\n",
    "\n",
    "em_slides = '/Users/netraranga/Desktop/Projects/google_gemini/docs//original_pdfs/em_annotated.pdf'\n",
    "file_26 = genai.upload_file(path=em_slides)\n",
    "\n",
    "pca_slides = '/Users/netraranga/Desktop/Projects/google_gemini/docs//original_pdfs/pca_annotated.pdf'\n",
    "file_27 = genai.upload_file(path=pca_slides)\n",
    "\n",
    "lecture_14 = '/Users/netraranga/Desktop/Projects/google_gemini/docs/transcripts/lecture_14_transcript.txt'\n",
    "file_28 = genai.upload_file(path=lecture_14)\n",
    "\n",
    "lecture_15 = '/Users/netraranga/Desktop/Projects/google_gemini/docs/transcripts/lecture_15_transcript.txt'\n",
    "file_29 = genai.upload_file(path=lecture_15)\n",
    "\n",
    "# ml_advice = '/Users/netraranga/Desktop/Projects/google_gemini/docs/ml_advice.pdf'\n",
    "# file_30 = genai.upload_file(path=ml_advice)\n",
    "\n",
    "lecture_16 = '/Users/netraranga/Desktop/Projects/google_gemini/docs/transcripts/lecture_16_transcript.txt'\n",
    "file_31 = genai.upload_file(path=lecture_16)\n",
    "\n",
    "learning_slides = '/Users/netraranga/Desktop/Projects/google_gemini/docs//original_pdfs/learning.pdf'\n",
    "file_32 = genai.upload_file(path=learning_slides)\n",
    "\n",
    "lecture_17 = '/Users/netraranga/Desktop/Projects/google_gemini/docs/transcripts/lecture_17_transcript.txt'\n",
    "file_33 = genai.upload_file(path=lecture_17)\n",
    "\n",
    "lecture_18 = '/Users/netraranga/Desktop/Projects/google_gemini/docs/transcripts/lecture_18_transcript.txt'\n",
    "file_34 = genai.upload_file(path=lecture_18)\n",
    "\n",
    "lecture_19 = '/Users/netraranga/Desktop/Projects/google_gemini/docs/transcripts/lecture_19_transcript.txt'\n",
    "file_35 = genai.upload_file(path=lecture_19)\n",
    "\n",
    "fairness_slides = '/Users/netraranga/Desktop/Projects/google_gemini/docs//original_pdfs/fairness_annotated.pdf'\n",
    "file_36 = genai.upload_file(path=fairness_slides)\n",
    "\n",
    "privacy_slides = '/Users/netraranga/Desktop/Projects/google_gemini/docs//original_pdfs/privacy_annotated.pdf'\n",
    "file_37 = genai.upload_file(path=privacy_slides)\n",
    "\n",
    "explanation_slides = '/Users/netraranga/Desktop/Projects/google_gemini/docs//original_pdfs/explainability_annotated.pdf'\n",
    "file_38 = genai.upload_file(path=explanation_slides)\n",
    "\n",
    "textbook = '/Users/netraranga/Desktop/Projects/google_gemini/docs/textbook.pdf'\n",
    "file_39 = genai.upload_file(path=textbook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "### System Prompt\n",
    "system_prompt = \"\"\"You are an expert tutor specializing in machine learning, with comprehensive knowledge of the Stanford CS229 \"Introduction to Machine Learning\" course. You have access to all relevant materials, including:\n",
    "- Annotated and regular lecture notes for each session.\n",
    "- Transcripts of all recorded lectures.\n",
    "- The complete course textbook.\n",
    "Your role is to guide the user through the CS229 course material by:\n",
    "1. **Providing clear, detailed explanations** of key machine learning concepts and algorithms, from foundational topics like linear regression and classification to advanced areas such as support vector machines and unsupervised learning.\n",
    "2. **Connecting course concepts**, explaining how different topics (e.g., gradient descent, regularization) relate and build upon each other across lectures.\n",
    "3. **Summarizing lectures and sections**, highlighting major takeaways, essential equations, and conceptual insights.\n",
    "4. **Supporting exam preparation**, identifying high-impact topics, common pitfalls, and suggesting areas for further review.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cache(name, contents, time=10):\n",
    "    \"\"\"\n",
    "    Create a cache for the gemini model\n",
    "    \"\"\"\n",
    "    custom_cache = caching.CachedContent.create(\n",
    "    model='models/gemini-1.5-flash-002',\n",
    "    display_name=name,\n",
    "    system_instruction=(\n",
    "    system_prompt),\n",
    "    contents=contents,\n",
    "    ttl=datetime.timedelta(minutes=time))\n",
    "\n",
    "    return custom_cache\n",
    "\n",
    "\n",
    "def gemini_response(cache, question):\n",
    "    \"\"\"\n",
    "    Function to generate a response from the gemini model\n",
    "    \"\"\"\n",
    "    model = genai.GenerativeModel.from_cached_content(cached_content=cache)\n",
    "    response = model.generate_content([(question)])\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regular Queries from certain lectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "textbook_cache = create_cache(name='textbook', contents=file_39)\n",
    "response_1 = gemini_response(textbook_cache, 'Give me an overview of L1 and L2 regularization and how they are used in machine learning.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "lecture_cache = create_cache(name='lecture_notes', contents=[file_1, file_2, file_4, file_5, file_7, file_8, file_10, file_11, file_12, file_13, file_14, file_15, file_16, file_17, file_18, file_19, file_20, file_21, file_23, file_24, file_25, file_26, file_27, file_28, file_29, file_31, file_32, file_33, file_34, file_35, file_39])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_2 = gemini_response(lecture_cache, 'What is an examle of something mentioned in the Neural Networks lecture that wasn not included in the textbook? Provide 2-3 specific examples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Neural Networks lectures in CS229 contain several concepts and details not explicitly covered in the textbook. Here are a few examples:\n",
      "\n",
      "1. **Different Variants of Gradient Descent in Deep Learning:** While the textbook covers gradient descent, the lectures delve into the specifics of stochastic gradient descent (SGD) and mini-batch gradient descent, including practical considerations like the choice of batch size (often determined empirically by the maximum batch size your GPU memory can handle) and the fact that smaller batch sizes often lead to better performance but at the cost of increased noise.  The textbook doesn't give the same level of practical algorithmic detail.\n",
      "\n",
      "2. **ReLU and Other Activation Functions:** Although the textbook might mention activation functions in general, the lectures focus specifically on the ReLU (Rectified Linear Unit) activation function, its properties (non-linearity), its use in neural networks, and its widespread popularity in deep learning.  The lectures also discuss other activation functions like sigmoid and tanh, comparing and contrasting their properties and suitability for different applications; this level of comparative analysis isn't present in the textbook's more concise overview.\n",
      "\n",
      "3. **Connection Between Neural Networks and Kernel Methods:** The lectures draw a direct parallel between neural networks and kernel methods. The idea that the penultimate layer of a neural network can be viewed as a learned feature map (Φβ(x)), creating a structure similar to the feature map used in kernel methods (Φ(x)), is explained in detail. This connection, highlighting the learned versus handcrafted feature aspect, is not explicitly elaborated in the textbook.\n",
      "\n",
      "\n",
      "These examples show how the lectures often build upon the textbook's foundational material by providing specific algorithmic details, implementation advice, and connections between different machine learning approaches.  They enhance the understanding of practical aspects not always emphasized in the theoretical treatment of the textbook.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(response_2.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The CS229 lecture on KMeans includes several important points and nuanced discussions not explicitly detailed in the accompanying notes.  Here are some key concepts that are discussed in the lecture but receive less attention or are absent from the notes:\n",
      "\n",
      "\n",
      "1. **The Squishiness of Unsupervised Learning and the Role of Assumptions:** The lecture emphasizes the inherent ambiguity and difficulty in unsupervised learning compared to supervised learning.  It highlights that unsupervised methods necessitate stronger assumptions about the underlying data structure (e.g., the existence of K clusters) and accept weaker guarantees (e.g., convergence to a local rather than a global optimum). This philosophical point about the trade-off between stronger assumptions and weaker guarantees isn't explicitly stated in the notes, which focus more on the algorithmic details.\n",
      "\n",
      "2. **Initialization Strategies and KMeans++:** The lecture introduces the importance of initialization in KMeans. While the notes mention random initialization, they lack the discussion of the limitations of this approach, particularly the possibility of getting stuck in poor local minima due to bad initial centroid placement. The lecture introduces KMeans++, highlighting its improved approximation ratio and its role as the default initialization method in scikit-learn,  providing a more robust approach than simply running KMeans multiple times with random initialization.  This sophisticated algorithm and its advantages are not covered in the provided notes.\n",
      "\n",
      "3. **The Difficulty of Choosing K:** The lecture explicitly addresses the challenging task of selecting the optimal number of clusters (K).  The notes primarily focus on the algorithm assuming K is known. However, the lecture acknowledges that there is no single \"right\" answer for K, that it's fundamentally a modeling choice, and that the user may need to leverage domain knowledge or evaluate results for different K values to determine the most meaningful clustering.\n",
      "\n",
      "4. **Intuitive Explanation of KMeans Convergence:** The lecture provides a more intuitive explanation for why the KMeans algorithm converges.  The notes state convergence but lack the detailed explanation of how the potential function (sum of squared distances from points to their cluster centers) monotonically decreases with each iteration, preventing oscillations and ensuring convergence to a (possibly local) minimum.  The lecture connects this convergence to the concept of gradient descent on the potential function, offering a deeper understanding than just stating convergence.\n",
      "\n",
      "5. **Comparison to Other Clustering Approaches:** The lecture briefly touches upon the limitations of KMeans due to its assumption of spherical, equally sized clusters and mentions other approaches, such as the application of k-means after performing dimensionality reduction (e.g., PCA or embeddings) for data which are not spherically symmetric,  or the merging of clusters to improve clustering results. This discussion on the limitations of the basic algorithm and the existence of more sophisticated techniques is absent from the notes.\n",
      "\n",
      "In summary, while the notes provide the core KMeans algorithm, the lecture expands upon these core aspects by offering crucial insights into the theoretical challenges and practical considerations involved in unsupervised learning and the implementation of KMeans.  The focus shifts from purely algorithmic to a more nuanced discussion of assumptions, limitations, and interpretational subtleties of the method.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response_3 = gemini_response(lecture_cache, 'What are some key concepts covered in the KMeans lecture that are not covered in the notes? Be very specific in the points you generate.')\n",
    "print(response_3.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pca_comparison = genai.upload_file(path='/Users/netraranga/Desktop/Projects/google_gemini/docs/consolidated/combined_pca_slides.pdf')\n",
    "pca_cache = create_cache(name='pca', contents=pca_comparison)\n",
    "response_pca= gemini_response(pca_cache, 'What are the differences between the PCA original slides and the annotated slides? Be specific in the type of differences you generate, do not include generic points like the annotated slides have more information')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The difference between the original and annotated PCA slides lies primarily in the addition of handwritten notes and diagrams on the annotated version.  These additions clarify concepts and calculations presented in the original slides. Let's break down the specific types of annotations:\n",
      "\n",
      "1. **Elaboration on Mathematical Concepts:** The annotated slides contain additional mathematical steps, derivations, and explanations of equations related to reconstruction error, covariance matrices, and the relationship between PCA and eigenvectors.  For example, the derivation of the reconstruction error is expanded, showing intermediate steps and clarifying how minimizing this error leads to the selection of eigenvectors.\n",
      "\n",
      "2. **Visual Aids and Interpretations:**  Handwritten diagrams and annotations are added to existing figures to illustrate the projection process, the reconstruction error visually, and the choice of optimal projection vectors.  These additions offer a more intuitive understanding of how the algorithm works geometrically.\n",
      "\n",
      "3. **Conceptual Clarifications:**  The annotator adds notes explaining the meaning and implications of key concepts like \"intrinsic dimensionality,\" the selection of principal components based on eigenvalues, and the interpretation of eigenvectors in the context of the data.  For instance, the slides illustrating word embeddings are enhanced with labels that group words by semantic categories (e.g., \"names,\" \"months,\" \"states/cities\").\n",
      "\n",
      "4. **Algorithm Steps and Flow:** The process of PCA, especially the steps in the algorithm, is broken down further and explained in more detail using handwritten annotations to better guide understanding of the flow.\n",
      "\n",
      "5. **Practical Considerations and Alternative Approaches:** The annotated slides touch upon practical issues like the computational challenges of dealing with high-dimensional covariance matrices, and introduce Singular Value Decomposition (SVD) as an efficient alternative.\n",
      "\n",
      "\n",
      "In short, while the original slides provide a structured overview of PCA, the annotations significantly enhance the understanding by providing detailed mathematical support, geometrical interpretations, conceptual clarifications, and practical implementation tips. They transform the slides from a presentation of results into a step-by-step tutorial.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(response_pca.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in caching.CachedContent.list():\n",
    "  print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for c in caching.CachedContent.list():\n",
    "#   print(c) #Slide 1 to 15 are 166273 tokens\n",
    "  #Slide 1 to 38 are 500798\n",
    "\n",
    "for c in caching.CachedContent.list():\n",
    "    c.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TO ODO\n",
    "#-combines all of the slide contents into one file so it passes the cache min size limit\n",
    "#Determine with chatgpt what are good questions - study guides on certain lectures and concepts\n",
    "#Identify the differece between annotated notes and regular notes\n",
    "#Create a study guide that is grounded in the lecture nad pulls additional key concepts from the notes\n",
    "#Generate some python questions for certain lectures for the application piece \n",
    "#Watch a certain video and see if the LLM can retrieve the specific fact or instnce referenced in the video"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
